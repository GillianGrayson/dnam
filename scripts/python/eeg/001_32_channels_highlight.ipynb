{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from sklearn.linear_model import ElasticNet, ElasticNetCV\n",
    "from sklearn.model_selection import RepeatedKFold, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from scripts.python.routines.betas import betas_drop_na\n",
    "from plotly.subplots import make_subplots\n",
    "from numpy.ma import masked_array\n",
    "from scipy import stats\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import pickle\n",
    "import random\n",
    "import plotly.express as px\n",
    "import copy\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from scripts.python.pheno.datasets.filter import filter_pheno\n",
    "from scripts.python.pheno.datasets.features import get_column_name, get_status_dict, get_sex_dict\n",
    "from scripts.python.routines.plot.scatter import add_scatter_trace\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "from scripts.python.routines.manifest import get_manifest\n",
    "from scripts.python.routines.plot.save import save_figure\n",
    "from scripts.python.routines.plot.layout import add_layout, get_axis\n",
    "from scripts.python.routines.plot.p_value import add_p_value_annotation\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import plotly.io as pio\n",
    "pio.kaleido.scope.mathjax = None\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=False)\n",
    "from pathlib import Path\n",
    "from functools import reduce\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import kruskal, mannwhitneyu\n",
    "from impyute.imputation.cs import fast_knn, mean, median, random, mice, mode, em\n",
    "from scripts.python.eeg.routines import plot_32_electrodes_scatter, plot_32_electrodes_bar, plot_32_electrodes_beeswarm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prepare data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path = \"E:/YandexDisk/EEG/experiments\"\n",
    "\n",
    "exp_type = '1st_day'\n",
    "exp_sub_type = 'real'\n",
    "model = 'xgboost'\n",
    "exp_date = '2022-07-02_12-09-58'\n",
    "\n",
    "class_column = 'class_simp'\n",
    "\n",
    "df_data = pd.read_excel(f\"{path}/{exp_type}/data.xlsx\", index_col=\"index\")\n",
    "\n",
    "df_features = pd.read_excel(f\"{path}/{exp_type}/features_freq.xlsx\", index_col=\"features\")\n",
    "features = df_features.index.values\n",
    "\n",
    "df_classes = pd.read_excel(f\"{path}/{exp_type}/classes/{exp_sub_type}.xlsx\")\n",
    "classes = df_classes[class_column].values\n",
    "\n",
    "df_data = df_data.loc[df_data[class_column].isin(classes), :]\n",
    "subjects = sorted(df_data['subject'].unique(), key=lambda x: float(x[1::]))\n",
    "samples = df_data.index.values\n",
    "\n",
    "path_load = f\"{path}/{exp_type}/models/{exp_type}_{exp_sub_type}_trn_val_{model}/runs/{exp_date}\"\n",
    "path_save = f\"{path}/special/001_32_channels_highlight/{exp_type}_{exp_sub_type}_trn_val_{model}\"\n",
    "pathlib.Path(f\"{path_save}\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df_importance = pd.read_excel(f\"{path_load}/feature_importances.xlsx\", index_col='feature')\n",
    "missed_features = set(df_features.index) - set(df_importance.index)\n",
    "df_missed = pd.DataFrame(index=missed_features, columns=['importance'], data=np.zeros(len(missed_features)))\n",
    "df_importance = pd.concat([df_importance,df_missed])\n",
    "\n",
    "df_predictions = pd.read_excel(f\"{path_load}/predictions.xlsx\", index_col='index')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SHAP global (train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "shap_part = 'trn'\n",
    "\n",
    "pathlib.Path(f\"{path_save}/shap_{shap_part}/left\").mkdir(parents=True, exist_ok=True)\n",
    "pathlib.Path(f\"{path_save}/shap_{shap_part}/right\").mkdir(parents=True, exist_ok=True)\n",
    "df_shap_left = pd.read_excel(f\"{path_load}/shap/{shap_part}/shap_left_{exp_sub_type}.xlsx\", index_col='index')\n",
    "shap_samples = df_shap_left.index.values\n",
    "shap_subjects = sorted(df_data.loc[df_data.index.isin(df_shap_left.index), 'subject'].unique(), key=lambda x: float(x[1::]))\n",
    "df_shap_left = df_shap_left.T\n",
    "df_shap_right = pd.read_excel(f\"{path_load}/shap/{shap_part}/shap_right_{exp_sub_type}.xlsx\", index_col='index')\n",
    "df_shap_right = df_shap_right.T\n",
    "\n",
    "dict_subj_left = {}\n",
    "dict_subj_right = {}\n",
    "for subj in shap_subjects:\n",
    "    subj_columns = df_shap_left.columns.values[df_shap_left.columns.str.contains(subj)]\n",
    "    left_columns = [s for s in subj_columns if \"left\" in s]\n",
    "    right_columns = [s for s in subj_columns if \"right\" in s]\n",
    "    dict_subj_left[subj] = left_columns\n",
    "    dict_subj_right[subj] = right_columns\n",
    "\n",
    "for feat in features:\n",
    "    df_shap_left.at[feat, 'mean_abs_shap'] = np.mean(np.abs(df_shap_left.loc[feat, shap_samples].values))\n",
    "    df_shap_right.at[feat, 'mean_abs_shap'] = np.mean(np.abs(df_shap_right.loc[feat, shap_samples].values))\n",
    "    for subj in shap_subjects:\n",
    "        df_shap_left.at[feat, f\"{subj}_left\"] = np.mean(df_shap_left.loc[feat, dict_subj_left[subj]].values)\n",
    "        df_shap_left.at[feat, f\"{subj}_right\"] = np.mean(df_shap_left.loc[feat, dict_subj_right[subj]].values)\n",
    "        df_shap_right.at[feat, f\"{subj}_left\"] = np.mean(df_shap_right.loc[feat, dict_subj_left[subj]].values)\n",
    "        df_shap_right.at[feat, f\"{subj}_right\"] = np.mean(df_shap_right.loc[feat, dict_subj_right[subj]].values)\n",
    "\n",
    "df_shap_left.sort_values(['mean_abs_shap'], ascending=[False], inplace=True)\n",
    "df_shap_right.sort_values(['mean_abs_shap'], ascending=[False], inplace=True)\n",
    "\n",
    "plot_32_electrodes_scatter(df_shap_left, 'mean_abs_shap', \"Mean(|SHAP values|)\", \"min2max\", f\"{path_save}/shap_{shap_part}/left\")\n",
    "plot_32_electrodes_bar(df_shap_left, 'mean_abs_shap', \"Mean(|SHAP values|)\", \"min2max\", f\"{path_save}/shap_{shap_part}/left\")\n",
    "plot_32_electrodes_beeswarm(df_shap_left, df_data, shap_samples , \"SHAP values\", f\"{path_save}/shap_{shap_part}/left\")\n",
    "plot_32_electrodes_scatter(df_shap_right, 'mean_abs_shap', \"Mean(|SHAP values|)\", \"min2max\", f\"{path_save}/shap_{shap_part}/right\")\n",
    "plot_32_electrodes_bar(df_shap_right, 'mean_abs_shap', \"Mean(|SHAP values|)\", \"min2max\", f\"{path_save}/shap_{shap_part}/right\")\n",
    "plot_32_electrodes_beeswarm(df_shap_right, df_data, shap_samples , \"SHAP values\", f\"{path_save}/shap_{shap_part}/right\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SHAP local (val)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "shap_part = 'val'\n",
    "\n",
    "pathlib.Path(f\"{path_save}/shap_{shap_part}\").mkdir(parents=True, exist_ok=True)\n",
    "df_shap_left = pd.read_excel(f\"{path_load}/shap/{shap_part}/shap_left_{exp_sub_type}.xlsx\", index_col='index')\n",
    "shap_samples = df_shap_left.index.values\n",
    "shap_subjects = sorted(df_data.loc[df_data.index.isin(df_shap_left.index), 'subject'].unique(), key=lambda x: float(x[1::]))\n",
    "df_shap_left = df_shap_left.T\n",
    "df_shap_right = pd.read_excel(f\"{path_load}/shap/{shap_part}/shap_right_{exp_sub_type}.xlsx\", index_col='index')\n",
    "df_shap_right = df_shap_right.T\n",
    "\n",
    "dict_subj_left = {}\n",
    "dict_subj_right = {}\n",
    "for subj in shap_subjects:\n",
    "    subj_columns = df_shap_left.columns.values[df_shap_left.columns.str.contains(subj)]\n",
    "    left_columns = [s for s in subj_columns if \"left\" in s]\n",
    "    right_columns = [s for s in subj_columns if \"right\" in s]\n",
    "    dict_subj_left[subj] = left_columns\n",
    "    dict_subj_right[subj] = right_columns\n",
    "\n",
    "for feat in features:\n",
    "    df_shap_left.at[feat, 'mean_abs_shap'] = np.mean(np.abs(df_shap_left.loc[feat, shap_samples].values))\n",
    "    df_shap_right.at[feat, 'mean_abs_shap'] = np.mean(np.abs(df_shap_right.loc[feat, shap_samples].values))\n",
    "    for subj in shap_subjects:\n",
    "        df_shap_left.at[feat, f\"{subj}_left\"] = np.mean(df_shap_left.loc[feat, dict_subj_left[subj]].values)\n",
    "        df_shap_left.at[feat, f\"{subj}_right\"] = np.mean(df_shap_left.loc[feat, dict_subj_right[subj]].values)\n",
    "        df_shap_right.at[feat, f\"{subj}_left\"] = np.mean(df_shap_right.loc[feat, dict_subj_left[subj]].values)\n",
    "        df_shap_right.at[feat, f\"{subj}_right\"] = np.mean(df_shap_right.loc[feat, dict_subj_right[subj]].values)\n",
    "\n",
    "df_shap_left.sort_values(['mean_abs_shap'], ascending=[False], inplace=True)\n",
    "df_shap_right.sort_values(['mean_abs_shap'], ascending=[False], inplace=True)\n",
    "\n",
    "samples_targ = [\n",
    "    'S6_T0_right_real',\n",
    "    'S9_T3_right_real',\n",
    "    'S14_T4_right_real',\n",
    "\n",
    "    'S6_T0_left_real',\n",
    "    'S9_T10_left_real',\n",
    "    'S14_T7_left_real',\n",
    "\n",
    "    'S6_T5_left_real',\n",
    "    'S9_T15_left_real',\n",
    "    'S14_T18_left_real',\n",
    "]\n",
    "\n",
    "for sample in samples_targ:\n",
    "    pathlib.Path(f\"{path_save}/shap_{shap_part}/{sample}/left\").mkdir(parents=True, exist_ok=True)\n",
    "    pathlib.Path(f\"{path_save}/shap_{shap_part}/{sample}/right\").mkdir(parents=True, exist_ok=True)\n",
    "    plot_32_electrodes_scatter(df_shap_left, sample, \"SHAP values\", \"minus2plus\", f\"{path_save}/shap_{shap_part}/{sample}/left\")\n",
    "    plot_32_electrodes_scatter(df_shap_right, sample, \"SHAP values\", \"minus2plus\", f\"{path_save}/shap_{shap_part}/{sample}/right\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-7948d80f",
   "language": "python",
   "display_name": "PyCharm (dnam)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}