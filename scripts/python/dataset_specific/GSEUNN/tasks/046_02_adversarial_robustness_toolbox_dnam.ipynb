{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src.utils.outliers.iqr import add_iqr_outs_to_df, plot_iqr_outs, plot_iqr_outs_cls\n",
    "from src.utils.outliers.pyod import add_pyod_outs_to_df, plot_pyod_outs, plot_pyod_outs_cls\n",
    "from scripts.python.dataset_specific.GSEUNN.tasks.routines_046 import plot_regression_error_distributions, plot_cls_dim_red\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy import stats\n",
    "import plotly.express as px\n",
    "from scripts.python.routines.plot.scatter import add_scatter_trace\n",
    "import plotly.graph_objects as go\n",
    "from scripts.python.routines.plot.save import save_figure\n",
    "from scripts.python.routines.plot.layout import add_layout, get_axis\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import plotly.io as pio\n",
    "import importlib\n",
    "pio.kaleido.scope.mathjax = None\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "from scipy.interpolate import interp1d\n",
    "from src.utils.verbose import NoStdStreams\n",
    "init_notebook_mode(connected=False)\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from omegaconf import OmegaConf\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "import pathlib\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.decomposition import MiniBatchDictionaryLearning, FastICA\n",
    "from sklearn.random_projection import GaussianRandomProjection, SparseRandomProjection\n",
    "from sklearn.manifold import MDS, Isomap\n",
    "from openTSNE import TSNE\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from scipy import stats\n",
    "import patchworklib as pw\n",
    "import os\n",
    "import functools\n",
    "from scipy.stats import iqr\n",
    "from statannotations.Annotator import Annotator\n",
    "from scipy.stats import mannwhitneyu, kruskal\n",
    "import shap\n",
    "from slugify import slugify\n",
    "from src.models.tabular.widedeep.ft_transformer import WDFTTransformerModel\n",
    "from src.models.tabular.widedeep.tab_net import WDTabNetModel\n",
    "from art.estimators.regression.pytorch import PyTorchRegressor\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "from art.estimators.regression.blackbox import BlackBoxRegressor\n",
    "from art.attacks.evasion import ProjectedGradientDescentNumpy, FastGradientMethod, BasicIterativeMethod, MomentumIterativeMethod\n",
    "from art.attacks.evasion import ZooAttack, CarliniL2Method, ElasticNet, NewtonFool\n",
    "import torch\n",
    "from src.tasks.metrics import get_cls_pred_metrics, get_cls_prob_metrics\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "from sdv.metadata import SingleTableMetadata\n",
    "from sdv.lite import SingleTablePreset\n",
    "from sdv.single_table import GaussianCopulaSynthesizer, CTGANSynthesizer, TVAESynthesizer, CopulaGANSynthesizer\n",
    "from sdv.evaluation.single_table import evaluate_quality\n",
    "from sdv.evaluation.single_table import get_column_plot\n",
    "from sdv.evaluation.single_table import get_column_pair_plot\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scripts.python.routines.mvals import expit2\n",
    "\n",
    "import missingno as msno\n",
    "\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "from pyod.models.ecod import ECOD\n",
    "from pyod.models.abod import ABOD\n",
    "from pyod.models.copod import COPOD\n",
    "from pyod.models.sos import SOS\n",
    "from pyod.models.kde import KDE\n",
    "from pyod.models.sampling import Sampling\n",
    "from pyod.models.gmm import GMM\n",
    "\n",
    "from pyod.models.kpca import KPCA\n",
    "from pyod.models.mcd import MCD\n",
    "from pyod.models.ocsvm import OCSVM\n",
    "from pyod.models.lmdd import LMDD\n",
    "\n",
    "from pyod.models.lof import LOF\n",
    "from pyod.models.cof import COF\n",
    "from pyod.models.cblof import CBLOF\n",
    "from pyod.models.hbos import HBOS\n",
    "from pyod.models.knn import KNN\n",
    "from pyod.models.sod import SOD\n",
    "\n",
    "from pyod.models.iforest import IForest\n",
    "from pyod.models.inne import INNE\n",
    "from pyod.models.loda import LODA\n",
    "from pyod.models.suod import SUOD\n",
    "\n",
    "from pyod.models.auto_encoder_torch import AutoEncoder\n",
    "from pyod.models.vae import VAE\n",
    "from pyod.models.deep_svdd import DeepSVDD\n",
    "\n",
    "from pyod.models.lunar import LUNAR\n",
    "\n",
    "from torchmetrics import BootStrapper\n",
    "\n",
    "\n",
    "def conjunction(conditions):\n",
    "    return functools.reduce(np.logical_and, conditions)\n",
    "\n",
    "\n",
    "def disjunction(conditions):\n",
    "    return functools.reduce(np.logical_or, conditions)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Adversarial examples for DNAm data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data processing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prepare data for ML, convert mvals to betas"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path = \"D:/YandexDisk/Work/pydnameth/datasets/GPL21145/GSEUNN/special/046_adversarial_robustness_toolbox/dnam\"\n",
    "\n",
    "df_mvals = pd.read_excel(f\"{path}/mvals.xlsx\", index_col=0)\n",
    "feats = pd.read_excel(f\"{path}/feats_1000.xlsx\", index_col=0).index.values\n",
    "\n",
    "betas = expit2(df_mvals.loc[:, feats].values)\n",
    "df_betas = df_mvals.copy()\n",
    "df_betas.loc[:, feats] = betas\n",
    "df_betas['Partition'].replace({'Train': 'trn_val', 'Validation': 'tst'}, inplace=True)\n",
    "df_betas.to_excel(f\"{path}/betas.xlsx\", index_label='subject_id')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Collect ML results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path = \"D:/YandexDisk/Work/pydnameth/datasets/GPL21145/GSEUNN/special/046_adversarial_robustness_toolbox/dnam\"\n",
    "\n",
    "model = 'widedeep_tab_net'\n",
    "\n",
    "path_runs = f\"{path}/models/{model}_trn_val_tst/multiruns\"\n",
    "\n",
    "files = glob(f\"{path_runs}/*/*/metrics_all_best_*.xlsx\")\n",
    "\n",
    "df_tmp = pd.read_excel(files[0], index_col=\"metric\")\n",
    "head, tail = os.path.split(files[0])\n",
    "cfg = OmegaConf.load(f\"{head}/.hydra/overrides.yaml\")\n",
    "params = []\n",
    "for param_pair in cfg:\n",
    "    param, val = param_pair.split('=')\n",
    "    params.append(param)\n",
    "df_res = pd.DataFrame(index=files)\n",
    "\n",
    "parts = [\n",
    "    'trn',\n",
    "    'val',\n",
    "    'tst',\n",
    "    'val_tst'\n",
    "]\n",
    "\n",
    "for file in files:\n",
    "    head, tail = os.path.split(file)\n",
    "    # Metrics\n",
    "    df_metrics = pd.read_excel(file, index_col=\"metric\")\n",
    "    for metric in df_metrics.index.values:\n",
    "        for part in parts:\n",
    "            df_res.at[file, metric + f\"_{part}\"] = df_metrics.at[metric, part]\n",
    "\n",
    "    # Params\n",
    "    cfg = OmegaConf.load(f\"{head}/.hydra/overrides.yaml\")\n",
    "    for param_pair in cfg:\n",
    "        param, val = param_pair.split('=')\n",
    "        df_res.at[file, param] = val\n",
    "\n",
    "df_res[\"train_worse_val\"] = False\n",
    "df_res.loc[df_res[\"accuracy_weighted_val\"] > df_res[\"accuracy_weighted_trn\"], \"train_worse_val\"] = True\n",
    "\n",
    "df_res[\"File\"] = df_res.index.str.replace(path_runs, '', regex=False)\n",
    "df_res.set_index(\"File\", inplace=True)\n",
    "\n",
    "first_columns = [\n",
    "    'accuracy_weighted_trn',\n",
    "    'accuracy_weighted_val',\n",
    "    'accuracy_weighted_tst',\n",
    "    'accuracy_weighted_val_tst'\n",
    "]\n",
    "df_res = df_res[first_columns + [col for col in df_res.columns if col not in first_columns]]\n",
    "df_res.to_excel(f\"{path_runs}/summary.xlsx\", index=True, index_label=\"file\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load data, models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_type = 'widedeep_tab_net'\n",
    "model_fn = 'best_fold_0000'\n",
    "model_version = 'v2'\n",
    "\n",
    "path = 'D:/YandexDisk/Work/pydnameth/datasets/GPL21145/GSEUNN/special/046_adversarial_robustness_toolbox/dnam'\n",
    "pathlib.Path(f\"{path}/Origin\").mkdir(parents=True, exist_ok=True)\n",
    "df = pd.read_excel(f\"{path}/betas.xlsx\", index_col=0)\n",
    "feats = pd.read_excel(f\"{path}/feats_1000.xlsx\", index_col=0).index.values\n",
    "ids_feat = list(range(len(feats)))\n",
    "\n",
    "df_pred = pd.read_excel(f\"{path}/models/{model_type}/{model_version}/predictions.xlsx\", index_col=0)\n",
    "df.loc[df.index, ['Real', 'Pred', 'Prob Control', 'Prob Parkinson']] = df_pred.loc[df.index, ['Status', 'pred', 'pred_prob_0', 'pred_prob_1']].values\n",
    "df['Data'] = 'Real'\n",
    "df['Eps'] = 'Origin'\n",
    "\n",
    "col_real = 'Real'\n",
    "col_pred = 'Pred'\n",
    "\n",
    "ids_trn_val = df.index[df['Partition'] == 'trn_val'].values\n",
    "ids_tst = df.index[df['Partition'] == 'tst'].values\n",
    "ids_all = df.index[df['Partition'].isin(['trn_val', 'tst'])].values\n",
    "ids_dict = {\n",
    "    'trn_val': ids_trn_val,\n",
    "    'tst': ids_tst,\n",
    "    'all': ids_all,\n",
    "}\n",
    "\n",
    "model = WDTabNetModel.load_from_checkpoint(checkpoint_path=f\"{path}/models/{model_type}/{model_version}/{model_fn}.ckpt\")\n",
    "model.produce_probabilities = False\n",
    "model.eval()\n",
    "model.freeze()\n",
    "\n",
    "colors_augs = {\n",
    "    'FAST_ML': px.colors.qualitative.Light24[0],\n",
    "    'GaussianCopula': px.colors.qualitative.Light24[1],\n",
    "    'CTGANSynthesizer': px.colors.qualitative.Light24[2],\n",
    "    'TVAESynthesizer': px.colors.qualitative.Light24[3],\n",
    "    'CopulaGANSynthesizer': px.colors.qualitative.Light24[4],\n",
    "}\n",
    "colors_atks_eps = {\n",
    "    \"MomentumIterative\": px.colors.qualitative.D3[0],\n",
    "    \"BasicIterative\": px.colors.qualitative.D3[1],\n",
    "    \"ProjectedGradientDescent\": px.colors.qualitative.D3[2],\n",
    "    \"FastGradient\": px.colors.qualitative.D3[3],\n",
    "}\n",
    "colors_atks_bss = {\n",
    "    \"ElasticNet\": px.colors.qualitative.G10[7],\n",
    "    \"CarliniL2Method\": px.colors.qualitative.G10[8],\n",
    "    \"ZooAttack\": px.colors.qualitative.G10[9],\n",
    "}\n",
    "colors_atks_eta = {\n",
    "    'NewtonFool': px.colors.qualitative.T10[7],\n",
    "}\n",
    "\n",
    "dim_red_labels = {\n",
    "    'PCA': ['PC 1', 'PC 2'],\n",
    "    'SVD': ['SVD 1', 'SVD 2'],\n",
    "    't-SNE': ['t-SNE 1', 't-SNE 2'],\n",
    "    'GRP': ['GRP 1', 'GRP 2'],\n",
    "    'SRP': ['SRP 1', 'SRP 2'],\n",
    "    'IsoMap': ['IsoMap 1', 'IsoMap 2'],\n",
    "    'MBDL': ['MBDL 1', 'MBDL 2'],\n",
    "}\n",
    "\n",
    "pyod_method_names = [\n",
    "    'ECOD',\n",
    "    'LUNAR',\n",
    "    'DeepSVDD',\n",
    "    'VAE',\n",
    "    'LODA',\n",
    "    'INNE',\n",
    "    'IForest',\n",
    "    'SOD',\n",
    "    'KNN',\n",
    "    'CBLOF',\n",
    "    'LOF',\n",
    "    'MCD',\n",
    "    'GMM',\n",
    "    'Sampling',\n",
    "    'SOS',\n",
    "    'COPOD',\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create PyOD models, trained on trn_val samples"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "contamination = 0.1\n",
    "\n",
    "pyod_methods = {\n",
    "    'ECOD': ECOD(contamination=contamination),\n",
    "    'LUNAR': LUNAR(),\n",
    "    'DeepSVDD': DeepSVDD(contamination=contamination, verbose=0),\n",
    "    'VAE': VAE(encoder_neurons=[32, 16, 8], decoder_neurons=[8, 16, 32], contamination=contamination),\n",
    "    'LODA': LODA(contamination=contamination),\n",
    "    'INNE': INNE(contamination=contamination),\n",
    "    'IForest': IForest(contamination=contamination),\n",
    "    'SOD': SOD(contamination=contamination),\n",
    "    'KNN': KNN(contamination=contamination),\n",
    "    'CBLOF': CBLOF(contamination=contamination),\n",
    "    'LOF': LOF(contamination=contamination),\n",
    "    'MCD': MCD(contamination=contamination),\n",
    "    'GMM': GMM(contamination=contamination),\n",
    "    'Sampling': Sampling(contamination=contamination),\n",
    "    'SOS': SOS(contamination=contamination),\n",
    "    'COPOD': COPOD(contamination=contamination),\n",
    "}\n",
    "\n",
    "for method_name, method in (pbar := tqdm(pyod_methods.items())):\n",
    "    pbar.set_description(f\"Processing {method_name}\")\n",
    "    \n",
    "    method.fit(df.loc[ids_trn_val, feats].values)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create dimensionality reduction models, trained on trn_val samples"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_dim_red = df.loc[ids_trn_val, feats].values\n",
    "random_state = 42\n",
    "dim_red_models = {\n",
    "    'PCA': PCA(n_components=2, whiten=False, random_state=random_state).fit(X_dim_red),\n",
    "    'SVD': TruncatedSVD(n_components=2, algorithm='randomized', n_iter=5, random_state=random_state).fit(X_dim_red),\n",
    "    't-SNE': TSNE(n_components=2, random_state=random_state).fit(X_dim_red),\n",
    "    'GRP': GaussianRandomProjection(n_components=2, eps=0.5, random_state=random_state).fit(X_dim_red),\n",
    "    'SRP': SparseRandomProjection(n_components=2, density='auto', eps=0.5, dense_output=False, random_state=random_state).fit(X_dim_red),\n",
    "    'IsoMap': Isomap(n_components=2, n_neighbors=5).fit(X_dim_red),\n",
    "    'MBDL': MiniBatchDictionaryLearning(n_components=2, batch_size=100, alpha=1, n_iter=25, random_state=random_state).fit(X_dim_red),\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Original data processing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "add_pyod_outs_to_df(df, pyod_methods, feats)\n",
    "add_iqr_outs_to_df(df, df.loc[ids_trn_val, :], feats)\n",
    "for method_name, method in (pbar := tqdm(dim_red_models.items())):\n",
    "    pbar.set_description(f\"Processing {method_name}\")\n",
    "    dim_red_res = method.transform(df.loc[:, feats].values)\n",
    "    df.loc[:, dim_red_labels[method_name][0]] = dim_red_res[:, 0]\n",
    "    df.loc[:, dim_red_labels[method_name][1]] = dim_red_res[:, 1]\n",
    "df.to_excel(f\"{path}/Origin/df.xlsx\", index_label='sample_id')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load original processed data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_excel(f\"{path}/Origin/df.xlsx\", index_col=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Original data plots in reduced dimension"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pathlib.Path(f\"{path}/Origin/dim_red\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df_fig = df.loc[:, list(np.concatenate(list(dim_red_labels.values()))) + ['Real', 'Pred', 'Prob Parkinson']].copy()\n",
    "df_fig.loc[df_fig['Real'] == 0, 'Status'] = 'Control'\n",
    "df_fig.loc[df_fig['Real'] == 1, 'Status'] = 'Parkinson'\n",
    "for method in dim_red_labels:\n",
    "    plot_cls_dim_red(\n",
    "        df=df_fig,\n",
    "        col_class='Status',\n",
    "        cls_names=['Control', 'Parkinson'],\n",
    "        col_prob='Prob Parkinson',\n",
    "        cols_dim_red=dim_red_labels[method],\n",
    "        title='Original',\n",
    "        fn=f\"{path}/Origin/dim_red/{method}\"\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Features distributions plots"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pathlib.Path(f\"{path}/Origin/feats\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df_stat = pd.DataFrame(index=feats, columns=['mw_pval', 'mw_pval_fdr_bh'])\n",
    "for f in feats:\n",
    "    _, df_stat.at[f, 'mw_pval'] = mannwhitneyu(df.loc[df['Real'] == 0, f].values, df.loc[df['Real'] == 1, f].values, alternative='two-sided')\n",
    "_, df_stat.loc[:, 'mw_pval_fdr_bh'], _, _ = multipletests(df_stat.loc[:, \"mw_pval\"], 0.05, method='fdr_bh')\n",
    "df_stat.sort_values(['mw_pval_fdr_bh'], ascending=[True], inplace=True)\n",
    "df_stat[r'$ -\\log_{10}(\\mathrm{p-value})$'] = -np.log10(df_stat['mw_pval_fdr_bh'].astype(float))\n",
    "df_stat.to_excel(f\"{path}/Origin/feats/df_stat.xlsx\", index_label=\"Features\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "sns.set_theme(style='whitegrid')\n",
    "kdeplot = sns.kdeplot(\n",
    "    data=df_stat,\n",
    "    x=r'$ -\\log_{10}(\\mathrm{p-value})$',\n",
    "    color='darkgreen',\n",
    "    linewidth=2,\n",
    "    cut=0,\n",
    "    fill=True,\n",
    "    ax=ax\n",
    ")\n",
    "kdeplot.set_title('Features Distribution Differences')\n",
    "plt.savefig(f\"{path}/Origin/feats/kde_pval.png\", bbox_inches='tight', dpi=200)\n",
    "plt.savefig(f\"{path}/Origin/feats/kde_pval.pdf\", bbox_inches='tight')\n",
    "plt.close(fig)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_top_features = 10\n",
    "top_features = list(df_stat.index[0:n_top_features])\n",
    "df_fig = df.loc[:, top_features + ['Real']].copy()\n",
    "df_fig.loc[df_fig['Real'] == 0, 'Status'] = 'Control'\n",
    "df_fig.loc[df_fig['Real'] == 1, 'Status'] = 'Parkinson'\n",
    "df_fig = df_fig.melt(id_vars=['Status'], value_vars=list(df_stat.index[0:n_top_features]), var_name='CpG', value_name='Methylation')\n",
    "df_fig['CpG'].replace({x: f\"{x}\\npval: {df_stat.at[x, 'mw_pval_fdr_bh']:0.2e}\" for x in top_features}, inplace=True)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 1 * n_top_features))\n",
    "sns.set_theme(style='whitegrid')\n",
    "violin = sns.violinplot(\n",
    "    data=df_fig,\n",
    "    x='Methylation',\n",
    "    y='CpG',\n",
    "    orient='h',\n",
    "    hue='Status',\n",
    "    split=True,\n",
    "    linewidth=1,\n",
    "    palette={'Control': 'dodgerblue', 'Parkinson': 'crimson'},\n",
    "    hue_order=['Control', 'Parkinson'],\n",
    "    cut=0,\n",
    "    inner=\"quart\",\n",
    "    ax=ax\n",
    ")\n",
    "plt.savefig(f\"{path}/Origin/feats/violins.png\", bbox_inches='tight', dpi=200)\n",
    "plt.savefig(f\"{path}/Origin/feats/violins.pdf\", bbox_inches='tight')\n",
    "plt.close(fig)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Probability distribution plot"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_fig = df.loc[:, top_features + ['Prob Parkinson', 'Real']].copy()\n",
    "df_fig.loc[df_fig['Real'] == 0, 'Status'] = 'Control'\n",
    "df_fig.loc[df_fig['Real'] == 1, 'Status'] = 'Parkinson'\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "sns.set_theme(style='whitegrid')\n",
    "kdeplot = sns.kdeplot(\n",
    "    data=df_fig,\n",
    "    x='Prob Parkinson',\n",
    "    hue='Status',\n",
    "    palette={'Control': 'dodgerblue', 'Parkinson': 'crimson'},\n",
    "    hue_order=['Control', 'Parkinson'],\n",
    "    linewidth=2,\n",
    "    cut=0,\n",
    "    fill=True,\n",
    "    ax=ax\n",
    ")\n",
    "plt.savefig(f\"{path}/Origin/kde_proba.png\", bbox_inches='tight', dpi=200)\n",
    "plt.savefig(f\"{path}/Origin/kde_proba.pdf\", bbox_inches='tight')\n",
    "plt.close(fig)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Outliers analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# IQR plots\n",
    "pathlib.Path(f\"{path}/Origin/outliers_iqr\").mkdir(parents=True, exist_ok=True)\n",
    "plot_iqr_outs(df, feats, 'grey', 'Origin', f\"{path}/Origin/outliers_iqr\", is_msno_plots=False)\n",
    "df_fig = df.loc[:, ['Real', 'Pred', 'n_outs_iqr', 'Prob Control', 'Prob Parkinson']].copy()\n",
    "df_fig.loc[df_fig['Real'] == 0, 'Status'] = 'Control'\n",
    "df_fig.loc[df_fig['Real'] == 1, 'Status'] = 'Parkinson'\n",
    "plot_iqr_outs_cls(\n",
    "    df=df_fig,\n",
    "    path=f\"{path}/Origin/outliers_iqr\",\n",
    "    col_class=\"Status\",\n",
    "    col_pred=\"Pred\",\n",
    "    col_real=\"Real\",\n",
    "    cols_prob=['Prob Control', 'Prob Parkinson'],\n",
    "    palette={'Control': 'dodgerblue', 'Parkinson': 'crimson'}\n",
    ")\n",
    "\n",
    "# PyOD plots\n",
    "pathlib.Path(f\"{path}/Origin/outliers_pyod\").mkdir(parents=True, exist_ok=True)\n",
    "plot_pyod_outs(df, pyod_method_names, 'grey', 'Origin', f\"{path}/Origin/outliers_pyod\", n_cols=4)\n",
    "df_fig = df.loc[:, ['Real', 'Pred', 'Detections', 'Prob Control', 'Prob Parkinson']].copy()\n",
    "df_fig.loc[df_fig['Real'] == 0, 'Status'] = 'Control'\n",
    "df_fig.loc[df_fig['Real'] == 1, 'Status'] = 'Parkinson'\n",
    "plot_pyod_outs_cls(\n",
    "    df=df_fig,\n",
    "    path=f\"{path}/Origin/outliers_pyod\",\n",
    "    col_class=\"Status\",\n",
    "    col_pred=\"Pred\",\n",
    "    col_real=\"Real\",\n",
    "    cols_prob=['Prob Control', 'Prob Parkinson'],\n",
    "    palette={'Control': 'dodgerblue', 'Parkinson': 'crimson'}\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Confidence"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "quantiles = torch.tensor([0.05, 0.95])\n",
    "\n",
    "pathlib.Path(f\"{path}/Origin/confidence\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "metrics_pred = get_cls_pred_metrics(num_classes=2)\n",
    "df_metrics = pd.DataFrame(index=list(metrics_pred.keys()))\n",
    "\n",
    "df_ori = df.loc[ids_tst, :].copy()\n",
    "df_ori.loc[df_ori['Real'] == 0, 'Status'] = 'Control'\n",
    "df_ori.loc[df_ori['Real'] == 1, 'Status'] = 'Parkinson'\n",
    "df_ori['Type'] = 'Real'\n",
    "y_real_ori = torch.from_numpy(df_ori.loc[:, \"Real\"].values.astype('int32'))\n",
    "y_pred_ori = torch.from_numpy(df_ori.loc[:, \"Pred\"].values.astype('int32'))\n",
    "\n",
    "for metric_name, metric_pair in metrics_pred.items():\n",
    "    metric = metric_pair[0]\n",
    "    bootstrap = BootStrapper(\n",
    "        metric,\n",
    "        num_bootstraps=200,\n",
    "        sampling_strategy=\"multinomial\",\n",
    "        quantile=quantiles\n",
    "    )\n",
    "    bootstrap.update(y_pred_ori, y_real_ori)\n",
    "    bootstrap_output = bootstrap.compute()\n",
    "    df_metrics.at[metric_name, 'mean'] = bootstrap_output['mean'].detach().cpu().numpy()\n",
    "    df_metrics.at[metric_name, 'std'] = bootstrap_output['std'].detach().cpu().numpy()\n",
    "    df_metrics.at[metric_name, 'q0.05'] = bootstrap_output['quantile'].detach().cpu().numpy()[0]\n",
    "    df_metrics.at[metric_name, 'q0.95'] = bootstrap_output['quantile'].detach().cpu().numpy()[1]\n",
    "df_metrics.to_excel(f\"{path}/Origin/confidence/metrics.xlsx\", index_label='Metrics')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.2 Augmented data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_smps = 10000\n",
    "\n",
    "df_aug_sdv_input = df.loc[:, np.concatenate((['Real'], feats))]\n",
    "metadata = SingleTableMetadata()\n",
    "metadata.detect_from_dataframe(data=df_aug_sdv_input)\n",
    "metadata.update_column('Real', sdtype='categorical')\n",
    "\n",
    "synthesizers = {\n",
    "    'GaussianCopula': GaussianCopulaSynthesizer(metadata),\n",
    "    'CTGANSynthesizer': CTGANSynthesizer(metadata),\n",
    "    'TVAESynthesizer': TVAESynthesizer(metadata),\n",
    "    'CopulaGANSynthesizer': CopulaGANSynthesizer(metadata),\n",
    "    'FAST_ML': SingleTablePreset(metadata, name='FAST_ML'),\n",
    "}\n",
    "\n",
    "for s_name, s in (pbar := tqdm(synthesizers.items())):\n",
    "    pbar.set_description(f\"Processing {s_name}\")\n",
    "    path_curr = f\"{path}/Augmentation/{s_name}\"\n",
    "    pathlib.Path(f\"{path_curr}\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    s.fit(\n",
    "        data=df_aug_sdv_input\n",
    "    )\n",
    "    s.save(\n",
    "        filepath=f\"{path_curr}/synthesizer.pkl\"\n",
    "    )\n",
    "    df_aug_sdv = s.sample(\n",
    "        num_rows=n_smps\n",
    "    )\n",
    "    quality_report = evaluate_quality(\n",
    "        df_aug_sdv_input,\n",
    "        df_aug_sdv,\n",
    "        metadata\n",
    "    )\n",
    "    \n",
    "    q_rep_prop = quality_report.get_properties()\n",
    "    q_rep_prop.set_index('Property', inplace=True)\n",
    "    \n",
    "    df_col_shapes = quality_report.get_details(property_name='Column Shapes')\n",
    "    df_col_shapes.sort_values([\"Score\"], ascending=[False], inplace=True)\n",
    "    df_col_shapes.to_excel(f\"{path_curr}/ColumnShapes.xlsx\", index=False)\n",
    "    \n",
    "    df_col_pair_trends = quality_report.get_details(property_name='Column Pair Trends')\n",
    "    df_col_pair_trends.to_excel(f\"{path_curr}/ColumnPairTrends.xlsx\", index=False)\n",
    "    \n",
    "    model.produce_probabilities = True\n",
    "    y_pred_prob = model(torch.from_numpy(np.float32(df_aug_sdv.loc[:, feats].values))).cpu().detach().numpy()\n",
    "    y_pred = np.argmax(y_pred_prob, 1)\n",
    "    df_aug_sdv[\"Pred\"] = y_pred\n",
    "    df_aug_sdv[\"Prob Control\"] = y_pred_prob[:, 0]\n",
    "    df_aug_sdv[\"Prob Parkinson\"] = y_pred_prob[:, 1]\n",
    "    \n",
    "    for m, drm in dim_red_models.items():\n",
    "        dim_red_res = drm.transform(df_aug_sdv.loc[:, feats].values)\n",
    "        df_aug_sdv.loc[:, dim_red_labels[m][0]] = dim_red_res[:, 0]\n",
    "        df_aug_sdv.loc[:, dim_red_labels[m][1]] = dim_red_res[:, 1]\n",
    "        \n",
    "    add_iqr_outs_to_df(df_aug_sdv, df.loc[ids_trn_val, :], feats)\n",
    "    add_pyod_outs_to_df(df_aug_sdv, pyod_methods, feats)\n",
    "        \n",
    "    df_aug_sdv.to_excel(f\"{path_curr}/df.xlsx\", index_label='sample_id')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Calculate metrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_ori = df.loc[ids_tst, :].copy()\n",
    "df_ori.loc[df_ori['Real'] == 0, 'Status'] = 'Control'\n",
    "df_ori.loc[df_ori['Real'] == 1, 'Status'] = 'Parkinson'\n",
    "df_ori['Type'] = 'Real'\n",
    "\n",
    "for s_name in (pbar := tqdm(colors_augs)):\n",
    "    pbar.set_description(f\"Processing {s_name}\")\n",
    "    path_curr = f\"{path}/Augmentation/{s_name}\"\n",
    "\n",
    "    df_aug = pd.read_excel(f\"{path_curr}/df.xlsx\", index_col='sample_id')\n",
    "\n",
    "    metrics_pred = get_cls_pred_metrics(num_classes=2)\n",
    "    metrics_prob = get_cls_prob_metrics(num_classes=2)\n",
    "    df_metrics = pd.DataFrame(index=list(metrics_pred.keys()) + list(metrics_prob.keys()))\n",
    "    y_real_ori = torch.from_numpy(df_ori.loc[:, \"Real\"].values.astype('int32'))\n",
    "    y_pred_ori = torch.from_numpy(df_ori.loc[:, \"Pred\"].values.astype('int32'))\n",
    "    y_prob_ori = torch.from_numpy(df_ori.loc[:, [\"Prob Control\", \"Prob Parkinson\"]].values)\n",
    "    \n",
    "    y_real_aug = torch.from_numpy(df_aug.loc[:, \"Real\"].values.astype('int32'))\n",
    "    y_pred_aug = torch.from_numpy(df_aug.loc[:, \"Pred\"].values.astype('int32'))\n",
    "    y_prob_aug = torch.from_numpy(df_aug.loc[:, [\"Prob Control\", \"Prob Parkinson\"]].values)\n",
    "    for m in metrics_pred:\n",
    "        m_val = float(metrics_pred[m][0](y_pred_aug, y_real_aug).numpy())\n",
    "        metrics_pred[m][0].reset()\n",
    "        df_metrics.at[m, s_name] = m_val\n",
    "        m_val = float(metrics_pred[m][0](y_pred_ori, y_real_ori).numpy())\n",
    "        df_metrics.at[m, 'Origin'] = m_val\n",
    "        metrics_pred[m][0].reset()\n",
    "    for m in metrics_prob:\n",
    "        m_val = 0\n",
    "        try:\n",
    "            m_val = float(metrics_prob[m][0](y_prob_aug, y_real_aug).numpy())\n",
    "        except ValueError:\n",
    "            pass\n",
    "        metrics_prob[m][0].reset()\n",
    "        df_metrics.at[m, s_name] = m_val\n",
    "        m_val = 0\n",
    "        try:\n",
    "            m_val = float(metrics_prob[m][0](y_prob_ori, y_real_ori).numpy())\n",
    "        except ValueError:\n",
    "            pass\n",
    "        metrics_prob[m][0].reset()\n",
    "        df_metrics.at[m, 'Origin'] = m_val\n",
    "    df_metrics.to_excel(f\"{path_curr}/metrics.xlsx\", index_label='Metrics')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot metrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_metrics = pd.DataFrame(index=['Real'] + list(colors_augs.keys()), columns=['Accuracy', 'AUROC'])\n",
    "metrics_dict = {'Accuracy': 'accuracy_weighted', 'AUROC': 'auroc_weighted'}\n",
    "for s_name in (pbar := tqdm(colors_augs)):\n",
    "    pbar.set_description(f\"Processing {s_name}\")\n",
    "    path_curr = f\"{path}/Augmentation/{s_name}\"\n",
    "    \n",
    "    df_metrics_curr = pd.read_excel(f\"{path_curr}/metrics.xlsx\", index_col=0)\n",
    "    for m in metrics_dict:\n",
    "        df_metrics.at[s_name, m] = df_metrics_curr.at[metrics_dict[m], s_name]\n",
    "        if s_name == 'FAST_ML':\n",
    "            df_metrics.at['Real', m] = df_metrics_curr.at[metrics_dict[m], 'Origin']\n",
    "df_metrics.to_excel(f\"{path}/Augmentation/metrics.xlsx\", index_label='Metrics')\n",
    "\n",
    "df_metrics['Type'] = df_metrics.index\n",
    "barplots = {}\n",
    "for m in metrics_dict:\n",
    "    barplots[m] = pw.Brick(figsize=(3.5, 2.0))\n",
    "    sns.set_theme(style='whitegrid')\n",
    "    barplot = sns.barplot(\n",
    "        data=df_metrics,\n",
    "        y='Type',\n",
    "        hue='Type',\n",
    "        x=m,\n",
    "        edgecolor='black',\n",
    "        palette={'Real': 'grey'} | colors_augs,\n",
    "        dodge=False,\n",
    "        ax=barplots[m],\n",
    "    )\n",
    "    barplots[m].get_legend().remove()\n",
    "    for container in barplots[m].containers:\n",
    "        barplots[m].bar_label(container, fmt='%.2f')\n",
    "pw_fig = barplots['Accuracy'] | barplots['AUROC']\n",
    "pw_fig.savefig(f\"{path}/Augmentation/metrics.png\", bbox_inches='tight', dpi=200)\n",
    "pw_fig.savefig(f\"{path}/Augmentation/metrics.pdf\", bbox_inches='tight')\n",
    "pw.clear()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot in reduced dimension"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_ori = df.loc[ids_tst, :].copy()\n",
    "df_ori.loc[df_ori['Real'] == 0, 'Status'] = 'Control'\n",
    "df_ori.loc[df_ori['Real'] == 1, 'Status'] = 'Parkinson'\n",
    "df_ori['Type'] = 'Real'\n",
    "\n",
    "for s_name in (pbar := tqdm(colors_augs)):\n",
    "    pbar.set_description(f\"Processing {s_name}\")\n",
    "    path_curr = f\"{path}/Augmentation/{s_name}\"\n",
    "    \n",
    "    df_aug = pd.read_excel(f\"{path_curr}/df.xlsx\", index_col='sample_id')\n",
    "    df_ori_aug = pd.concat([df_ori, df_aug])\n",
    "    for m in dim_red_labels:\n",
    "        pathlib.Path(f\"{path_curr}/dim_red\").mkdir(parents=True, exist_ok=True)\n",
    "        n_bins = 20\n",
    "        x_xtd = (df_aug[dim_red_labels[m][0]].max() - df_aug[dim_red_labels[m][0]].min()) * 0.075\n",
    "        x_min = df_aug[dim_red_labels[m][0]].min() - x_xtd\n",
    "        x_max = df_aug[dim_red_labels[m][0]].max() + x_xtd\n",
    "        x_shift = (x_max - x_min) / n_bins\n",
    "        x_bin_centers = np.linspace(\n",
    "            start=x_min + 0.5 * x_shift,\n",
    "            stop=x_max - 0.5 * x_shift,\n",
    "            num=n_bins\n",
    "        )\n",
    "        y_xtd = (df_aug[dim_red_labels[m][1]].max() - df_aug[dim_red_labels[m][1]].min()) * 0.075\n",
    "        y_min = df_aug[dim_red_labels[m][1]].min() - y_xtd\n",
    "        y_max = df_aug[dim_red_labels[m][1]].max() + y_xtd\n",
    "        y_shift = (y_max - y_min) / n_bins\n",
    "        y_bin_centers = np.linspace(\n",
    "            start=y_min + 0.5 * y_shift,\n",
    "            stop=y_max - 0.5 * y_shift,\n",
    "            num=n_bins\n",
    "        )\n",
    "        df_heatmap_sum = pd.DataFrame(index=x_bin_centers, columns=y_bin_centers, data=np.zeros((n_bins, n_bins)))\n",
    "        df_heatmap_cnt = pd.DataFrame(index=x_bin_centers, columns=y_bin_centers, data=np.zeros((n_bins, n_bins)))\n",
    "        xs = df_aug.loc[:, dim_red_labels[m][0]].values\n",
    "        xs_ids = np.floor((xs - x_min) / (x_shift + 1e-10)).astype(int)\n",
    "        ys = df_aug.loc[:, dim_red_labels[m][1]].values\n",
    "        ys_ids = np.floor((ys - y_min) / (y_shift + 1e-10)).astype(int)\n",
    "        zs = df_aug.loc[:, \"Prob Parkinson\"].values\n",
    "        for d_id in range(len(xs_ids)):\n",
    "            df_heatmap_sum.iat[xs_ids[d_id], ys_ids[d_id]] += zs[d_id]\n",
    "            df_heatmap_cnt.iat[xs_ids[d_id], ys_ids[d_id]] += 1\n",
    "        df_heatmap = pd.DataFrame(data=df_heatmap_sum.values / df_heatmap_cnt.values, columns=df_heatmap_sum.columns, index=df_heatmap_sum.index)\n",
    "        df_heatmap.to_excel(f\"{path_curr}/dim_red/{m}_heatmap.xlsx\")\n",
    "        \n",
    "        norm = plt.Normalize(df_ori_aug[\"Prob Parkinson\"].min(), df_ori_aug[\"Prob Parkinson\"].max())\n",
    "        sm = plt.cm.ScalarMappable(cmap='seismic', norm=norm)\n",
    "        sm.set_array([])\n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "        sns.set_theme(style='whitegrid')\n",
    "\n",
    "        ax.imshow(\n",
    "            X=df_heatmap.transpose().iloc[::-1].values,\n",
    "            extent=[x_min, x_max, y_min, y_max],\n",
    "            vmin=df_ori_aug[\"Prob Parkinson\"].min(),\n",
    "            vmax=df_ori_aug[\"Prob Parkinson\"].max(),\n",
    "            aspect=x_shift/y_shift,\n",
    "            cmap=\"seismic\",\n",
    "            alpha=0.8\n",
    "        )\n",
    "        \n",
    "        scatter_colors = {sample: colors.rgb2hex(sm.to_rgba(row[\"Prob Parkinson\"])) for sample, row in df.iterrows()}\n",
    "        scatter = sns.scatterplot(\n",
    "            data=df.loc[ids_tst, :],\n",
    "            x=dim_red_labels[m][0],\n",
    "            y=dim_red_labels[m][1],\n",
    "            palette=scatter_colors,\n",
    "            hue=df.loc[ids_tst, :].index,\n",
    "            linewidth=0.2,\n",
    "            alpha=0.75,\n",
    "            edgecolor=\"cyan\",\n",
    "            marker='o',\n",
    "            s=15,\n",
    "            ax=ax\n",
    "        )\n",
    "        scatter.get_legend().remove()\n",
    "        fig.colorbar(sm, label=\"Prob Parkinson\")\n",
    "        plt.title(f'{s_name}', y=1.2, fontsize = 14)\n",
    "        \n",
    "        legend_handles = [\n",
    "            mlines.Line2D([], [], marker='o', linestyle='None', markeredgecolor='k', markerfacecolor='lightgrey', markersize=10, label='Real'),\n",
    "            mlines.Line2D([], [], marker='s', linestyle='None', markeredgewidth=0, markerfacecolor='lightgrey', markersize=10, label='Synthetic')\n",
    "        ]\n",
    "        plt.legend(handles=legend_handles, title=\"Samples\", bbox_to_anchor=(0, 1.02, 1, 0.2), loc=\"lower left\", borderaxespad=0, mode=\"expand\", ncol=2, frameon=False)\n",
    "        \n",
    "        plt.savefig(f\"{path_curr}/dim_red/{m}.png\", bbox_inches='tight', dpi=200)\n",
    "        plt.savefig(f\"{path_curr}/dim_red/{m}.pdf\", bbox_inches='tight')\n",
    "        plt.close(fig)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot features differences"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Verison 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_ori = df.loc[ids_tst, :].copy()\n",
    "df_ori.loc[df_ori['Real'] == 0, 'Status'] = 'Control'\n",
    "df_ori.loc[df_ori['Real'] == 1, 'Status'] = 'Parkinson'\n",
    "df_ori['Type'] = 'Real'\n",
    "for s_name in (pbar := tqdm(colors_augs)):\n",
    "    pbar.set_description(f\"Processing {s_name}\")\n",
    "    path_curr = f\"{path}/Augmentation/{s_name}\"\n",
    "    pathlib.Path(f\"{path_curr}/feats\").mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    df_aug = pd.read_excel(f\"{path_curr}/df.xlsx\", index_col='sample_id')\n",
    "    df_aug.loc[df_aug['Real'] == 0, 'Status'] = 'Control'\n",
    "    df_aug.loc[df_aug['Real'] == 1, 'Status'] = 'Parkinson'\n",
    "    df_aug['Type'] = s_name\n",
    "    df_ori_aug = pd.concat([df_ori, df_aug])\n",
    "    \n",
    "    countplots = {}\n",
    "    kdeplots = {}\n",
    "    for cls in ['Control', 'Parkinson']:\n",
    "        countplots[cls] = pw.Brick(figsize=(3, 1))\n",
    "        sns.set_theme(style='whitegrid')\n",
    "        countplot = sns.countplot(\n",
    "            data=df_ori_aug.loc[df_ori_aug['Status'] == cls, :],\n",
    "            y='Type',\n",
    "            edgecolor='black',\n",
    "            palette={'Real': 'grey'} | colors_augs,\n",
    "            orient='h',\n",
    "            order=['Real', s_name],\n",
    "            ax=countplots[cls]\n",
    "        )\n",
    "        countplots[cls].bar_label(countplot.containers[0])\n",
    "        countplots[cls].set_xlabel(\"Count\")\n",
    "        countplots[cls].set_title(f\"{cls} samples\")\n",
    "        \n",
    "        kdeplots[cls] = pw.Brick(figsize=(4, 2))\n",
    "        sns.set_theme(style='whitegrid')\n",
    "        kde = sns.kdeplot(\n",
    "            data=df_ori_aug.loc[df_ori_aug['Status'] == cls, :],\n",
    "            x=f\"Prob Parkinson\",\n",
    "            hue='Type',\n",
    "            linewidth=2,\n",
    "            palette={'Real': 'grey'} | colors_augs,\n",
    "            hue_order=['Real', s_name],\n",
    "            fill=True,\n",
    "            common_true=False,\n",
    "            cut=0,\n",
    "            ax=kdeplots[cls]\n",
    "        )\n",
    "        sns.move_legend(kdeplots[cls], \"upper center\")\n",
    "        kdeplots[cls].set_title(f\"{cls} samples\")\n",
    "\n",
    "    \n",
    "    df_stat = pd.DataFrame(index=feats, columns=['mw_pval', 'mw_pval_fdr_bh'])\n",
    "    for f in feats:\n",
    "        _, df_stat.at[f, 'mw_pval'] = mannwhitneyu(\n",
    "            df_ori_aug.loc[df_ori_aug['Type'] == 'Real', f].values,\n",
    "            df_ori_aug.loc[df_ori_aug['Type'] == s_name, f].values,\n",
    "            alternative='two-sided'\n",
    "        )\n",
    "    _, df_stat.loc[:, 'mw_pval_fdr_bh'], _, _ = multipletests(df_stat.loc[:, \"mw_pval\"], 0.05, method='fdr_bh')\n",
    "    df_stat.sort_values(['mw_pval_fdr_bh'], ascending=[True], inplace=True)\n",
    "    df_stat[r'$ -\\log_{10}(\\mathrm{p-value})$'] = -np.log10(df_stat['mw_pval_fdr_bh'].astype(float))\n",
    "    df_stat.to_excel(f\"{path_curr}/feats/df_stat.xlsx\", index_label=\"Features\")\n",
    "    \n",
    "    brick_kde_pvals = pw.Brick(figsize=(6, 1.75))\n",
    "    sns.set_theme(style='whitegrid')\n",
    "    kdeplot = sns.kdeplot(\n",
    "        data=df_stat,\n",
    "        x=r'$ -\\log_{10}(\\mathrm{p-value})$',\n",
    "        color='darkgreen',\n",
    "        linewidth=2,\n",
    "        cut=0,\n",
    "        fill=True,\n",
    "        ax=brick_kde_pvals\n",
    "    )\n",
    "    brick_kde_pvals.set_title('Features Distribution Differences')\n",
    "    \n",
    "    n_top_features = 5\n",
    "    top_features = list(df_stat.index[0:n_top_features])\n",
    "    df_fig = df_ori_aug.loc[:, top_features + ['Type']].copy()\n",
    "    df_fig = df_fig.melt(\n",
    "        id_vars=['Type'],\n",
    "        value_vars=list(df_stat.index[0:n_top_features]),\n",
    "        var_name='CpG',\n",
    "        value_name='Methylation')\n",
    "    df_fig['CpG'].replace({x: f\"{x}\\npval: {df_stat.at[x, 'mw_pval_fdr_bh']:0.2e}\" for x in top_features}, inplace=True)\n",
    "    \n",
    "    brick_feats_violins = pw.Brick(figsize=(6, 3))\n",
    "    sns.set_theme(style='whitegrid')\n",
    "    violin = sns.violinplot(\n",
    "        data=df_fig,\n",
    "        x='Methylation',\n",
    "        y='CpG',\n",
    "        orient='h',\n",
    "        hue='Type',\n",
    "        split=True,\n",
    "        linewidth=1,\n",
    "        palette={'Real': 'grey'} | colors_augs,\n",
    "        hue_order=['Real', s_name],\n",
    "        cut=0,\n",
    "        inner=\"quart\",\n",
    "        ax=brick_feats_violins\n",
    "    )\n",
    "\n",
    "    pw_fig = (countplots['Control'] | countplots['Parkinson']) / (kdeplots['Control'] | kdeplots['Parkinson']) / brick_kde_pvals / brick_feats_violins\n",
    "    pw_fig.savefig(f\"{path_curr}/feats/fig.png\", bbox_inches='tight', dpi=200)\n",
    "    pw_fig.savefig(f\"{path_curr}/feats/fig.pdf\", bbox_inches='tight')\n",
    "    pw.clear()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Version 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_ori = df.loc[ids_tst, :].copy()\n",
    "df_ori.loc[df_ori['Real'] == 0, 'Status'] = 'Control'\n",
    "df_ori.loc[df_ori['Real'] == 1, 'Status'] = 'Parkinson'\n",
    "df_ori['Type'] = 'Real'\n",
    "for s_name in (pbar := tqdm(colors_augs)):\n",
    "    pbar.set_description(f\"Processing {s_name}\")\n",
    "    path_curr = f\"{path}/Augmentation/{s_name}\"\n",
    "    pathlib.Path(f\"{path_curr}/feats\").mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    df_aug = pd.read_excel(f\"{path_curr}/df.xlsx\", index_col='sample_id')\n",
    "    df_aug.loc[df_aug['Real'] == 0, 'Status'] = 'Control'\n",
    "    df_aug.loc[df_aug['Real'] == 1, 'Status'] = 'Parkinson'\n",
    "    df_aug['Type'] = s_name\n",
    "    df_ori_aug = pd.concat([df_ori, df_aug])\n",
    "    \n",
    "    countplots = {}\n",
    "    kdeplots = {}\n",
    "    for cls in ['Control', 'Parkinson']:\n",
    "        countplots[cls] = pw.Brick(figsize=(3, 1))\n",
    "        sns.set_theme(style='whitegrid')\n",
    "        countplot = sns.countplot(\n",
    "            data=df_ori_aug.loc[df_ori_aug['Status'] == cls, :],\n",
    "            y='Type',\n",
    "            edgecolor='black',\n",
    "            palette={'Real': 'grey'} | colors_augs,\n",
    "            orient='h',\n",
    "            order=['Real', s_name],\n",
    "            ax=countplots[cls]\n",
    "        )\n",
    "        countplots[cls].bar_label(countplot.containers[0])\n",
    "        countplots[cls].set_xlabel(\"Count\")\n",
    "        countplots[cls].set_title(f\"{cls} samples\")\n",
    "        \n",
    "        kdeplots[cls] = pw.Brick(figsize=(4, 2))\n",
    "        sns.set_theme(style='whitegrid')\n",
    "        kde = sns.kdeplot(\n",
    "            data=df_ori_aug.loc[df_ori_aug['Status'] == cls, :],\n",
    "            x=f\"Prob Parkinson\",\n",
    "            hue='Type',\n",
    "            linewidth=2,\n",
    "            palette={'Real': 'grey'} | colors_augs,\n",
    "            hue_order=['Real', s_name],\n",
    "            fill=True,\n",
    "            common_norm=False,\n",
    "            cut=0,\n",
    "            ax=kdeplots[cls]\n",
    "        )\n",
    "        sns.move_legend(kdeplots[cls], \"upper center\")\n",
    "        kdeplots[cls].set_title(f\"{cls} samples\")\n",
    "\n",
    "    df_stat = pd.read_excel(f\"{path_curr}/ColumnShapes.xlsx\", index_col=0)\n",
    "    df_stat = df_stat.loc[df_stat['Metric'] == \"KSComplement\", :]\n",
    "    df_stat.rename(columns={'Score': \"KSComplement\"}, inplace=True)\n",
    "    \n",
    "    brick_scores = pw.Brick(figsize=(7.5, 1.75))\n",
    "    sns.set_theme(style='whitegrid')\n",
    "    kdeplot = sns.kdeplot(\n",
    "        data=df_stat,\n",
    "        x='KSComplement',\n",
    "        color='darkgreen',\n",
    "        linewidth=2,\n",
    "        cut=0,\n",
    "        fill=True,\n",
    "        ax=brick_scores\n",
    "    )\n",
    "    brick_scores.set_title('Features Distribution Differences')\n",
    "    \n",
    "    n_features = 5\n",
    "    feats_dict = {\n",
    "        'Top Features': list(df_stat.index[0:n_top_features]),\n",
    "        'Bottom Features': list(df_stat.index[-n_top_features-1:-1][::-1])\n",
    "    }\n",
    "    brick_feats_violins = {}\n",
    "    for feats_set in feats_dict:\n",
    "        df_fig = df_ori_aug.loc[:, feats_dict[feats_set] + ['Type']].copy()\n",
    "        df_fig = df_fig.melt(\n",
    "            id_vars=['Type'],\n",
    "            value_vars=feats_dict[feats_set],\n",
    "            var_name='CpG',\n",
    "            value_name='Methylation')\n",
    "        df_fig['CpG'].replace({x: f\"{x}\\nScore: {df_stat.at[x, 'KSComplement']:0.2f}\" for x in feats_dict[feats_set]}, inplace=True)\n",
    "        \n",
    "        brick_feats_violins[feats_set] = pw.Brick(figsize=(2.5, 3))\n",
    "        sns.set_theme(style='whitegrid')\n",
    "        violin = sns.violinplot(\n",
    "            data=df_fig,\n",
    "            x='Methylation',\n",
    "            y='CpG',\n",
    "            orient='h',\n",
    "            hue='Type',\n",
    "            split=True,\n",
    "            linewidth=1,\n",
    "            palette={'Real': 'grey'} | colors_augs,\n",
    "            hue_order=['Real', s_name],\n",
    "            cut=0,\n",
    "            inner=\"quart\",\n",
    "            ax=brick_feats_violins[feats_set]\n",
    "        )\n",
    "        brick_feats_violins[feats_set].set_title(feats_set)\n",
    "\n",
    "    pw_fig = ((countplots['Control'] | countplots['Parkinson'])\n",
    "              / (kdeplots['Control'] | kdeplots['Parkinson'])\n",
    "              / brick_scores\n",
    "              / (brick_feats_violins['Top Features'] | brick_feats_violins['Bottom Features']))\n",
    "    pw_fig.savefig(f\"{path_curr}/feats/fig_v2.png\", bbox_inches='tight', dpi=200)\n",
    "    pw_fig.savefig(f\"{path_curr}/feats/fig_v2.pdf\", bbox_inches='tight')\n",
    "    pw.clear()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Outliers analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for s_name in (pbar := tqdm(colors_augs)):\n",
    "    pbar.set_description(f\"Processing {s_name}\")\n",
    "    path_curr = f\"{path}/Augmentation/{s_name}\"\n",
    "    \n",
    "    df_aug = pd.read_excel(f\"{path_curr}/df.xlsx\", index_col='sample_id')\n",
    "\n",
    "    # IQR outliers\n",
    "    pathlib.Path(f\"{path}/Augmentation/{s_name}/outliers_iqr\").mkdir(parents=True, exist_ok=True)\n",
    "    plot_iqr_outs(df_aug, feats, 'grey', s_name, f\"{path}/Augmentation/{s_name}/outliers_iqr\", is_msno_plots=False)\n",
    "    df_fig = df_aug.loc[:, ['Real', 'Pred', 'n_outs_iqr', 'Prob Control', 'Prob Parkinson']].copy()\n",
    "    df_fig.loc[df_fig['Real'] == 0, 'Status'] = 'Control'\n",
    "    df_fig.loc[df_fig['Real'] == 1, 'Status'] = 'Parkinson'\n",
    "    plot_iqr_outs_cls(\n",
    "        df=df_fig,\n",
    "        path=f\"{path}/Augmentation/{s_name}/outliers_iqr\",\n",
    "        col_class=\"Status\",\n",
    "        col_pred=\"Pred\",\n",
    "        col_real=\"Real\",\n",
    "        cols_prob=['Prob Control', 'Prob Parkinson'],\n",
    "        palette={'Control': 'dodgerblue', 'Parkinson': 'crimson'}\n",
    "    )\n",
    "    \n",
    "    # PyOD plots\n",
    "    pathlib.Path(f\"{path}/Augmentation/{s_name}/outliers_pyod\").mkdir(parents=True, exist_ok=True)\n",
    "    plot_pyod_outs(df_aug, pyod_method_names, 'grey', 'Origin', f\"{path}/Augmentation/{s_name}/outliers_pyod\", n_cols=4)\n",
    "    df_fig = df_aug.loc[:, ['Real', 'Pred', 'Detections', 'Prob Control', 'Prob Parkinson']].copy()\n",
    "    df_fig.loc[df_fig['Real'] == 0, 'Status'] = 'Control'\n",
    "    df_fig.loc[df_fig['Real'] == 1, 'Status'] = 'Parkinson'\n",
    "    plot_pyod_outs_cls(\n",
    "        df=df_fig,\n",
    "        path=f\"{path}/Augmentation/{s_name}/outliers_pyod\",\n",
    "        col_class=\"Status\",\n",
    "        col_pred=\"Pred\",\n",
    "        col_real=\"Real\",\n",
    "        cols_prob=['Prob Control', 'Prob Parkinson'],\n",
    "        palette={'Control': 'dodgerblue', 'Parkinson': 'crimson'}\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Confidence"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "quantiles = torch.tensor([0.05, 0.95])\n",
    "\n",
    "for s_name in (pbar := tqdm(colors_augs)):\n",
    "    pbar.set_description(f\"Processing {s_name}\")\n",
    "    path_curr = f\"{path}/Augmentation/{s_name}\"\n",
    "    \n",
    "    df_aug = pd.read_excel(f\"{path_curr}/df.xlsx\", index_col='sample_id')\n",
    "    df_aug.loc[df_aug['Real'] == 0, 'Status'] = 'Control'\n",
    "    df_aug.loc[df_aug['Real'] == 1, 'Status'] = 'Parkinson'\n",
    "    \n",
    "    pathlib.Path(f\"{path_curr}/confidence\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    metrics_pred = get_cls_pred_metrics(num_classes=2)\n",
    "    df_metrics = pd.DataFrame(index=list(metrics_pred.keys()))\n",
    "    y_real = torch.from_numpy(df_aug.loc[:, \"Real\"].values.astype('int32'))\n",
    "    y_pred = torch.from_numpy(df_aug.loc[:, \"Pred\"].values.astype('int32'))\n",
    "    \n",
    "    for metric_name, metric_pair in metrics_pred.items():\n",
    "        metric = metric_pair[0]\n",
    "        bootstrap = BootStrapper(\n",
    "            metric,\n",
    "            num_bootstraps=200,\n",
    "            sampling_strategy=\"multinomial\",\n",
    "            quantile=quantiles\n",
    "        )\n",
    "        bootstrap.update(y_pred, y_real)\n",
    "        bootstrap_output = bootstrap.compute()\n",
    "        df_metrics.at[metric_name, 'mean'] = bootstrap_output['mean'].detach().cpu().numpy()\n",
    "        df_metrics.at[metric_name, 'std'] = bootstrap_output['std'].detach().cpu().numpy()\n",
    "        df_metrics.at[metric_name, 'q0.05'] = bootstrap_output['quantile'].detach().cpu().numpy()[0]\n",
    "        df_metrics.at[metric_name, 'q0.95'] = bootstrap_output['quantile'].detach().cpu().numpy()[1]\n",
    "    df_metrics.to_excel(f\"{path_curr}/confidence/metrics.xlsx\", index_label='Metrics')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "metrics_names = {\n",
    "    'accuracy_weighted': 'Accuracy',\n",
    "}\n",
    "quantiles = [0.05, 0.95]\n",
    "\n",
    "df_conf = pd.DataFrame(index=['Real'] + list(colors_augs.keys()), columns=[f\"{m}_{q}\" for m in metrics_names for q in quantiles])\n",
    "\n",
    "df_metrics = pd.read_excel(f\"{path}/Origin/confidence/metrics.xlsx\", index_col='Metrics')\n",
    "for m in metrics_names:\n",
    "    for q in quantiles:\n",
    "        df_conf.at[\"Real\", f\"{m}_{q}\"] = df_metrics.at[m, f\"q{q}\"]\n",
    "\n",
    "for s_name in (pbar := tqdm(colors_augs)):\n",
    "    pbar.set_description(f\"Processing {s_name}\")\n",
    "    \n",
    "    df_metrics = pd.read_excel(f\"{path}/Augmentation/{s_name}/confidence/metrics.xlsx\", index_col='Metrics')\n",
    "    for m in metrics_names:\n",
    "        for q in quantiles:\n",
    "            df_conf.at[s_name, f\"{m}_{q}\"] = df_metrics.at[m, f\"q{q}\"]\n",
    "\n",
    "colors_dict = {'Real': 'grey'} | colors_augs\n",
    "for m in metrics_names:\n",
    "    df_fig = df_conf.loc[:, [f\"{m}_{q}\" for q in quantiles]].copy()\n",
    "    df_fig['Type'] = df_fig.index\n",
    "    df_fig = df_fig.melt(id_vars=['Type'], value_name=metrics_names[m])\n",
    "    fig, ax = plt.subplots(figsize=(3, 2))\n",
    "    sns.set_theme(style='ticks') \n",
    "    scatter = sns.scatterplot(\n",
    "        data=df_fig,\n",
    "        x=metrics_names[m],\n",
    "        y='Type',\n",
    "        hue='Type',\n",
    "        palette=colors_dict,\n",
    "        hue_order=list(colors_dict.keys()),\n",
    "        linewidth=0.2,\n",
    "        alpha=0.95,\n",
    "        edgecolor=\"black\",\n",
    "        s=16,\n",
    "        ax=ax\n",
    "    )\n",
    "    scatter.get_legend().set_visible(False)\n",
    "    line = sns.lineplot(\n",
    "        data=df_fig,\n",
    "        x=metrics_names[m],\n",
    "        y='Type',\n",
    "        hue='Type',\n",
    "        palette=colors_dict,\n",
    "        hue_order=list(colors_dict.keys()),\n",
    "        linewidth=2,\n",
    "        ax=ax\n",
    "    )\n",
    "    line.get_legend().set_visible(False)\n",
    "    ax.set_xlabel(f\"Confidence Intervals for {metrics_names[m]}\")\n",
    "    plt.savefig(f\"{path}/Augmentation/confidence_{m}.png\", bbox_inches='tight', dpi=400)\n",
    "    plt.savefig(f\"{path}/Augmentation/confidence_{m}.pdf\", bbox_inches='tight')\n",
    "    plt.close(fig)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2.3. Attacks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ids_atk = ids_tst\n",
    "\n",
    "art_classifier = PyTorchClassifier(\n",
    "    model=model,\n",
    "    loss=model.loss_fn,\n",
    "    input_shape=(len(feats),),\n",
    "    nb_classes=2,\n",
    "    optimizer=torch.optim.Adam(\n",
    "        params=model.parameters(),\n",
    "        lr=model.hparams.optimizer_lr,\n",
    "        weight_decay=model.hparams.optimizer_weight_decay\n",
    "    ),\n",
    "    use_amp=False,\n",
    "    opt_level=\"O1\",\n",
    "    loss_scale=\"dynamic\",\n",
    "    channels_first=True,\n",
    "    clip_values=(0.0, 1.0),\n",
    "    preprocessing_defences=None,\n",
    "    postprocessing_defences=None,\n",
    "    preprocessing=(0.0, 1.0),\n",
    "    device_type=\"cpu\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Eps-depended attacks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "epsilons = sorted(list(set.union(\n",
    "    set(np.linspace(0.1, 1.0, 10)), \n",
    "    set(np.linspace(0.01, 0.1, 10)),\n",
    "    set(np.linspace(0.001, 0.01, 10))\n",
    ")))\n",
    "df_eps = pd.DataFrame(index=epsilons)\n",
    "\n",
    "for eps_raw in epsilons:\n",
    "\n",
    "    eps = np.array([eps_raw * iqr(df.loc[ids_atk, feat].values) for feat in feats])\n",
    "    eps_step = np.array([0.2 * eps_raw * iqr(df.loc[ids_atk, feat].values) for feat in feats])\n",
    "\n",
    "    attacks = {\n",
    "        'MomentumIterative': MomentumIterativeMethod(\n",
    "            estimator=art_classifier,\n",
    "            norm=np.inf,\n",
    "            eps=eps,\n",
    "            eps_step=eps_step,\n",
    "            decay=0.1,\n",
    "            max_iter=100,\n",
    "            targeted=False,\n",
    "            batch_size=512,\n",
    "            verbose=True\n",
    "        ),\n",
    "        'BasicIterative': BasicIterativeMethod(\n",
    "            estimator=art_classifier,\n",
    "            eps=eps,\n",
    "            eps_step=eps_step,\n",
    "            max_iter=100,\n",
    "            targeted=False,\n",
    "            batch_size=512,\n",
    "            verbose=True\n",
    "        ),\n",
    "        'ProjectedGradientDescent': ProjectedGradientDescentNumpy(\n",
    "            estimator=art_classifier,\n",
    "            norm=np.inf,\n",
    "            eps=eps,\n",
    "            eps_step=eps_step,\n",
    "            decay=None,\n",
    "            max_iter=100,\n",
    "            targeted=False,\n",
    "            num_random_init=0,\n",
    "            batch_size=512,\n",
    "            random_eps=False,\n",
    "            summary_writer=False,\n",
    "            verbose=True\n",
    "        ),\n",
    "        'FastGradient': FastGradientMethod(\n",
    "            estimator=art_classifier,\n",
    "            norm=np.inf,\n",
    "            eps=eps,\n",
    "            eps_step=eps_step,\n",
    "            targeted=False,\n",
    "            num_random_init=0,\n",
    "            batch_size=512,\n",
    "            minimal=False,\n",
    "            summary_writer=False,\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    for attack_name, attack in attacks.items():\n",
    "        path_curr = f\"{path}/Evasion/{attack_name}/eps_{eps_raw:0.4f}\"\n",
    "        pathlib.Path(f\"{path_curr}\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        X_adv = attack.generate(np.float32(df.loc[ids_atk, feats].values))\n",
    "        \n",
    "        df_adv = df.loc[ids_atk, ['Real']].copy()\n",
    "        df_adv.loc[ids_atk, feats] = X_adv\n",
    "        model.produce_probabilities = True\n",
    "        y_pred_prob = model(torch.from_numpy(np.float32(df_adv.loc[ids_atk, feats].values))).cpu().detach().numpy()\n",
    "        y_pred = np.argmax(y_pred_prob, 1)\n",
    "        df_adv[\"Pred\"] = y_pred\n",
    "        df_adv[\"Prob Control\"] = y_pred_prob[:, 0]\n",
    "        df_adv[\"Prob Parkinson\"] = y_pred_prob[:, 1]\n",
    "        df_adv[\"Eps\"] = eps_raw\n",
    "        df_adv[\"Data\"] = attack_name\n",
    "        \n",
    "        for m, drm in dim_red_models.items():\n",
    "            dim_red_res = drm.transform(df_adv.loc[:, feats].values)\n",
    "            df_adv.loc[:, dim_red_labels[m][0]] = dim_red_res[:, 0]\n",
    "            df_adv.loc[:, dim_red_labels[m][1]] = dim_red_res[:, 1]\n",
    "            \n",
    "        add_iqr_outs_to_df(df_adv, df.loc[ids_trn_val, :], feats)\n",
    "        add_pyod_outs_to_df(df_adv, pyod_methods, feats)\n",
    "            \n",
    "        df_adv.to_excel(f\"{path_curr}/df.xlsx\", index_label='sample_id')\n",
    "\n",
    "        metrics_pred = get_cls_pred_metrics(num_classes=2)\n",
    "        metrics_prob = get_cls_prob_metrics(num_classes=2)\n",
    "        df_metrics = pd.DataFrame(index=list(metrics_pred.keys()) + list(metrics_prob.keys()))\n",
    "        y_real = torch.from_numpy(df_adv.loc[ids_atk, \"Real\"].values.astype('int32'))\n",
    "        y_pred_atk = torch.from_numpy(df_adv.loc[ids_atk, \"Pred\"].values.astype('int32'))\n",
    "        y_pred_ori = torch.from_numpy(df.loc[ids_atk, \"Pred\"].values.astype('int32'))\n",
    "        y_prob_atk = torch.from_numpy(df_adv.loc[ids_atk, [\"Prob Control\", \"Prob Parkinson\"]].values)\n",
    "        y_prob_ori = torch.from_numpy(df.loc[ids_atk, [\"Prob Control\", \"Prob Parkinson\"]].values)\n",
    "        for m in metrics_pred:\n",
    "            m_val = float(metrics_pred[m][0](y_pred_atk, y_real).numpy())\n",
    "            metrics_pred[m][0].reset()\n",
    "            df_metrics.at[m, 'Attack'] = m_val\n",
    "            m_val = float(metrics_pred[m][0](y_pred_ori, y_real).numpy())\n",
    "            df_metrics.at[m, 'Origin'] = m_val\n",
    "            metrics_pred[m][0].reset()\n",
    "        for m in metrics_prob:\n",
    "            m_val = 0\n",
    "            try:\n",
    "                m_val = float(metrics_prob[m][0](y_prob_atk, y_real).numpy())\n",
    "            except ValueError:\n",
    "                pass\n",
    "            metrics_prob[m][0].reset()\n",
    "            df_metrics.at[m, 'Attack'] = m_val\n",
    "            m_val = 0\n",
    "            try:\n",
    "                m_val = float(metrics_prob[m][0](y_prob_ori, y_real).numpy())\n",
    "            except ValueError:\n",
    "                pass\n",
    "            metrics_prob[m][0].reset()\n",
    "            df_metrics.at[m, 'Origin'] = m_val\n",
    "            \n",
    "        df_metrics.to_excel(f\"{path_curr}/metrics.xlsx\", index_label='Metrics')\n",
    "        \n",
    "        if attack_name == 'MomentumIterative':\n",
    "            df_eps.loc[eps_raw, \"Origin_Accuracy\"] = df_metrics.at['accuracy_weighted', 'Origin']\n",
    "        df_eps.loc[eps_raw, f\"{attack_name}_Accuracy\"] = df_metrics.at['accuracy_weighted', 'Attack']\n",
    "            \n",
    "df_eps.to_excel(f\"{path}/Evasion/df_eps.xlsx\", index_label='eps')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_eps = pd.read_excel(f\"{path}/Evasion/df_eps.xlsx\", index_col=0)\n",
    "\n",
    "atks_trgt = ['MomentumIterative', 'BasicIterative', 'FastGradient']\n",
    "\n",
    "df_fig = df_eps.loc[:, [f\"{x}_Accuracy\" for x in atks_trgt]].copy()\n",
    "df_fig.rename(columns={f\"{x}_Accuracy\": x for x in atks_trgt}, inplace=True)\n",
    "df_fig['Eps'] = df_fig.index.values\n",
    "df_fig = df_fig.melt(id_vars=\"Eps\", var_name='Method', value_name=\"Accuracy\")\n",
    "fig = plt.figure()\n",
    "sns.set_theme(style='whitegrid', font_scale=1)\n",
    "lines = sns.lineplot(\n",
    "    data=df_fig,\n",
    "    x='Eps',\n",
    "    y=\"Accuracy\",\n",
    "    hue=f\"Method\",\n",
    "    style=f\"Method\",\n",
    "    palette=colors_atks_eps,\n",
    "    hue_order=atks_trgt,\n",
    "    markers=True,\n",
    "    dashes=False,\n",
    ")\n",
    "plt.xscale('log')\n",
    "lines.set_xlabel(r'$\\epsilon$')\n",
    "x_min = 0.0009\n",
    "x_max = 1.05\n",
    "basic = df_eps.at[0.01, f\"Origin_Accuracy\"]\n",
    "lines.set_xlim(x_min, x_max)\n",
    "plt.gca().plot(\n",
    "    [x_min, x_max],\n",
    "    [basic, basic],\n",
    "    color='k',\n",
    "    linestyle='dashed',\n",
    "    linewidth=1\n",
    ")\n",
    "plt.savefig(f\"{path}/Evasion/line_accuracy_vs_eps.png\", bbox_inches='tight', dpi=200)\n",
    "plt.savefig(f\"{path}/Evasion/line_accuracy_vs_eps.pdf\", bbox_inches='tight')\n",
    "plt.close(fig)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Binary Search Steps attacks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "bsss = list(range(1, 11, 1))\n",
    "df_bss = pd.DataFrame(index=bsss)\n",
    "\n",
    "for bss in bsss:\n",
    "\n",
    "    attacks = {\n",
    "        'ElasticNet': ElasticNet(\n",
    "            classifier=art_classifier,\n",
    "            confidence=0.0,\n",
    "            targeted=False,\n",
    "            learning_rate=1e-3,\n",
    "            binary_search_steps=bss,\n",
    "            max_iter=20,\n",
    "            beta=1e-3,\n",
    "            initial_const=1e-4,\n",
    "            batch_size=1,\n",
    "            decision_rule=\"EN\",\n",
    "            verbose=True,\n",
    "        ),\n",
    "        'CarliniL2Method': CarliniL2Method(\n",
    "            classifier=art_classifier,\n",
    "            confidence=0.0,\n",
    "            targeted=False,\n",
    "            learning_rate=0.001,\n",
    "            binary_search_steps=bss,\n",
    "            max_iter=20,\n",
    "            initial_const=1e-4,\n",
    "            max_halving=5,\n",
    "            max_doubling=5,\n",
    "            batch_size=1,\n",
    "            verbose=True\n",
    "        ),\n",
    "        'ZooAttack': ZooAttack(\n",
    "            classifier=art_classifier,\n",
    "            confidence=0.0,\n",
    "            targeted=False,\n",
    "            learning_rate=0.001,\n",
    "            max_iter=20,\n",
    "            binary_search_steps=bss,\n",
    "            initial_const=1e-4,\n",
    "            abort_early=True,\n",
    "            use_resize=False,\n",
    "            use_importance=True,\n",
    "            nb_parallel=16,\n",
    "            batch_size=1,\n",
    "            variable_h=0.001,\n",
    "            verbose=True\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    for attack_name, attack in attacks.items():\n",
    "        path_curr = f\"{path}/Evasion/{attack_name}/bss_{bss}\"\n",
    "        pathlib.Path(f\"{path_curr}\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        X_adv = attack.generate(np.float32(df.loc[ids_atk, feats].values))\n",
    "        \n",
    "        df_adv = df.loc[ids_atk, ['Real']].copy()\n",
    "        df_adv.loc[ids_atk, feats] = X_adv\n",
    "        model.produce_probabilities = True\n",
    "        y_pred_prob = model(torch.from_numpy(np.float32(df_adv.loc[ids_atk, feats].values))).cpu().detach().numpy()\n",
    "        y_pred = np.argmax(y_pred_prob, 1)\n",
    "        df_adv[\"Pred\"] = y_pred\n",
    "        df_adv[\"Prob Control\"] = y_pred_prob[:, 0]\n",
    "        df_adv[\"Prob Parkinson\"] = y_pred_prob[:, 1]\n",
    "        df_adv[\"BSS\"] = bss\n",
    "        df_adv[\"Data\"] = attack_name\n",
    "        \n",
    "        for m, drm in dim_red_models.items():\n",
    "            dim_red_res = drm.transform(df_adv.loc[:, feats].values)\n",
    "            df_adv.loc[:, dim_red_labels[m][0]] = dim_red_res[:, 0]\n",
    "            df_adv.loc[:, dim_red_labels[m][1]] = dim_red_res[:, 1]\n",
    "            \n",
    "        add_iqr_outs_to_df(df_adv, df.loc[ids_trn_val, :], feats)\n",
    "        add_pyod_outs_to_df(df_adv, pyod_methods, feats)\n",
    "            \n",
    "        df_adv.to_excel(f\"{path_curr}/df.xlsx\", index_label='sample_id')\n",
    "\n",
    "        metrics_pred = get_cls_pred_metrics(num_classes=2)\n",
    "        metrics_prob = get_cls_prob_metrics(num_classes=2)\n",
    "        df_metrics = pd.DataFrame(index=list(metrics_pred.keys()) + list(metrics_prob.keys()))\n",
    "        y_real = torch.from_numpy(df_adv.loc[ids_atk, \"Real\"].values.astype('int32'))\n",
    "        y_pred_atk = torch.from_numpy(df_adv.loc[ids_atk, \"Pred\"].values.astype('int32'))\n",
    "        y_pred_ori = torch.from_numpy(df.loc[ids_atk, \"Pred\"].values.astype('int32'))\n",
    "        y_prob_atk = torch.from_numpy(df_adv.loc[ids_atk, [\"Prob Control\", \"Prob Parkinson\"]].values)\n",
    "        y_prob_ori = torch.from_numpy(df.loc[ids_atk, [\"Prob Control\", \"Prob Parkinson\"]].values)\n",
    "        for m in metrics_pred:\n",
    "            m_val = float(metrics_pred[m][0](y_pred_atk, y_real).numpy())\n",
    "            metrics_pred[m][0].reset()\n",
    "            df_metrics.at[m, 'Attack'] = m_val\n",
    "            m_val = float(metrics_pred[m][0](y_pred_ori, y_real).numpy())\n",
    "            df_metrics.at[m, 'Origin'] = m_val\n",
    "            metrics_pred[m][0].reset()\n",
    "        for m in metrics_prob:\n",
    "            m_val = 0\n",
    "            try:\n",
    "                m_val = float(metrics_prob[m][0](y_prob_atk, y_real).numpy())\n",
    "            except ValueError:\n",
    "                pass\n",
    "            metrics_prob[m][0].reset()\n",
    "            df_metrics.at[m, 'Attack'] = m_val\n",
    "            m_val = 0\n",
    "            try:\n",
    "                m_val = float(metrics_prob[m][0](y_prob_ori, y_real).numpy())\n",
    "            except ValueError:\n",
    "                pass\n",
    "            metrics_prob[m][0].reset()\n",
    "            df_metrics.at[m, 'Origin'] = m_val\n",
    "            \n",
    "        df_metrics.to_excel(f\"{path_curr}/metrics.xlsx\", index_label='Metrics')\n",
    "        \n",
    "        if attack_name == 'ElasticNet':\n",
    "            df_bss.loc[bss, \"Origin_Accuracy\"] = df_metrics.at['accuracy_weighted', 'Origin']\n",
    "        df_bss.loc[bss, f\"{attack_name}_Accuracy\"] = df_metrics.at['accuracy_weighted', 'Attack']\n",
    "            \n",
    "df_bss.to_excel(f\"{path}/Evasion/df_bss.xlsx\", index_label='eps')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_bss = pd.read_excel(f\"{path}/Evasion/df_bss.xlsx\", index_col=0)\n",
    "\n",
    "atks_trgt = ['ElasticNet', 'CarliniL2Method', 'ZooAttack']\n",
    "\n",
    "df_fig = df_bss.loc[:, [f\"{x}_Accuracy\" for x in atks_trgt]].copy()\n",
    "df_fig.rename(columns={f\"{x}_Accuracy\": x for x in atks_trgt}, inplace=True)\n",
    "df_fig['BSS'] = df_fig.index.values\n",
    "df_fig = df_fig.melt(id_vars=\"BSS\", var_name='Method', value_name=\"Accuracy\")\n",
    "fig = plt.figure()\n",
    "sns.set_theme(style='whitegrid', font_scale=1)\n",
    "lines = sns.lineplot(\n",
    "    data=df_fig,\n",
    "    x='BSS',\n",
    "    y=\"Accuracy\",\n",
    "    hue=f\"Method\",\n",
    "    style=f\"Method\",\n",
    "    palette=colors_atks_bss,\n",
    "    hue_order=atks_trgt,\n",
    "    markers=True,\n",
    "    dashes=False,\n",
    ")\n",
    "lines.set_xlabel('BSS')\n",
    "basic = pd.read_excel(f\"{path}/Evasion/ElasticNet/bss_1/metrics.xlsx\", index_col=0).at['accuracy_weighted', 'Origin']\n",
    "x_min = 0.5\n",
    "x_max = 10.5\n",
    "lines.set_xlim(x_min, x_max)\n",
    "plt.gca().plot(\n",
    "    [x_min, x_max],\n",
    "    [basic, basic],\n",
    "    color='k',\n",
    "    linestyle='dashed',\n",
    "    linewidth=1\n",
    ")\n",
    "plt.savefig(f\"{path}/Evasion/line_accuracy_vs_bss.png\", bbox_inches='tight', dpi=200)\n",
    "plt.savefig(f\"{path}/Evasion/line_accuracy_vs_bss.pdf\", bbox_inches='tight')\n",
    "plt.close(fig)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Eta-depended attacks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#etas = np.concatenate([np.geomspace(1e-8, 1e-1, 8), np.geomspace(1e-8, 1e-1, 8) * 5])\n",
    "etas = sorted(list(set.union(\n",
    "    set(np.linspace(0.1, 1.0, 10)), \n",
    "    set(np.linspace(0.01, 0.1, 10)),\n",
    "    set(np.linspace(0.001, 0.01, 10))\n",
    ")))\n",
    "\n",
    "df_etas = pd.DataFrame(index=etas)\n",
    "\n",
    "for eta in etas:\n",
    "\n",
    "    attacks = {\n",
    "        'NewtonFool': NewtonFool(\n",
    "            classifier=art_classifier,\n",
    "            max_iter=100,\n",
    "            eta=eta,\n",
    "            batch_size=100,\n",
    "            verbose=True,\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    for attack_name, attack in attacks.items():\n",
    "        path_curr = f\"{path}/Evasion/{attack_name}/eta_{eta:0.2e}\"\n",
    "        pathlib.Path(f\"{path_curr}\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        X_adv = attack.generate(np.float32(df.loc[ids_atk, feats].values))\n",
    "        \n",
    "        df_adv = df.loc[ids_atk, ['Real']].copy()\n",
    "        df_adv.loc[ids_atk, feats] = X_adv\n",
    "        model.produce_probabilities = True\n",
    "        y_pred_prob = model(torch.from_numpy(np.float32(df_adv.loc[ids_atk, feats].values))).cpu().detach().numpy()\n",
    "        y_pred = np.argmax(y_pred_prob, 1)\n",
    "        df_adv[\"Pred\"] = y_pred\n",
    "        df_adv[\"Prob Control\"] = y_pred_prob[:, 0]\n",
    "        df_adv[\"Prob Parkinson\"] = y_pred_prob[:, 1]\n",
    "        df_adv[\"Eta\"] = f\"{eta:0.2e}\"\n",
    "        df_adv[\"Data\"] = attack_name\n",
    "        \n",
    "        for m, drm in dim_red_models.items():\n",
    "            dim_red_res = drm.transform(df_adv.loc[:, feats].values)\n",
    "            df_adv.loc[:, dim_red_labels[m][0]] = dim_red_res[:, 0]\n",
    "            df_adv.loc[:, dim_red_labels[m][1]] = dim_red_res[:, 1]\n",
    "            \n",
    "        add_iqr_outs_to_df(df_adv, df.loc[ids_trn_val, :], feats)\n",
    "        add_pyod_outs_to_df(df_adv, pyod_methods, feats)\n",
    "            \n",
    "        df_adv.to_excel(f\"{path_curr}/df.xlsx\", index_label='sample_id')\n",
    "\n",
    "        metrics_pred = get_cls_pred_metrics(num_classes=2)\n",
    "        metrics_prob = get_cls_prob_metrics(num_classes=2)\n",
    "        df_metrics = pd.DataFrame(index=list(metrics_pred.keys()) + list(metrics_prob.keys()))\n",
    "        y_real = torch.from_numpy(df_adv.loc[ids_atk, \"Real\"].values.astype('int32'))\n",
    "        y_pred_atk = torch.from_numpy(df_adv.loc[ids_atk, \"Pred\"].values.astype('int32'))\n",
    "        y_pred_ori = torch.from_numpy(df.loc[ids_atk, \"Pred\"].values.astype('int32'))\n",
    "        y_prob_atk = torch.from_numpy(df_adv.loc[ids_atk, [\"Prob Control\", \"Prob Parkinson\"]].values)\n",
    "        y_prob_ori = torch.from_numpy(df.loc[ids_atk, [\"Prob Control\", \"Prob Parkinson\"]].values)\n",
    "        for m in metrics_pred:\n",
    "            m_val = float(metrics_pred[m][0](y_pred_atk, y_real).numpy())\n",
    "            metrics_pred[m][0].reset()\n",
    "            df_metrics.at[m, 'Attack'] = m_val\n",
    "            m_val = float(metrics_pred[m][0](y_pred_ori, y_real).numpy())\n",
    "            df_metrics.at[m, 'Origin'] = m_val\n",
    "            metrics_pred[m][0].reset()\n",
    "        for m in metrics_prob:\n",
    "            m_val = 0\n",
    "            try:\n",
    "                m_val = float(metrics_prob[m][0](y_prob_atk, y_real).numpy())\n",
    "            except ValueError:\n",
    "                pass\n",
    "            metrics_prob[m][0].reset()\n",
    "            df_metrics.at[m, 'Attack'] = m_val\n",
    "            m_val = 0\n",
    "            try:\n",
    "                m_val = float(metrics_prob[m][0](y_prob_ori, y_real).numpy())\n",
    "            except ValueError:\n",
    "                pass\n",
    "            metrics_prob[m][0].reset()\n",
    "            df_metrics.at[m, 'Origin'] = m_val\n",
    "            \n",
    "        df_metrics.to_excel(f\"{path_curr}/metrics.xlsx\", index_label='Metrics')\n",
    "        \n",
    "        if attack_name == 'NewtonFool':\n",
    "            df_etas.loc[eta, \"Origin_Accuracy\"] = df_metrics.at['accuracy_weighted', 'Origin']\n",
    "        df_etas.loc[eta, f\"{attack_name}_Accuracy\"] = df_metrics.at['accuracy_weighted', 'Attack']\n",
    "            \n",
    "df_etas.to_excel(f\"{path}/Evasion/df_etas.xlsx\", index_label='eta')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_etas = pd.read_excel(f\"{path}/Evasion/df_etas.xlsx\", index_col=0)\n",
    "\n",
    "atks_trgt = ['NewtonFool']\n",
    "\n",
    "df_fig = df_etas.loc[:, [f\"{x}_Accuracy\" for x in atks_trgt]].copy()\n",
    "df_fig.rename(columns={f\"{x}_Accuracy\": x for x in atks_trgt}, inplace=True)\n",
    "df_fig['Eta'] = df_fig.index.values\n",
    "df_fig = df_fig.melt(id_vars=\"Eta\", var_name='Method', value_name=\"Accuracy\")\n",
    "fig = plt.figure()\n",
    "sns.set_theme(style='whitegrid', font_scale=1)\n",
    "lines = sns.lineplot(\n",
    "    data=df_fig,\n",
    "    x='Eta',\n",
    "    y=\"Accuracy\",\n",
    "    hue=f\"Method\",\n",
    "    style=f\"Method\",\n",
    "    palette=colors_atks_eta,\n",
    "    hue_order=atks_trgt,\n",
    "    markers=True,\n",
    "    dashes=False,\n",
    ")\n",
    "plt.xscale('log')\n",
    "lines.set_xlabel(r'$\\eta$')\n",
    "x_min = 8e-4\n",
    "x_max = 1.1\n",
    "basic = df_etas.at[0.01, f\"Origin_Accuracy\"]\n",
    "lines.set_xlim(x_min, x_max)\n",
    "plt.gca().plot(\n",
    "    [x_min, x_max],\n",
    "    [basic, basic],\n",
    "    color='k',\n",
    "    linestyle='dashed',\n",
    "    linewidth=1\n",
    ")\n",
    "plt.savefig(f\"{path}/Evasion/line_accuracy_vs_eta.png\", bbox_inches='tight', dpi=200)\n",
    "plt.savefig(f\"{path}/Evasion/line_accuracy_vs_eta.pdf\", bbox_inches='tight')\n",
    "plt.close(fig)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Setup for plots"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "atks_options = {\n",
    "    'Eps': {\n",
    "        'types': ['MomentumIterative', 'BasicIterative', 'FastGradient'],\n",
    "        'values': [0.005, 0.02, 0.05, 0.2]\n",
    "    },\n",
    "    'BSS': {\n",
    "        'types': ['ElasticNet', 'CarliniL2Method', 'ZooAttack'],\n",
    "        'values': [2, 4, 6, 8]\n",
    "    },\n",
    "    'Eta': {\n",
    "        'types': ['NewtonFool'],\n",
    "        'values': [1e-3, 2e-3, 3e-3, 1e-2]\n",
    "    },\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot in reduced dimension"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_ori = df.loc[ids_tst, :].copy()\n",
    "df_ori.loc[df_ori['Real'] == 0, 'Status'] = 'Control'\n",
    "df_ori.loc[df_ori['Real'] == 1, 'Status'] = 'Parkinson'\n",
    "df_ori['Type'] = 'Real'\n",
    "df_ori['Symbol'] = 'o'\n",
    "df_ori['MarkerSize'] = 70\n",
    "\n",
    "for var_param, opt in atks_options.items():\n",
    "    for atk_type in opt['types']:\n",
    "        for var_val in opt['values']:\n",
    "            if var_param == 'Eps':\n",
    "                path_curr = f\"{path}/Evasion/{atk_type}/eps_{var_val:0.4f}\"\n",
    "                val_str = f'Eps = {var_val:0.4f}'\n",
    "            elif var_param == 'BSS':\n",
    "                path_curr = f\"{path}/Evasion/{atk_type}/bss_{var_val}\"\n",
    "                val_str = f'BSS = {var_val}'\n",
    "            else:\n",
    "                path_curr = f\"{path}/Evasion/{atk_type}/eta_{var_val:0.2e}\"\n",
    "                val_str = f'Eta = {var_val:0.2e}'\n",
    "            \n",
    "            print(f\"{atk_type} {val_str}\")\n",
    "            \n",
    "            pathlib.Path(f\"{path_curr}/dim_red\").mkdir(parents=True, exist_ok=True)\n",
    "                \n",
    "            df_ori[var_param] = 'Origin'\n",
    "            df_adv = pd.read_excel(f\"{path_curr}/df.xlsx\", index_col=0)\n",
    "            df_adv[var_param] = var_val\n",
    "            df_adv.set_index(df_adv.index.values + f' {val_str}', inplace=True)\n",
    "            df_adv['Symbol'] = 'X'\n",
    "            df_adv['MarkerSize'] = 50\n",
    "            df_ori_adv = pd.concat([df_ori, df_adv])\n",
    "            \n",
    "            for m in ['t-SNE']:\n",
    "                norm = plt.Normalize(df_ori_adv[\"Prob Parkinson\"].min(), df_ori_adv[\"Prob Parkinson\"].max())\n",
    "                sm = plt.cm.ScalarMappable(cmap=\"seismic\", norm=norm)\n",
    "                sm.set_array([])\n",
    "                \n",
    "                fig, ax = plt.subplots(figsize=(8, 6))\n",
    "                sns.set_theme(style='whitegrid')\n",
    "                \n",
    "                scatter = sns.scatterplot(\n",
    "                    data=df_ori_adv,\n",
    "                    x=dim_red_labels[m][0],\n",
    "                    y=dim_red_labels[m][1],\n",
    "                    palette='seismic',\n",
    "                    hue=\"Prob Parkinson\",\n",
    "                    linewidth=0.5,\n",
    "                    alpha=0.75,\n",
    "                    edgecolor=\"cyan\",\n",
    "                    style=df_ori_adv.loc[:, 'Symbol'].values,\n",
    "                    size='MarkerSize',\n",
    "                    ax=ax\n",
    "                )\n",
    "                scatter.get_legend().remove()\n",
    "                scatter.figure.colorbar(sm, label=\"Prob Parkinson\")\n",
    "                scatter.set_title(val_str, loc='left', y=1.05, fontdict={'fontsize': 20})\n",
    "    \n",
    "                legend_handles = [\n",
    "                    mlines.Line2D([], [], marker='o', linestyle='None', markeredgecolor='k', markerfacecolor='lightgrey', markersize=10, label='Real'),\n",
    "                    mlines.Line2D([], [], marker='X', linestyle='None', markeredgecolor='k', markerfacecolor='lightgrey', markersize=7, label='Attack')\n",
    "                ]\n",
    "                plt.legend(handles=legend_handles, title=\"Samples\", bbox_to_anchor=(0.4, 1.02, 1, 0.2), loc=\"lower left\", borderaxespad=0, ncol=2, frameon=False)\n",
    "                \n",
    "                plt.savefig(f\"{path_curr}/dim_red/{m}.png\", bbox_inches='tight', dpi=200)\n",
    "                plt.savefig(f\"{path_curr}/dim_red/{m}.pdf\", bbox_inches='tight')\n",
    "                plt.close(fig)  "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot features differences"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_ori = df.loc[ids_tst, :].copy()\n",
    "df_ori.loc[df_ori['Real'] == 0, 'Status'] = 'Control'\n",
    "df_ori.loc[df_ori['Real'] == 1, 'Status'] = 'Parkinson'\n",
    "df_ori['Type'] = 'Real'\n",
    "\n",
    "for var_param, opt in atks_options.items():\n",
    "    for atk_type in opt['types']:\n",
    "        df_ori[var_param] = 'Origin'\n",
    "        dfs_ori_advs = [df_ori]\n",
    "        \n",
    "        palette_curr = {'Origin': 'gray'} \n",
    "        for var_val_id, var_val in enumerate(opt['values']):\n",
    "            if var_param == 'Eps':\n",
    "                path_curr = f\"{path}/Evasion/{atk_type}/eps_{var_val:0.4f}\"\n",
    "                val_str = f'Eps = {var_val:0.4f}'\n",
    "            elif var_param == 'BSS':\n",
    "                path_curr = f\"{path}/Evasion/{atk_type}/bss_{var_val}\"\n",
    "                val_str = f'BSS = {var_val}'\n",
    "            else:\n",
    "                path_curr = f\"{path}/Evasion/{atk_type}/eta_{var_val:0.2e}\"\n",
    "                val_str = f'Eta = {var_val:0.2e}'\n",
    "            \n",
    "            palette_curr[var_val] = px.colors.qualitative.G10[var_val_id]\n",
    "                \n",
    "            df_adv = pd.read_excel(f\"{path_curr}/df.xlsx\", index_col=0)\n",
    "            df_adv[var_param] = var_val\n",
    "            df_adv.loc[df_adv['Real'] == 0, 'Status'] = 'Control'\n",
    "            df_adv.loc[df_adv['Real'] == 1, 'Status'] = 'Parkinson'\n",
    "            df_adv.set_index(df_adv.index.values + f' {val_str}', inplace=True)\n",
    "            dfs_ori_advs.append(df_adv)\n",
    "        df_ori_adv = pd.concat(dfs_ori_advs)\n",
    "\n",
    "        kdeplots = {}\n",
    "        for cls in ['Control', 'Parkinson']:\n",
    "            kdeplots[cls] = pw.Brick(figsize=(4, 2))\n",
    "            sns.set_theme(style='whitegrid')\n",
    "            kde = sns.kdeplot(\n",
    "                data=df_ori_adv.loc[df_ori_adv['Status'] == cls, :],\n",
    "                x=f\"Prob Parkinson\",\n",
    "                hue=var_param,\n",
    "                linewidth=2,\n",
    "                palette=palette_curr,\n",
    "                hue_order=list(palette_curr.keys()),\n",
    "                fill=True,\n",
    "                cut=0,\n",
    "                ax=kdeplots[cls]\n",
    "            )\n",
    "            sns.move_legend(kdeplots[cls], \"upper center\")\n",
    "            kdeplots[cls].set_title(f\"{cls} samples\")\n",
    "    \n",
    "        df_stat = pd.DataFrame(index=feats, columns=[f'{var_val}' for var_val in opt['values']])\n",
    "        for f in feats:\n",
    "            vals_dict = {'Origin': df_ori_adv.loc[df_ori_adv[var_param] == 'Origin', f].values}\n",
    "            for var_val_id, var_val in enumerate(opt['values']):\n",
    "                vals_dict[var_val] = df_ori_adv.loc[df_ori_adv[var_param] == var_val, f].values\n",
    "                _, df_stat.at[f, f'{var_val}'] = mannwhitneyu(\n",
    "                    vals_dict['Origin'],\n",
    "                    vals_dict[var_val],\n",
    "                    alternative='two-sided'\n",
    "                )\n",
    "                _, df_stat.loc[:, f'{var_val}_fdr_bh'], _, _ = multipletests(df_stat.loc[:, f'{var_val}'], 0.05, method='fdr_bh')\n",
    "        df_stat.sort_values([f\"{opt['values'][-1]}\"], ascending=[True], inplace=True)\n",
    "        df_stat.to_excel(f\"{path}/Evasion/df_stat_{var_param}_{atk_type}.xlsx\", index_label=\"Features\")\n",
    "        \n",
    "        pw_fig = (kdeplots['Control'] | kdeplots['Parkinson'])\n",
    "        pw_fig.savefig(f\"{path}/Evasion/feats_{var_param}_{atk_type}.png\", bbox_inches='tight', dpi=200)\n",
    "        pw_fig.savefig(f\"{path}/Evasion/feats_{var_param}_{atk_type}.pdf\", bbox_inches='tight')\n",
    "        pw.clear()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Outliers analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_ori = df.loc[ids_tst, :].copy()\n",
    "df_ori.loc[df_ori['Real'] == 0, 'Status'] = 'Control'\n",
    "df_ori.loc[df_ori['Real'] == 1, 'Status'] = 'Parkinson'\n",
    "df_ori['Type'] = 'Real'\n",
    "\n",
    "for var_param, opt in atks_options.items():\n",
    "    for atk_type in opt['types']:\n",
    "        for var_val_id, var_val in enumerate(opt['values']):\n",
    "            if var_param == 'Eps':\n",
    "                path_curr = f\"{path}/Evasion/{atk_type}/eps_{var_val:0.4f}\"\n",
    "                val_str = f'Eps = {var_val:0.4f}'\n",
    "            elif var_param == 'BSS':\n",
    "                path_curr = f\"{path}/Evasion/{atk_type}/bss_{var_val}\"\n",
    "                val_str = f'BSS = {var_val}'\n",
    "            else:\n",
    "                path_curr = f\"{path}/Evasion/{atk_type}/eta_{var_val:0.2e}\"\n",
    "                val_str = f'Eta = {var_val:0.2e}'\n",
    "            \n",
    "            df_adv = pd.read_excel(f\"{path_curr}/df.xlsx\", index_col=0)\n",
    "            df_adv[var_param] = var_val\n",
    "            df_adv.loc[df_adv['Real'] == 0, 'Status'] = 'Control'\n",
    "            df_adv.loc[df_adv['Real'] == 1, 'Status'] = 'Parkinson'\n",
    "            df_adv.set_index(df_adv.index.values + f' {val_str}', inplace=True)\n",
    "            \n",
    "            # IQR outliers\n",
    "            pathlib.Path(f\"{path_curr}/outliers_iqr\").mkdir(parents=True, exist_ok=True)\n",
    "            plot_iqr_outs(df_adv, feats, 'grey', atk_type, f\"{path_curr}/outliers_iqr\", is_msno_plots=False)\n",
    "            df_fig = df_adv.loc[:, ['Real', 'Pred', 'n_outs_iqr', 'Prob Control', 'Prob Parkinson']].copy()\n",
    "            df_fig.loc[df_fig['Real'] == 0, 'Status'] = 'Control'\n",
    "            df_fig.loc[df_fig['Real'] == 1, 'Status'] = 'Parkinson'\n",
    "            plot_iqr_outs_cls(\n",
    "                df=df_fig,\n",
    "                path=f\"{path_curr}/outliers_iqr\",\n",
    "                col_class=\"Status\",\n",
    "                col_pred=\"Pred\",\n",
    "                col_real=\"Real\",\n",
    "                cols_prob=['Prob Control', 'Prob Parkinson'],\n",
    "                palette={'Control': 'dodgerblue', 'Parkinson': 'crimson'}\n",
    "            )\n",
    "            \n",
    "            # PyOD plots\n",
    "            pathlib.Path(f\"{path_curr}/outliers_pyod\").mkdir(parents=True, exist_ok=True)\n",
    "            plot_pyod_outs(df_adv, pyod_method_names, 'grey', 'Origin', f\"{path_curr}/outliers_pyod\", n_cols=4)\n",
    "            df_fig = df_adv.loc[:, ['Real', 'Pred', 'Detections', 'Prob Control', 'Prob Parkinson']].copy()\n",
    "            df_fig.loc[df_fig['Real'] == 0, 'Status'] = 'Control'\n",
    "            df_fig.loc[df_fig['Real'] == 1, 'Status'] = 'Parkinson'\n",
    "            plot_pyod_outs_cls(\n",
    "                df=df_fig,\n",
    "                path=f\"{path_curr}/outliers_pyod\",\n",
    "                col_class=\"Status\",\n",
    "                col_pred=\"Pred\",\n",
    "                col_real=\"Real\",\n",
    "                cols_prob=['Prob Control', 'Prob Parkinson'],\n",
    "                palette={'Control': 'dodgerblue', 'Parkinson': 'crimson'}\n",
    "            )\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Confidence"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "quantiles = torch.tensor([0.05, 0.95])\n",
    "\n",
    "epsilons = sorted(list(set.union(\n",
    "    set(np.linspace(0.1, 1.0, 10)), \n",
    "    set(np.linspace(0.01, 0.1, 10)),\n",
    "    set(np.linspace(0.001, 0.01, 10))\n",
    ")))\n",
    "\n",
    "bsss = list(range(1, 11, 1))\n",
    "\n",
    "etas = sorted(list(set.union(\n",
    "    set(np.linspace(0.1, 1.0, 10)), \n",
    "    set(np.linspace(0.01, 0.1, 10)),\n",
    "    set(np.linspace(0.001, 0.01, 10))\n",
    ")))\n",
    "\n",
    "atks_options = {\n",
    "    'Eps': {\n",
    "        'types': ['MomentumIterative', 'BasicIterative', 'FastGradient'],\n",
    "        'values': epsilons\n",
    "    },\n",
    "    'BSS': {\n",
    "        'types': ['ElasticNet', 'CarliniL2Method', 'ZooAttack'],\n",
    "        'values': bsss\n",
    "    },\n",
    "    'Eta': {\n",
    "        'types': ['NewtonFool'],\n",
    "        'values': etas\n",
    "    },\n",
    "}\n",
    "\n",
    "for var_param, opt in atks_options.items():\n",
    "    for atk_type in opt['types']:\n",
    "        for var_val_id, var_val in enumerate(opt['values']):\n",
    "            if var_param == 'Eps':\n",
    "                path_curr = f\"{path}/Evasion/{atk_type}/eps_{var_val:0.4f}\"\n",
    "                val_str = f'Eps = {var_val:0.4f}'\n",
    "            elif var_param == 'BSS':\n",
    "                path_curr = f\"{path}/Evasion/{atk_type}/bss_{var_val}\"\n",
    "                val_str = f'BSS = {var_val}'\n",
    "            else:\n",
    "                path_curr = f\"{path}/Evasion/{atk_type}/eta_{var_val:0.2e}\"\n",
    "                val_str = f'Eta = {var_val:0.2e}'\n",
    "            \n",
    "            df_adv = pd.read_excel(f\"{path_curr}/df.xlsx\", index_col=0)\n",
    "            df_adv.loc[df_adv['Real'] == 0, 'Status'] = 'Control'\n",
    "            df_adv.loc[df_adv['Real'] == 1, 'Status'] = 'Parkinson'\n",
    "            \n",
    "            pathlib.Path(f\"{path_curr}/confidence\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            metrics_pred = get_cls_pred_metrics(num_classes=2)\n",
    "            df_metrics = pd.DataFrame(index=list(metrics_pred.keys()))\n",
    "            y_real = torch.from_numpy(df_adv.loc[:, \"Real\"].values.astype('int32'))\n",
    "            y_pred = torch.from_numpy(df_adv.loc[:, \"Pred\"].values.astype('int32'))\n",
    "            \n",
    "            for metric_name, metric_pair in metrics_pred.items():\n",
    "                metric = metric_pair[0]\n",
    "                bootstrap = BootStrapper(\n",
    "                    metric,\n",
    "                    num_bootstraps=200,\n",
    "                    sampling_strategy=\"multinomial\",\n",
    "                    quantile=quantiles\n",
    "                )\n",
    "                bootstrap.update(y_pred, y_real)\n",
    "                bootstrap_output = bootstrap.compute()\n",
    "                df_metrics.at[metric_name, 'mean'] = bootstrap_output['mean'].detach().cpu().numpy()\n",
    "                df_metrics.at[metric_name, 'std'] = bootstrap_output['std'].detach().cpu().numpy()\n",
    "                df_metrics.at[metric_name, 'q0.05'] = bootstrap_output['quantile'].detach().cpu().numpy()[0]\n",
    "                df_metrics.at[metric_name, 'q0.95'] = bootstrap_output['quantile'].detach().cpu().numpy()[1]\n",
    "            df_metrics.to_excel(f\"{path_curr}/confidence/metrics.xlsx\", index_label='Metrics')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "metrics_names = {\n",
    "    'accuracy_weighted': 'Accuracy',\n",
    "}\n",
    "quantiles = [0.05, 0.95]\n",
    "\n",
    "epsilons = sorted(list(set.union(\n",
    "    set(np.linspace(0.1, 1.0, 10)), \n",
    "    set(np.linspace(0.01, 0.1, 10)),\n",
    "    set(np.linspace(0.001, 0.01, 10))\n",
    ")))\n",
    "\n",
    "bsss = list(range(1, 11, 1))\n",
    "\n",
    "etas = sorted(list(set.union(\n",
    "    set(np.linspace(0.1, 1.0, 10)), \n",
    "    set(np.linspace(0.01, 0.1, 10)),\n",
    "    set(np.linspace(0.001, 0.01, 10))\n",
    ")))\n",
    "\n",
    "atks_options = {\n",
    "    'Eps': {\n",
    "        'types': ['MomentumIterative', 'BasicIterative', 'FastGradient'],\n",
    "        'values': epsilons\n",
    "    },\n",
    "    'BSS': {\n",
    "        'types': ['ElasticNet', 'CarliniL2Method', 'ZooAttack'],\n",
    "        'values': bsss\n",
    "    },\n",
    "    'Eta': {\n",
    "        'types': ['NewtonFool'],\n",
    "        'values': etas\n",
    "    },\n",
    "}\n",
    "\n",
    "df_conf = pd.DataFrame(index=['Real'] + list(colors_augs.keys()), columns=[f\"{m}_{q}\" for m in metrics_names for q in quantiles])\n",
    "\n",
    "df_metrics = pd.read_excel(f\"{path}/Origin/confidence/metrics.xlsx\", index_col='Metrics')\n",
    "for m in metrics_names:\n",
    "    for q in quantiles:\n",
    "        df_conf.at[\"Real\", f\"{m}_{q}\"] = df_metrics.at[m, f\"q{q}\"]\n",
    "\n",
    "\n",
    "for var_param, opt in atks_options.items():\n",
    "    for atk_type in opt['types']:\n",
    "        df_conf = pd.DataFrame(index=opt['values'], columns=[f\"{m}_{q}\" for m in metrics_names for q in quantiles])\n",
    "        for var_val_id, var_val in enumerate(opt['values']):\n",
    "            if var_param == 'Eps':\n",
    "                path_curr = f\"{path}/Evasion/{atk_type}/eps_{var_val:0.4f}\"\n",
    "                val_str = f'Eps = {var_val:0.4f}'\n",
    "                palette = colors_atks_eps\n",
    "            elif var_param == 'BSS':\n",
    "                path_curr = f\"{path}/Evasion/{atk_type}/bss_{var_val}\"\n",
    "                val_str = f'BSS = {var_val}'\n",
    "                palette = colors_atks_bss\n",
    "            else:\n",
    "                path_curr = f\"{path}/Evasion/{atk_type}/eta_{var_val:0.2e}\"\n",
    "                val_str = f'Eta = {var_val:0.2e}'\n",
    "                palette = colors_atks_eta\n",
    "            df_metrics = pd.read_excel(f\"{path_curr}/confidence/metrics.xlsx\", index_col='Metrics')\n",
    "            for m in metrics_names:\n",
    "                for q in quantiles:\n",
    "                    df_conf.at[var_val, f\"{m}_{q}\"] = df_metrics.at[m, f\"q{q}\"]\n",
    "        \n",
    "        if var_param == 'Eps':\n",
    "            palette = colors_atks_eps\n",
    "        elif var_param == 'BSS':\n",
    "            palette = colors_atks_bss\n",
    "        else:\n",
    "            palette = colors_atks_eta\n",
    "        \n",
    "        for m in metrics_names:\n",
    "            df_fig = df_conf.loc[:, [f\"{m}_{q}\" for q in quantiles]].copy()\n",
    "            df_fig['Type'] = df_fig.index\n",
    "            df_fig = df_fig.melt(id_vars=['Type'], value_name=metrics_names[m])\n",
    "            fig, ax = plt.subplots(figsize=(5, 4))\n",
    "            sns.set_theme(style='ticks') \n",
    "            scatter = sns.scatterplot(\n",
    "                data=df_fig,\n",
    "                y=metrics_names[m],\n",
    "                x='Type',\n",
    "                hue='Type',\n",
    "                palette={x: palette[atk_type] for x in opt['values']},\n",
    "                hue_order=opt['values'],\n",
    "                linewidth=0.2,\n",
    "                alpha=0.95,\n",
    "                edgecolor=\"black\",\n",
    "                s=16,\n",
    "                ax=ax\n",
    "            )\n",
    "            scatter.get_legend().set_visible(False)\n",
    "            line = sns.lineplot(\n",
    "                data=df_fig,\n",
    "                y=metrics_names[m],\n",
    "                x='Type',\n",
    "                hue='Type',\n",
    "                palette={x: palette[atk_type] for x in opt['values']},\n",
    "                hue_order=opt['values'],\n",
    "                linewidth=3,\n",
    "                ax=ax\n",
    "            )\n",
    "            line.get_legend().set_visible(False)\n",
    "            \n",
    "            if var_param == 'Eps':\n",
    "                plt.xscale('log')\n",
    "                ax.set_xlabel(r'$\\epsilon$')\n",
    "            elif var_param == 'BSS':\n",
    "                ax.set_xlabel(\"BSS\")\n",
    "            else:\n",
    "                plt.xscale('log')\n",
    "                ax.set_xlabel(r'$\\eta$')\n",
    "            ax.set_ylabel(f\"Confidence Intervals for {metrics_names[m]}\")\n",
    "            plt.savefig(f\"{path}/Evasion/{atk_type}/confidence_{m}.png\", bbox_inches='tight', dpi=400)\n",
    "            plt.savefig(f\"{path}/Evasion/{atk_type}/confidence_{m}.pdf\", bbox_inches='tight')\n",
    "            plt.close(fig)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
