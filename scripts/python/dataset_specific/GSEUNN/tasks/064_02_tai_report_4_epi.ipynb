{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"D:/Work/dnam/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T14:06:57.200053Z",
     "start_time": "2024-07-08T14:06:52.515253Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "import pathlib\n",
    "import os\n",
    "import scipy.stats\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "from art.attacks.evasion import FastGradientMethod, BasicIterativeMethod, MomentumIterativeMethod\n",
    "from art.attacks.evasion import ZooAttack, CarliniL2Method, ElasticNet, NewtonFool\n",
    "import torch\n",
    "\n",
    "from pyod.models.ecod import ECOD\n",
    "from pyod.models.copod import COPOD\n",
    "from pyod.models.sos import SOS\n",
    "from pyod.models.qmcd import QMCD as QMCDOD\n",
    "from pyod.models.sampling import Sampling\n",
    "from pyod.models.gmm import GMM\n",
    "from pyod.models.pca import PCA\n",
    "from pyod.models.mcd import MCD\n",
    "from pyod.models.cd import CD\n",
    "from pyod.models.lmdd import LMDD\n",
    "from pyod.models.lof import LOF\n",
    "from pyod.models.cof import COF\n",
    "from pyod.models.cblof import CBLOF\n",
    "from pyod.models.hbos import HBOS\n",
    "from pyod.models.knn import KNN\n",
    "from pyod.models.sod import SOD\n",
    "from pyod.models.rod import ROD\n",
    "from pyod.models.iforest import IForest\n",
    "from pyod.models.inne import INNE\n",
    "from pyod.models.dif import DIF\n",
    "from pyod.models.feature_bagging import FeatureBagging\n",
    "from pyod.models.loda import LODA\n",
    "from pyod.models.lunar import LUNAR\n",
    "\n",
    "from pythresh.thresholds.iqr import IQR\n",
    "from pythresh.thresholds.mad import MAD\n",
    "from pythresh.thresholds.fwfm import FWFM\n",
    "from pythresh.thresholds.yj import YJ\n",
    "from pythresh.thresholds.zscore import ZSCORE\n",
    "from pythresh.thresholds.aucp import AUCP\n",
    "from pythresh.thresholds.qmcd import QMCD\n",
    "from pythresh.thresholds.fgd import FGD\n",
    "from pythresh.thresholds.dsn import DSN\n",
    "from pythresh.thresholds.clf import CLF\n",
    "from pythresh.thresholds.filter import FILTER\n",
    "from pythresh.thresholds.wind import WIND\n",
    "from pythresh.thresholds.eb import EB\n",
    "from pythresh.thresholds.regr import REGR\n",
    "from pythresh.thresholds.boot import BOOT\n",
    "from pythresh.thresholds.mcst import MCST\n",
    "from pythresh.thresholds.hist import HIST\n",
    "from pythresh.thresholds.moll import MOLL\n",
    "from pythresh.thresholds.chau import CHAU\n",
    "from pythresh.thresholds.gesd import GESD\n",
    "from pythresh.thresholds.mtt import MTT\n",
    "from pythresh.thresholds.karch import KARCH\n",
    "from pythresh.thresholds.ocsvm import OCSVM\n",
    "from pythresh.thresholds.clust import CLUST\n",
    "from pythresh.thresholds.decomp import DECOMP\n",
    "from pythresh.thresholds.meta import META\n",
    "from pythresh.thresholds.vae import VAE\n",
    "from pythresh.thresholds.cpd import CPD\n",
    "from pythresh.thresholds.gamgmm import GAMGMM\n",
    "from pythresh.thresholds.mixmod import MIXMOD\n",
    "\n",
    "from pytorch_tabular.config import DataConfig, OptimizerConfig, TrainerConfig\n",
    "from pytorch_tabular.models.common.heads import LinearHeadConfig\n",
    "from pytorch_tabular.models import CategoryEmbeddingModelConfig\n",
    "from pytorch_tabular import model_sweep\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src.models.tabular.widedeep.tab_net import WDTabNetModel\n",
    "from src.tasks.metrics import get_cls_pred_metrics, get_cls_prob_metrics\n",
    "\n",
    "\n",
    "def split_stratified_into_train_val_test(df_input, stratify_colname='y',\n",
    "                                         frac_train=0.6, frac_val=0.15, frac_test=0.25,\n",
    "                                         random_state=None):\n",
    "    '''\n",
    "    Splits a Pandas dataframe into three subsets (train, val, and test)\n",
    "    following fractional ratios provided by the user, where each subset is\n",
    "    stratified by the values in a specific column (that is, each subset has\n",
    "    the same relative frequency of the values in the column). It performs this\n",
    "    splitting by running train_test_split() twice.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df_input : Pandas dataframe\n",
    "        Input dataframe to be split.\n",
    "    stratify_colname : str\n",
    "        The name of the column that will be used for stratification. Usually\n",
    "        this column would be for the label.\n",
    "    frac_train : float\n",
    "    frac_val   : float\n",
    "    frac_test  : float\n",
    "        The ratios with which the dataframe will be split into train, val, and\n",
    "        test data. The values should be expressed as float fractions and should\n",
    "        sum to 1.0.\n",
    "    random_state : int, None, or RandomStateInstance\n",
    "        Value to be passed to train_test_split().\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df_train, df_val, df_test :\n",
    "        Dataframes containing the three splits.\n",
    "    '''\n",
    "\n",
    "    if frac_train + frac_val + frac_test != 1.0:\n",
    "        raise ValueError('fractions %f, %f, %f do not add up to 1.0' % \\\n",
    "                         (frac_train, frac_val, frac_test))\n",
    "\n",
    "    if stratify_colname not in df_input.columns:\n",
    "        raise ValueError('%s is not a column in the dataframe' % (stratify_colname))\n",
    "\n",
    "    X = df_input # Contains all columns.\n",
    "    y = df_input[[stratify_colname]] # Dataframe of just the column on which to stratify.\n",
    "\n",
    "    # Split original dataframe into train and temp dataframes.\n",
    "    df_train, df_temp, y_train, y_temp = train_test_split(X,\n",
    "                                                          y,\n",
    "                                                          stratify=y,\n",
    "                                                          test_size=(1.0 - frac_train),\n",
    "                                                          random_state=random_state)\n",
    "\n",
    "    # Split the temp dataframe into val and test dataframes.\n",
    "    relative_frac_test = frac_test / (frac_val + frac_test)\n",
    "    df_val, df_test, y_val, y_test = train_test_split(df_temp,\n",
    "                                                      y_temp,\n",
    "                                                      stratify=y_temp,\n",
    "                                                      test_size=relative_frac_test,\n",
    "                                                      random_state=random_state)\n",
    "\n",
    "    assert len(df_input) == len(df_train) + len(df_val) + len(df_test)\n",
    "\n",
    "    return df_train, df_val, df_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Load data and model, define PyTorchClassifier, setup colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T14:06:14.901149Z",
     "start_time": "2024-07-08T14:06:14.896146Z"
    }
   },
   "outputs": [],
   "source": [
    "model_type = 'widedeep_tab_net'\n",
    "model_fn = 'best_fold_0000'\n",
    "model_version = 'v2'\n",
    "\n",
    "path_load = 'D:/YandexDisk/Work/pydnameth/datasets/GPL21145/GSEUNN/special/046_adversarial_robustness_toolbox/dnam'\n",
    "path = \"D:/YandexDisk/Work/pydnameth/datasets/GPL21145/GSEUNN\"\n",
    "path_save = f\"{path}/special/064_tai_report_4/dnam\"\n",
    "pathlib.Path(f\"{path_save}\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T14:06:16.809256Z",
     "start_time": "2024-07-08T14:06:16.593913Z"
    }
   },
   "outputs": [],
   "source": [
    "feats = pd.read_excel(f\"{path_load}/feats_1000.xlsx\", index_col=0).index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-07-08T14:06:18.763842Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(f\"{path_load}/betas.xlsx\", index_col=0)\n",
    "ids_feat = list(range(len(feats)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.read_excel(f\"{path_load}/models/{model_type}/{model_version}/predictions.xlsx\", index_col=0)\n",
    "df.loc[df.index, ['Real', 'Pred', 'Prob Control', 'Prob Parkinson']] = df_pred.loc[df.index, ['Status', 'pred', 'pred_prob_0', 'pred_prob_1']].values\n",
    "df['Data'] = 'Real'\n",
    "df['Eps'] = 'Origin'\n",
    "\n",
    "col_real = 'Real'\n",
    "col_pred = 'Pred'\n",
    "\n",
    "ids_trn_val = df.index[df['Partition'] == 'trn_val'].values\n",
    "ids_tst = df.index[df['Partition'] == 'tst'].values\n",
    "ids_all = df.index[df['Partition'].isin(['trn_val', 'tst'])].values\n",
    "ids_dict = {\n",
    "    'trn_val': ids_trn_val,\n",
    "    'tst': ids_tst,\n",
    "    'all': ids_all,\n",
    "}\n",
    "\n",
    "model = WDTabNetModel.load_from_checkpoint(checkpoint_path=f\"{path_load}/models/{model_type}/{model_version}/{model_fn}.ckpt\")\n",
    "model.produce_probabilities = False\n",
    "model.eval()\n",
    "model.freeze()\n",
    "\n",
    "art_classifier = PyTorchClassifier(\n",
    "    model=model,\n",
    "    loss=model.loss_fn,\n",
    "    input_shape=(len(feats),),\n",
    "    nb_classes=2,\n",
    "    optimizer=torch.optim.Adam(\n",
    "        params=model.parameters(),\n",
    "        lr=model.hparams.optimizer_lr,\n",
    "        weight_decay=model.hparams.optimizer_weight_decay\n",
    "    ),\n",
    "    use_amp=False,\n",
    "    opt_level=\"O1\",\n",
    "    loss_scale=\"dynamic\",\n",
    "    channels_first=True,\n",
    "    clip_values=(0.0, 1.0),\n",
    "    preprocessing_defences=None,\n",
    "    postprocessing_defences=None,\n",
    "    preprocessing=(0.0, 1.0),\n",
    "    device_type=\"cpu\"\n",
    ")\n",
    "\n",
    "colors_atks_eps = {\n",
    "    \"MomentumIterative\": px.colors.qualitative.D3[0],\n",
    "    \"BasicIterative\": px.colors.qualitative.D3[1],\n",
    "    \"ProjectedGradientDescent\": px.colors.qualitative.D3[2],\n",
    "    \"FastGradient\": px.colors.qualitative.D3[3],\n",
    "}\n",
    "colors_atks_bss = {\n",
    "    \"ElasticNet\": px.colors.qualitative.G10[7],\n",
    "    \"CarliniL2Method\": px.colors.qualitative.G10[8],\n",
    "    \"ZooAttack\": px.colors.qualitative.G10[9],\n",
    "}\n",
    "colors_atks_eta = {\n",
    "    'NewtonFool': px.colors.qualitative.T10[7],\n",
    "}\n",
    "\n",
    "df.to_excel(f\"{path_save}/df_origin.xlsx\", index_label='sample_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Create pyod and pythresh models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    'ECDF-Based (ECOD)': ECOD(),\n",
    "    'Copula-Based (COPOD)': COPOD(),\n",
    "    # 'Stochastic (SOS)': SOS(),\n",
    "    # 'Quasi-Monte Carlo Discrepancy (QMCD)': QMCDOD(),\n",
    "    # 'Rapid distance-based via Sampling': Sampling(),\n",
    "    # 'Probabilistic Mixture Modeling (GMM)': GMM(),\n",
    "    'Principal Component Analysis (PCA)': PCA(),\n",
    "    'Local Outlier Factor (LOF)': LOF(),\n",
    "    'Connectivity-Based Outlier Factor (COF)': COF(),\n",
    "    'Clustering-Based Local Outlier Factor (CBLOF)': CBLOF(),\n",
    "    'Histogram-based Outlier Score (HBOS)': HBOS(),\n",
    "    'k Nearest Neighbors (kNN)': KNN(),\n",
    "    'Subspace Outlier Detection (SOD)': SOD(),\n",
    "    'Isolation Forest': IForest(),\n",
    "    'Isolation-Based with Nearest-Neighbor Ensembles (INNE)': INNE(),\n",
    "    'Deep Isolation Forest for Anomaly Detection (DIF)': DIF(),\n",
    "    'Feature Bagging': FeatureBagging(),\n",
    "    'Lightweight On-line Detector of Anomalies (LODA)': LODA(),\n",
    "    # 'LUNAR': LUNAR()\n",
    "}\n",
    "\n",
    "thresholders = {\n",
    "        'Inter-Quartile Region (IQR)':IQR(),\n",
    "        'Median Absolute Deviation (MAD)':MAD(),\n",
    "        'Full Width at Full Minimum (FWFM)':FWFM(),\n",
    "        'Yeo-Johnson Transformation (YJ)': YJ(),\n",
    "        'Z Score (ZSCORE)': ZSCORE(),\n",
    "        'AUC Percentage (AUCP)': AUCP(),\n",
    "        'Quasi-Monte Carlo Discreperancy (QMCD)': QMCD(),\n",
    "        'Fixed Gradient Descent (FGD)': FGD(),\n",
    "        'Distance Shift from Normal (DSN)': DSN(),\n",
    "        'Trained Classifier (CLF)': CLF(),\n",
    "        'Filtering Based (FILTER)': FILTER(),\n",
    "        # 'Topological Winding Number (WIND)': WIND(),\n",
    "        'Elliptical Boundary (EB)': EB(),\n",
    "        'Regression Intercept (REGR)': REGR(),\n",
    "        # 'Bootstrap Method (BOOT)': BOOT(),\n",
    "        # 'Monte Carlo Statistical Tests (MCST)': MCST(),\n",
    "        'Histogram Based Methods (HIST)': HIST(),\n",
    "        # 'Mollifier (MOLL)': MOLL(),\n",
    "        \"Chauvenet's Criterion (CHAU)\": CHAU(),\n",
    "        'Generalized Extreme Studentized Deviate (GESD)': GESD(),\n",
    "        'Modified Thompson Tau Test (MTT)': MTT(),\n",
    "        'Karcher Mean (KARCH)': KARCH(),\n",
    "        'One-Class SVM (OCSVM)': OCSVM(),\n",
    "        'Clustering (CLUST)': CLUST(),\n",
    "        'Decomposition (DECOMP)': DECOMP(),\n",
    "        'Meta-model (META)': META(),\n",
    "        'Variational Autoencoder (VAE)': VAE(),\n",
    "        'Change Point Detection (CPD)': CPD(),\n",
    "        'Bayesian Gamma GMM (GAMGMM)': GAMGMM(skip=True),\n",
    "        'Mixture Models (MIXMOD)': MIXMOD(),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outliers for original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "    warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "    warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
    "    warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "\n",
    "    df_outs = pd.DataFrame(index=list(classifiers.keys()), columns=list(thresholders.keys()))\n",
    "    for pyod_m_name, pyod_m in classifiers.items():\n",
    "        print(pyod_m_name)\n",
    "        scores = pyod_m.fit(df.loc[ids_tst, feats].values).decision_scores_\n",
    "        for pythresh_m_name, pythresh_m in thresholders.items():\n",
    "            labels = pythresh_m.eval(scores)\n",
    "            df_outs.at[pyod_m_name, pythresh_m_name] = sum(labels) / len(labels) * 100\n",
    "    df_outs.to_excel(f\"{path_save}/outliers.xlsx\")\n",
    "    \n",
    "    df_fig = df_outs.astype(float)\n",
    "    sns.set_theme(style='ticks', font_scale=1.0)\n",
    "    fig, ax = plt.subplots(figsize=(16, 7))\n",
    "    heatmap = sns.heatmap(\n",
    "        df_fig,\n",
    "        annot=True,\n",
    "        fmt=\".1f\",\n",
    "        cmap='hot',\n",
    "        linewidth=0.1,\n",
    "        linecolor='black',\n",
    "        cbar_kws={\n",
    "            'orientation': 'horizontal',\n",
    "            'location': 'top',\n",
    "            'pad': 0.025,\n",
    "            'aspect': 30\n",
    "        },\n",
    "        annot_kws={\"size\": 12},\n",
    "        ax=ax\n",
    "    )\n",
    "    ax.set_xlabel('Outliers Detection Algorithms')\n",
    "    ax.set_ylabel('Thresholding Algorithms')\n",
    "    heatmap_pos = heatmap.get_position()\n",
    "    ax.figure.axes[-1].set_title(\"Outliers' percentage\")\n",
    "    ax.figure.axes[-1].tick_params()\n",
    "    for spine in ax.figure.axes[-1].spines.values():\n",
    "        spine.set_linewidth(1)\n",
    "    plt.savefig(f\"{path_save}/outliers.png\", bbox_inches='tight', dpi=200)\n",
    "    plt.savefig(f\"{path_save}/outliers.pdf\", bbox_inches='tight')\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Adversarial attacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eps-depended attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = sorted(list(set.union(\n",
    "    set(np.linspace(0.1, 1.0, 10)), \n",
    "    set(np.linspace(0.01, 0.1, 10)),\n",
    "    set(np.linspace(0.001, 0.01, 10))\n",
    ")))\n",
    "df_eps = pd.DataFrame(index=epsilons)\n",
    "\n",
    "\n",
    "for eps_raw in epsilons:\n",
    "\n",
    "    eps = np.array([eps_raw * scipy.stats.iqr(df.loc[ids_tst, feat].values) for feat in feats])\n",
    "    eps_step = np.array([0.2 * eps_raw * scipy.stats.iqr(df.loc[ids_tst, feat].values) for feat in feats])\n",
    "\n",
    "    attacks = {\n",
    "        'MomentumIterative': MomentumIterativeMethod(\n",
    "            estimator=art_classifier,\n",
    "            norm=np.inf,\n",
    "            eps=eps,\n",
    "            eps_step=eps_step,\n",
    "            decay=0.1,\n",
    "            max_iter=100,\n",
    "            targeted=False,\n",
    "            batch_size=512,\n",
    "            verbose=True\n",
    "        ),\n",
    "        'BasicIterative': BasicIterativeMethod(\n",
    "            estimator=art_classifier,\n",
    "            eps=eps,\n",
    "            eps_step=eps_step,\n",
    "            max_iter=100,\n",
    "            targeted=False,\n",
    "            batch_size=512,\n",
    "            verbose=True\n",
    "        ),\n",
    "        'FastGradient': FastGradientMethod(\n",
    "            estimator=art_classifier,\n",
    "            norm=np.inf,\n",
    "            eps=eps,\n",
    "            eps_step=eps_step,\n",
    "            targeted=False,\n",
    "            num_random_init=0,\n",
    "            batch_size=512,\n",
    "            minimal=False,\n",
    "            summary_writer=False,\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    for attack_name, attack in attacks.items():\n",
    "        path_curr = f\"{path_save}/Evasion/{attack_name}/eps_{eps_raw:0.4f}\"\n",
    "        pathlib.Path(f\"{path_curr}\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        X_adv = attack.generate(np.float32(df.loc[ids_tst, feats].values))\n",
    "        \n",
    "        df_adv = df.loc[ids_tst, ['Real']].copy()\n",
    "        df_adv.loc[ids_tst, feats] = X_adv\n",
    "        model.produce_probabilities = True\n",
    "        y_pred_prob = model(torch.from_numpy(np.float32(df_adv.loc[ids_tst, feats].values))).cpu().detach().numpy()\n",
    "        y_pred = np.argmax(y_pred_prob, 1)\n",
    "        df_adv[\"Pred\"] = y_pred\n",
    "        df_adv[\"Prob Control\"] = y_pred_prob[:, 0]\n",
    "        df_adv[\"Prob Parkinson\"] = y_pred_prob[:, 1]\n",
    "        df_adv[\"Eps\"] = eps_raw\n",
    "        df_adv[\"Data\"] = attack_name\n",
    "        \n",
    "        df_adv.to_excel(f\"{path_curr}/df.xlsx\", index_label='sample_id')\n",
    "\n",
    "        metrics_pred = get_cls_pred_metrics(num_classes=2)\n",
    "        metrics_prob = get_cls_prob_metrics(num_classes=2)\n",
    "        df_metrics = pd.DataFrame(index=list(metrics_pred.keys()) + list(metrics_prob.keys()))\n",
    "        y_real = torch.from_numpy(df_adv.loc[ids_tst, \"Real\"].values.astype('int32'))\n",
    "        y_pred_atk = torch.from_numpy(df_adv.loc[ids_tst, \"Pred\"].values.astype('int32'))\n",
    "        y_pred_ori = torch.from_numpy(df.loc[ids_tst, \"Pred\"].values.astype('int32'))\n",
    "        y_prob_atk = torch.from_numpy(df_adv.loc[ids_tst, [\"Prob Control\", \"Prob Parkinson\"]].values)\n",
    "        y_prob_ori = torch.from_numpy(df.loc[ids_tst, [\"Prob Control\", \"Prob Parkinson\"]].values)\n",
    "        for m in metrics_pred:\n",
    "            m_val = float(metrics_pred[m][0](y_pred_atk, y_real).numpy())\n",
    "            metrics_pred[m][0].reset()\n",
    "            df_metrics.at[m, 'Attack'] = m_val\n",
    "            m_val = float(metrics_pred[m][0](y_pred_ori, y_real).numpy())\n",
    "            df_metrics.at[m, 'Origin'] = m_val\n",
    "            metrics_pred[m][0].reset()\n",
    "        for m in metrics_prob:\n",
    "            m_val = 0\n",
    "            try:\n",
    "                m_val = float(metrics_prob[m][0](y_prob_atk, y_real).numpy())\n",
    "            except ValueError:\n",
    "                pass\n",
    "            metrics_prob[m][0].reset()\n",
    "            df_metrics.at[m, 'Attack'] = m_val\n",
    "            m_val = 0\n",
    "            try:\n",
    "                m_val = float(metrics_prob[m][0](y_prob_ori, y_real).numpy())\n",
    "            except ValueError:\n",
    "                pass\n",
    "            metrics_prob[m][0].reset()\n",
    "            df_metrics.at[m, 'Origin'] = m_val\n",
    "            \n",
    "        df_metrics.to_excel(f\"{path_curr}/metrics.xlsx\", index_label='Metrics')\n",
    "        \n",
    "        if attack_name == 'MomentumIterative':\n",
    "            df_eps.loc[eps_raw, \"Origin_Accuracy\"] = df_metrics.at['accuracy_weighted', 'Origin']\n",
    "        df_eps.loc[eps_raw, f\"{attack_name}_Accuracy\"] = df_metrics.at['accuracy_weighted', 'Attack']\n",
    "            \n",
    "df_eps.to_excel(f\"{path_save}/Evasion/df_eps.xlsx\", index_label='eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eps = pd.read_excel(f\"{path_save}/Evasion/df_eps.xlsx\", index_col=0)\n",
    "\n",
    "atks_trgt = ['MomentumIterative', 'BasicIterative', 'FastGradient']\n",
    "\n",
    "df_fig = df_eps.loc[:, [f\"{x}_Accuracy\" for x in atks_trgt]].copy()\n",
    "df_fig.rename(columns={f\"{x}_Accuracy\": x for x in atks_trgt}, inplace=True)\n",
    "df_fig['Eps'] = df_fig.index.values\n",
    "df_fig = df_fig.melt(id_vars=\"Eps\", var_name='Method', value_name=\"Accuracy\")\n",
    "fig = plt.figure()\n",
    "sns.set_theme(style='whitegrid', font_scale=1)\n",
    "lines = sns.lineplot(\n",
    "    data=df_fig,\n",
    "    x='Eps',\n",
    "    y=\"Accuracy\",\n",
    "    hue=f\"Method\",\n",
    "    style=f\"Method\",\n",
    "    palette=colors_atks_eps,\n",
    "    hue_order=atks_trgt,\n",
    "    markers=True,\n",
    "    dashes=False,\n",
    ")\n",
    "plt.xscale('log')\n",
    "lines.set_xlabel(r'$\\epsilon$')\n",
    "x_min = 0.0009\n",
    "x_max = 1.05\n",
    "basic = df_eps.at[0.01, f\"Origin_Accuracy\"]\n",
    "lines.set_xlim(x_min, x_max)\n",
    "plt.gca().plot(\n",
    "    [x_min, x_max],\n",
    "    [basic, basic],\n",
    "    color='k',\n",
    "    linestyle='dashed',\n",
    "    linewidth=1\n",
    ")\n",
    "plt.savefig(f\"{path_save}/Evasion/line_accuracy_vs_eps.png\", bbox_inches='tight', dpi=200)\n",
    "plt.savefig(f\"{path_save}/Evasion/line_accuracy_vs_eps.pdf\", bbox_inches='tight')\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Search Steps attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsss = list(range(1, 11, 1))\n",
    "df_bss = pd.DataFrame(index=bsss)\n",
    "\n",
    "for bss in [10]:\n",
    "\n",
    "    attacks = {\n",
    "        # 'ElasticNet': ElasticNet(\n",
    "        #     classifier=art_classifier,\n",
    "        #     confidence=0.0,\n",
    "        #     targeted=False,\n",
    "        #     learning_rate=1e-3,\n",
    "        #     binary_search_steps=bss,\n",
    "        #     max_iter=20,\n",
    "        #     beta=1e-3,\n",
    "        #     initial_const=1e-4,\n",
    "        #     batch_size=1,\n",
    "        #     decision_rule=\"EN\",\n",
    "        #     verbose=True,\n",
    "        # ),\n",
    "        'CarliniL2Method': CarliniL2Method(\n",
    "            classifier=art_classifier,\n",
    "            confidence=0.0,\n",
    "            targeted=False,\n",
    "            learning_rate=0.001,\n",
    "            binary_search_steps=bss,\n",
    "            max_iter=20,\n",
    "            initial_const=1e-4,\n",
    "            max_halving=5,\n",
    "            max_doubling=5,\n",
    "            batch_size=1,\n",
    "            verbose=True\n",
    "        ),\n",
    "        # 'ZooAttack': ZooAttack(\n",
    "        #     classifier=art_classifier,\n",
    "        #     confidence=0.0,\n",
    "        #     targeted=False,\n",
    "        #     learning_rate=0.001,\n",
    "        #     max_iter=20,\n",
    "        #     binary_search_steps=bss,\n",
    "        #     initial_const=1e-4,\n",
    "        #     abort_early=True,\n",
    "        #     use_resize=False,\n",
    "        #     use_importance=True,\n",
    "        #     nb_parallel=16,\n",
    "        #     batch_size=1,\n",
    "        #     variable_h=0.001,\n",
    "        #     verbose=True\n",
    "        # ),\n",
    "    }\n",
    "\n",
    "    for attack_name, attack in attacks.items():\n",
    "        path_curr = f\"{path_save}/Evasion/{attack_name}/bss_{bss}\"\n",
    "        pathlib.Path(f\"{path_curr}\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        X_adv = attack.generate(np.float32(df.loc[ids_tst, feats].values))\n",
    "        \n",
    "        df_adv = df.loc[ids_tst, ['Real']].copy()\n",
    "        df_adv.loc[ids_tst, feats] = X_adv\n",
    "        model.produce_probabilities = True\n",
    "        y_pred_prob = model(torch.from_numpy(np.float32(df_adv.loc[ids_tst, feats].values))).cpu().detach().numpy()\n",
    "        y_pred = np.argmax(y_pred_prob, 1)\n",
    "        df_adv[\"Pred\"] = y_pred\n",
    "        df_adv[\"Prob Control\"] = y_pred_prob[:, 0]\n",
    "        df_adv[\"Prob Parkinson\"] = y_pred_prob[:, 1]\n",
    "        df_adv[\"BSS\"] = bss\n",
    "        df_adv[\"Data\"] = attack_name\n",
    "            \n",
    "        df_adv.to_excel(f\"{path_curr}/df.xlsx\", index_label='sample_id')\n",
    "\n",
    "        metrics_pred = get_cls_pred_metrics(num_classes=2)\n",
    "        metrics_prob = get_cls_prob_metrics(num_classes=2)\n",
    "        df_metrics = pd.DataFrame(index=list(metrics_pred.keys()) + list(metrics_prob.keys()))\n",
    "        y_real = torch.from_numpy(df_adv.loc[ids_tst, \"Real\"].values.astype('int32'))\n",
    "        y_pred_atk = torch.from_numpy(df_adv.loc[ids_tst, \"Pred\"].values.astype('int32'))\n",
    "        y_pred_ori = torch.from_numpy(df.loc[ids_tst, \"Pred\"].values.astype('int32'))\n",
    "        y_prob_atk = torch.from_numpy(df_adv.loc[ids_tst, [\"Prob Control\", \"Prob Parkinson\"]].values)\n",
    "        y_prob_ori = torch.from_numpy(df.loc[ids_tst, [\"Prob Control\", \"Prob Parkinson\"]].values)\n",
    "        for m in metrics_pred:\n",
    "            m_val = float(metrics_pred[m][0](y_pred_atk, y_real).numpy())\n",
    "            metrics_pred[m][0].reset()\n",
    "            df_metrics.at[m, 'Attack'] = m_val\n",
    "            m_val = float(metrics_pred[m][0](y_pred_ori, y_real).numpy())\n",
    "            df_metrics.at[m, 'Origin'] = m_val\n",
    "            metrics_pred[m][0].reset()\n",
    "        for m in metrics_prob:\n",
    "            m_val = 0\n",
    "            try:\n",
    "                m_val = float(metrics_prob[m][0](y_prob_atk, y_real).numpy())\n",
    "            except ValueError:\n",
    "                pass\n",
    "            metrics_prob[m][0].reset()\n",
    "            df_metrics.at[m, 'Attack'] = m_val\n",
    "            m_val = 0\n",
    "            try:\n",
    "                m_val = float(metrics_prob[m][0](y_prob_ori, y_real).numpy())\n",
    "            except ValueError:\n",
    "                pass\n",
    "            metrics_prob[m][0].reset()\n",
    "            df_metrics.at[m, 'Origin'] = m_val\n",
    "            \n",
    "        df_metrics.to_excel(f\"{path_curr}/metrics.xlsx\", index_label='Metrics')\n",
    "        \n",
    "        if attack_name == 'ElasticNet':\n",
    "            df_bss.loc[bss, \"Origin_Accuracy\"] = df_metrics.at['accuracy_weighted', 'Origin']\n",
    "        df_bss.loc[bss, f\"{attack_name}_Accuracy\"] = df_metrics.at['accuracy_weighted', 'Attack']\n",
    "            \n",
    "df_bss.to_excel(f\"{path_save}/Evasion/df_bss.xlsx\", index_label='eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bss = pd.read_excel(f\"{path_save}/Evasion/df_bss.xlsx\", index_col=0)\n",
    "\n",
    "atks_trgt = ['ElasticNet', 'CarliniL2Method', 'ZooAttack']\n",
    "\n",
    "df_fig = df_bss.loc[:, [f\"{x}_Accuracy\" for x in atks_trgt]].copy()\n",
    "df_fig.rename(columns={f\"{x}_Accuracy\": x for x in atks_trgt}, inplace=True)\n",
    "df_fig['BSS'] = df_fig.index.values\n",
    "df_fig = df_fig.melt(id_vars=\"BSS\", var_name='Method', value_name=\"Accuracy\")\n",
    "fig = plt.figure()\n",
    "sns.set_theme(style='whitegrid', font_scale=1)\n",
    "lines = sns.lineplot(\n",
    "    data=df_fig,\n",
    "    x='BSS',\n",
    "    y=\"Accuracy\",\n",
    "    hue=f\"Method\",\n",
    "    style=f\"Method\",\n",
    "    palette=colors_atks_bss,\n",
    "    hue_order=atks_trgt,\n",
    "    markers=True,\n",
    "    dashes=False,\n",
    ")\n",
    "lines.set_xlabel('BSS')\n",
    "basic = pd.read_excel(f\"{path_save}/Evasion/ElasticNet/bss_1/metrics.xlsx\", index_col=0).at['accuracy_weighted', 'Origin']\n",
    "x_min = 0.5\n",
    "x_max = 10.5\n",
    "lines.set_xlim(x_min, x_max)\n",
    "plt.gca().plot(\n",
    "    [x_min, x_max],\n",
    "    [basic, basic],\n",
    "    color='k',\n",
    "    linestyle='dashed',\n",
    "    linewidth=1\n",
    ")\n",
    "plt.savefig(f\"{path_save}/Evasion/line_accuracy_vs_bss.png\", bbox_inches='tight', dpi=200)\n",
    "plt.savefig(f\"{path_save}/Evasion/line_accuracy_vs_bss.pdf\", bbox_inches='tight')\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eta-depended attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etas = sorted(list(set.union(\n",
    "    set(np.linspace(0.1, 1.0, 10)), \n",
    "    set(np.linspace(0.01, 0.1, 10)),\n",
    "    set(np.linspace(0.001, 0.01, 10))\n",
    ")))\n",
    "\n",
    "df_etas = pd.DataFrame(index=etas)\n",
    "\n",
    "for eta in etas:\n",
    "\n",
    "    attacks = {\n",
    "        'NewtonFool': NewtonFool(\n",
    "            classifier=art_classifier,\n",
    "            max_iter=100,\n",
    "            eta=eta,\n",
    "            batch_size=100,\n",
    "            verbose=True,\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    for attack_name, attack in attacks.items():\n",
    "        path_curr = f\"{path_save}/Evasion/{attack_name}/eta_{eta:0.2e}\"\n",
    "        pathlib.Path(f\"{path_curr}\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        X_adv = attack.generate(np.float32(df.loc[ids_atk, feats].values))\n",
    "        \n",
    "        df_adv = df.loc[ids_atk, ['Real']].copy()\n",
    "        df_adv.loc[ids_atk, feats] = X_adv\n",
    "        model.produce_probabilities = True\n",
    "        y_pred_prob = model(torch.from_numpy(np.float32(df_adv.loc[ids_atk, feats].values))).cpu().detach().numpy()\n",
    "        y_pred = np.argmax(y_pred_prob, 1)\n",
    "        df_adv[\"Pred\"] = y_pred\n",
    "        df_adv[\"Prob Control\"] = y_pred_prob[:, 0]\n",
    "        df_adv[\"Prob Parkinson\"] = y_pred_prob[:, 1]\n",
    "        df_adv[\"Eta\"] = f\"{eta:0.2e}\"\n",
    "        df_adv[\"Data\"] = attack_name\n",
    "            \n",
    "        df_adv.to_excel(f\"{path_curr}/df.xlsx\", index_label='sample_id')\n",
    "\n",
    "        metrics_pred = get_cls_pred_metrics(num_classes=2)\n",
    "        metrics_prob = get_cls_prob_metrics(num_classes=2)\n",
    "        df_metrics = pd.DataFrame(index=list(metrics_pred.keys()) + list(metrics_prob.keys()))\n",
    "        y_real = torch.from_numpy(df_adv.loc[ids_atk, \"Real\"].values.astype('int32'))\n",
    "        y_pred_atk = torch.from_numpy(df_adv.loc[ids_atk, \"Pred\"].values.astype('int32'))\n",
    "        y_pred_ori = torch.from_numpy(df.loc[ids_atk, \"Pred\"].values.astype('int32'))\n",
    "        y_prob_atk = torch.from_numpy(df_adv.loc[ids_atk, [\"Prob Control\", \"Prob Parkinson\"]].values)\n",
    "        y_prob_ori = torch.from_numpy(df.loc[ids_atk, [\"Prob Control\", \"Prob Parkinson\"]].values)\n",
    "        for m in metrics_pred:\n",
    "            m_val = float(metrics_pred[m][0](y_pred_atk, y_real).numpy())\n",
    "            metrics_pred[m][0].reset()\n",
    "            df_metrics.at[m, 'Attack'] = m_val\n",
    "            m_val = float(metrics_pred[m][0](y_pred_ori, y_real).numpy())\n",
    "            df_metrics.at[m, 'Origin'] = m_val\n",
    "            metrics_pred[m][0].reset()\n",
    "        for m in metrics_prob:\n",
    "            m_val = 0\n",
    "            try:\n",
    "                m_val = float(metrics_prob[m][0](y_prob_atk, y_real).numpy())\n",
    "            except ValueError:\n",
    "                pass\n",
    "            metrics_prob[m][0].reset()\n",
    "            df_metrics.at[m, 'Attack'] = m_val\n",
    "            m_val = 0\n",
    "            try:\n",
    "                m_val = float(metrics_prob[m][0](y_prob_ori, y_real).numpy())\n",
    "            except ValueError:\n",
    "                pass\n",
    "            metrics_prob[m][0].reset()\n",
    "            df_metrics.at[m, 'Origin'] = m_val\n",
    "            \n",
    "        df_metrics.to_excel(f\"{path_curr}/metrics.xlsx\", index_label='Metrics')\n",
    "        \n",
    "        if attack_name == 'NewtonFool':\n",
    "            df_etas.loc[eta, \"Origin_Accuracy\"] = df_metrics.at['accuracy_weighted', 'Origin']\n",
    "        df_etas.loc[eta, f\"{attack_name}_Accuracy\"] = df_metrics.at['accuracy_weighted', 'Attack']\n",
    "            \n",
    "df_etas.to_excel(f\"{path_save}/Evasion/df_etas.xlsx\", index_label='eta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_etas = pd.read_excel(f\"{path_save}/Evasion/df_etas.xlsx\", index_col=0)\n",
    "\n",
    "atks_trgt = ['NewtonFool']\n",
    "\n",
    "df_fig = df_etas.loc[:, [f\"{x}_Accuracy\" for x in atks_trgt]].copy()\n",
    "df_fig.rename(columns={f\"{x}_Accuracy\": x for x in atks_trgt}, inplace=True)\n",
    "df_fig['Eta'] = df_fig.index.values\n",
    "df_fig = df_fig.melt(id_vars=\"Eta\", var_name='Method', value_name=\"Accuracy\")\n",
    "fig = plt.figure()\n",
    "sns.set_theme(style='whitegrid', font_scale=1)\n",
    "lines = sns.lineplot(\n",
    "    data=df_fig,\n",
    "    x='Eta',\n",
    "    y=\"Accuracy\",\n",
    "    hue=f\"Method\",\n",
    "    style=f\"Method\",\n",
    "    palette=colors_atks_eta,\n",
    "    hue_order=atks_trgt,\n",
    "    markers=True,\n",
    "    dashes=False,\n",
    ")\n",
    "plt.xscale('log')\n",
    "lines.set_xlabel(r'$\\eta$')\n",
    "x_min = 8e-4\n",
    "x_max = 1.1\n",
    "basic = df_etas.at[0.01, f\"Origin_Accuracy\"]\n",
    "lines.set_xlim(x_min, x_max)\n",
    "plt.gca().plot(\n",
    "    [x_min, x_max],\n",
    "    [basic, basic],\n",
    "    color='k',\n",
    "    linestyle='dashed',\n",
    "    linewidth=1\n",
    ")\n",
    "plt.savefig(f\"{path_save}/Evasion/line_accuracy_vs_eta.png\", bbox_inches='tight', dpi=200)\n",
    "plt.savefig(f\"{path_save}/Evasion/line_accuracy_vs_eta.pdf\", bbox_inches='tight')\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers for attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attacks_options = {\n",
    "    'Eps': {\n",
    "        'types': ['MomentumIterative', 'BasicIterative', 'FastGradient'],\n",
    "        'values': [0.005, 0.02, 0.05, 0.2]\n",
    "    },\n",
    "    'BSS': {\n",
    "        'types': ['ElasticNet', 'CarliniL2Method', 'ZooAttack'],\n",
    "        'values': [2, 4, 6, 8]\n",
    "    },\n",
    "    'Eta': {\n",
    "        'types': ['NewtonFool'],\n",
    "        'values': [1e-3, 2e-3, 3e-3, 1e-2]\n",
    "    },\n",
    "}\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "    warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "    warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
    "    warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "\n",
    "    for var_param, opt in attacks_options.items():\n",
    "        print(var_param)\n",
    "        for atk_type in opt['types']:\n",
    "            print(atk_type)\n",
    "            for var_val_id, var_val in enumerate(opt['values']):\n",
    "                print(var_val)\n",
    "                if var_param == 'Eps':\n",
    "                    path_curr = f\"{path_save}/Evasion/{atk_type}/eps_{var_val:0.4f}\"\n",
    "                    val_str = f'Eps = {var_val:0.4f}'\n",
    "                elif var_param == 'BSS':\n",
    "                    path_curr = f\"{path_save}/Evasion/{atk_type}/bss_{var_val}\"\n",
    "                    val_str = f'BSS = {var_val}'\n",
    "                else:\n",
    "                    path_curr = f\"{path_save}/Evasion/{atk_type}/eta_{var_val:0.2e}\"\n",
    "                    val_str = f'Eta = {var_val:0.2e}'\n",
    "                    \n",
    "                df_adv = pd.read_excel(f\"{path_curr}/df.xlsx\", index_col='sample_id')\n",
    "                \n",
    "                df_outs = pd.DataFrame(index=list(classifiers.keys()), columns=list(thresholders.keys()))\n",
    "                for pyod_m_name, pyod_m in classifiers.items():\n",
    "                    scores = pyod_m.fit(df_adv.loc[:, feats].values).decision_scores_\n",
    "                    for pythresh_m_name, pythresh_m in thresholders.items(): \n",
    "                        labels = pythresh_m.eval(scores)\n",
    "                        df_outs.at[pyod_m_name, pythresh_m_name] = sum(labels) / len(labels) * 100\n",
    "                        \n",
    "                df_outs.to_excel(f\"{path_curr}/outliers.xlsx\")\n",
    "                \n",
    "                df_fig = df_outs.astype(float)\n",
    "                sns.set_theme(style='ticks', font_scale=1.0)\n",
    "                fig, ax = plt.subplots(figsize=(16, 7))\n",
    "                heatmap = sns.heatmap(\n",
    "                    df_fig,\n",
    "                    annot=True,\n",
    "                    fmt=\".1f\",\n",
    "                    cmap='hot',\n",
    "                    linewidth=0.1,\n",
    "                    linecolor='black',\n",
    "                    cbar_kws={\n",
    "                        'orientation': 'horizontal',\n",
    "                        'location': 'top',\n",
    "                        'pad': 0.025,\n",
    "                        'aspect': 30\n",
    "                    },\n",
    "                    annot_kws={\"size\": 12},\n",
    "                    ax=ax\n",
    "                )\n",
    "                ax.set_xlabel('Outliers Detection Algorithms')\n",
    "                ax.set_ylabel('Thresholding Algorithms')\n",
    "                heatmap_pos = heatmap.get_position()\n",
    "                ax.figure.axes[-1].set_title(\"Outliers' percentage\")\n",
    "                ax.figure.axes[-1].tick_params()\n",
    "                for spine in ax.figure.axes[-1].spines.values():\n",
    "                    spine.set_linewidth(1)\n",
    "                plt.savefig(f\"{path_curr}/outliers.png\", bbox_inches='tight', dpi=200)\n",
    "                plt.savefig(f\"{path_curr}/outliers.pdf\", bbox_inches='tight')\n",
    "                plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial defences from attacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate detectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ori = df.loc[ids_tst, feats].copy()\n",
    "df_ori['Class'] = 'Original'\n",
    "\n",
    "epsilons = sorted(list(set.union(\n",
    "    set(np.linspace(0.1, 1.0, 10)), \n",
    "    set(np.linspace(0.01, 0.1, 10)),\n",
    "    set(np.linspace(0.001, 0.01, 10))\n",
    ")))\n",
    "bsss = list(range(1, 11, 1))\n",
    "etas = sorted(list(set.union(\n",
    "    set(np.linspace(0.1, 1.0, 10)), \n",
    "    set(np.linspace(0.01, 0.1, 10)),\n",
    "    set(np.linspace(0.001, 0.01, 10))\n",
    ")))\n",
    "\n",
    "attacks_options = {\n",
    "    'Eps': {\n",
    "        'types': ['MomentumIterative', 'BasicIterative', 'FastGradient'],\n",
    "        'values': epsilons\n",
    "    },\n",
    "    'BSS': {\n",
    "        'types': ['ElasticNet', 'CarliniL2Method', 'ZooAttack'],\n",
    "        'values': bsss\n",
    "    },\n",
    "    'Eta': {\n",
    "        'types': ['NewtonFool'],\n",
    "        'values': etas\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "for var_param, opt in attacks_options.items():\n",
    "    print(var_param)\n",
    "    datasets[var_param] = {}\n",
    "    for atk_type in opt['types']:\n",
    "        print(atk_type)\n",
    "        datasets[var_param][atk_type] = {}\n",
    "        for var_val_id, var_val in enumerate(opt['values']):\n",
    "            if var_param == 'Eps':\n",
    "                path_curr = f\"{path_save}/Evasion/{atk_type}/eps_{var_val:0.4f}\"\n",
    "                val_str = f'{var_val:0.4f}'\n",
    "            elif var_param == 'BSS':\n",
    "                path_curr = f\"{path_save}/Evasion/{atk_type}/bss_{var_val}\"\n",
    "                val_str = f'{var_val}'\n",
    "            else:\n",
    "                path_curr = f\"{path_save}/Evasion/{atk_type}/eta_{var_val:0.2e}\"\n",
    "                val_str = f'{var_val:0.2e}'\n",
    "            print(val_str)\n",
    "            df_adv = pd.read_excel(f\"{path_curr}/df.xlsx\", index_col=0)\n",
    "            df_adv = df_adv[feats]\n",
    "            df_adv['Class'] = 'Attack'\n",
    "            datasets[var_param][atk_type][val_str] = df_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "    warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "    warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
    "    warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "\n",
    "    for var_param, opt in attacks_options.items():\n",
    "        print(var_param)\n",
    "        for atk_type in opt['types']:\n",
    "            print(atk_type)\n",
    "            \n",
    "            df_def_acc = pd.DataFrame(index=opt['values'], columns=['Model'] + list(opt['values']))\n",
    "            \n",
    "            for var_val_id, var_val in enumerate(opt['values']):\n",
    "                print(var_val)\n",
    "                if var_param == 'Eps':\n",
    "                    path_curr = f\"{path_save}/Evasion/{atk_type}/eps_{var_val:0.4f}\"\n",
    "                    val_str = f'{var_val:0.4f}'\n",
    "                elif var_param == 'BSS':\n",
    "                    path_curr = f\"{path_save}/Evasion/{atk_type}/bss_{var_val}\"\n",
    "                    val_str = f'{var_val}'\n",
    "                else:\n",
    "                    path_curr = f\"{path_save}/Evasion/{atk_type}/eta_{var_val:0.2e}\"\n",
    "                    val_str = f'{var_val:0.2e}'\n",
    "                    \n",
    "                # df_adv = pd.read_excel(f\"{path_curr}/df.xlsx\", index_col='sample_id')\n",
    "                # df_adv = df_adv[feats]\n",
    "                # df_adv['Class'] = 'Attack'\n",
    "                df_adv = datasets[var_param][atk_type][val_str]\n",
    "                df_def = pd.concat([df_ori.loc[ids_tst, :], df_adv.loc[ids_tst, :]])\n",
    "                \n",
    "                df_def_trn, df_def_val, df_def_tst = split_stratified_into_train_val_test(\n",
    "                    df_def, \n",
    "                    stratify_colname='Class',\n",
    "                    frac_train=0.60,\n",
    "                    frac_val=0.20,\n",
    "                    frac_test=0.20\n",
    "                )\n",
    "                \n",
    "                data_config = DataConfig(\n",
    "                    target=['Class'],\n",
    "                    continuous_cols=list(feats),\n",
    "                    continuous_feature_transform='yeo-johnson',\n",
    "                    normalize_continuous_features=True,\n",
    "                )\n",
    "                \n",
    "                trainer_config = TrainerConfig(\n",
    "                    batch_size=1024,\n",
    "                    max_epochs=100,\n",
    "                    min_epochs=1,\n",
    "                    auto_lr_find=True,\n",
    "                    early_stopping='valid_loss',\n",
    "                    early_stopping_min_delta=0.0001,\n",
    "                    early_stopping_mode='min',\n",
    "                    early_stopping_patience=100,\n",
    "                    checkpoints='valid_loss',\n",
    "                    checkpoints_path=f\"{path_curr}/detector\",\n",
    "                    load_best=True,\n",
    "                    progress_bar='none',\n",
    "                    seed=42\n",
    "                )\n",
    "                \n",
    "                optimizer_config = OptimizerConfig(\n",
    "                    optimizer='Adam',\n",
    "                    lr_scheduler='CosineAnnealingWarmRestarts',\n",
    "                    lr_scheduler_params={\n",
    "                        'T_0': 10,\n",
    "                        'T_mult': 1,\n",
    "                        'eta_min': 0.00001,\n",
    "                    },\n",
    "                    lr_scheduler_monitor_metric='valid_loss'\n",
    "                )\n",
    "        \n",
    "                head_config = LinearHeadConfig(\n",
    "                    layers='',\n",
    "                    activation='ReLU',\n",
    "                    dropout=0.1,\n",
    "                    use_batch_norm=False,\n",
    "                    initialization='xavier',\n",
    "                ).__dict__\n",
    "                \n",
    "                model_config = CategoryEmbeddingModelConfig(\n",
    "                    task=\"classification\",\n",
    "                    layers=\"256-128-64\",\n",
    "                    activation=\"LeakyReLU\",\n",
    "                    dropout=0.1,\n",
    "                    initialization=\"kaiming\",\n",
    "                    head=\"LinearHead\",\n",
    "                    head_config=head_config,\n",
    "                    learning_rate=1e-3,\n",
    "                )\n",
    "                \n",
    "                # model_list = [model_config]\n",
    "                model_list = 'lite'\n",
    "        \n",
    "                with warnings.catch_warnings():\n",
    "                    warnings.simplefilter(\"ignore\")\n",
    "                    sweep_df, best_model = model_sweep(\n",
    "                        task=\"classification\",\n",
    "                        train=df_def_trn,\n",
    "                        validation=df_def_val,\n",
    "                        test=df_def_tst,\n",
    "                        data_config=data_config,\n",
    "                        optimizer_config=optimizer_config,\n",
    "                        trainer_config=trainer_config,\n",
    "                        model_list=model_list,\n",
    "                        common_model_args=dict(head=\"LinearHead\", head_config=head_config),\n",
    "                        metrics=[\n",
    "                            'accuracy',\n",
    "                            'f1_score',\n",
    "                            'precision',\n",
    "                            'recall',\n",
    "                            'specificity',\n",
    "                            'cohen_kappa',\n",
    "                            'auroc'\n",
    "                        ],\n",
    "                        metrics_prob_input=[True, True, True, True, True, True, True],\n",
    "                        metrics_params=[\n",
    "                            {'task': 'multiclass', 'num_classes': 2, 'average': 'weighted'},\n",
    "                            {'task': 'multiclass', 'num_classes': 2, 'average': 'weighted'},\n",
    "                            {'task': 'multiclass', 'num_classes': 2, 'average': 'weighted'},\n",
    "                            {'task': 'multiclass', 'num_classes': 2, 'average': 'weighted'},\n",
    "                            {'task': 'multiclass', 'num_classes': 2, 'average': 'weighted'},\n",
    "                            {'task': 'multiclass', 'num_classes': 2},\n",
    "                            {'task': 'multiclass', 'num_classes': 2, 'average': 'weighted'},\n",
    "                        ],\n",
    "                        rank_metric=(\"accuracy\", \"higher_is_better\"),\n",
    "                        progress_bar=False,\n",
    "                        verbose=False,\n",
    "                        suppress_lightning_logger=True,\n",
    "                    )\n",
    "                ckpts = glob(f\"{path_curr}/detector/*\")\n",
    "                for ckpt in ckpts:\n",
    "                    os.remove(ckpt)\n",
    "                # best_model.save_model(f\"{path_curr}/detector\")\n",
    "                df_def_acc.at[var_val, 'Model'] = best_model.config['_model_name']\n",
    "                \n",
    "                for tst_var_val_id, tst_var_val in enumerate(opt['values']):\n",
    "                    if tst_var_val != var_val:\n",
    "                        print(f\"Testing: {tst_var_val}\")\n",
    "                        if var_param == 'Eps':\n",
    "                            path_tst = f\"{path_save}/Evasion/{atk_type}/eps_{tst_var_val:0.4f}\"\n",
    "                            val_str_tst = f'{tst_var_val:0.4f}'\n",
    "                        elif var_param == 'BSS':\n",
    "                            path_tst = f\"{path_save}/Evasion/{atk_type}/bss_{tst_var_val}\"\n",
    "                            val_str_tst = f'{tst_var_val}'\n",
    "                        else:\n",
    "                            path_tst = f\"{path_save}/Evasion/{atk_type}/eta_{tst_var_val:0.2e}\"\n",
    "                            val_str_tst = f'{tst_var_val:0.2e}'\n",
    "\n",
    "                        # df_adv_tst = pd.read_excel(f\"{path_tst}/df.xlsx\", index_col='sample_id')\n",
    "                        # df_adv_tst = df_adv_tst[feats]\n",
    "                        # df_adv_tst['Class'] = 'Attack'\n",
    "                        df_adv_tst = datasets[var_param][atk_type][val_str_tst]\n",
    "\n",
    "                        df_def_tst_eps = pd.concat([df_ori, df_adv_tst])\n",
    "                        metrics = best_model.evaluate(test=df_def_tst_eps, verbose=False)[0]\n",
    "                        df_def_acc.at[var_val, tst_var_val] = metrics['test_accuracy']\n",
    "            df_def_acc.to_excel(f\"{path_save}/Evasion/{atk_type}/detectors_accuracy.xlsx\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot detectors accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var_param, opt in attacks_options.items():\n",
    "        print(var_param)\n",
    "\n",
    "        for atk_type in opt['types']:\n",
    "            print(atk_type)\n",
    "            df_def_acc = pd.read_excel(f\"{path_save}/Evasion/{atk_type}/detectors_accuracy.xlsx\", index_col=0)\n",
    "            df_def_acc.drop(['Model'], axis=1, inplace=True)\n",
    "\n",
    "            if var_param == 'Eps':\n",
    "                figsize=(13, 12)\n",
    "                df_def_acc.rename(columns={x: f\"{x:.3f}\" for x in df_def_acc.columns}, inplace=True)\n",
    "                df_def_acc['index'] = [f\"{x:.3f}\" for x in df_def_acc.index.values]\n",
    "            elif var_param == 'BSS':\n",
    "                figsize=(6, 6)\n",
    "                df_def_acc.rename(columns={x: f\"{x:d}\" for x in df_def_acc.columns}, inplace=True)\n",
    "                df_def_acc['index'] = [f\"{x:d}\" for x in df_def_acc.index.values]\n",
    "            else:\n",
    "                figsize=(13, 12)\n",
    "                df_def_acc.rename(columns={x: f\"{x:.4f}\" for x in df_def_acc.columns}, inplace=True)\n",
    "                df_def_acc['index'] = [f\"{x:.4f}\" for x in df_def_acc.index.values]\n",
    "            df_def_acc.set_index('index', inplace=True)\n",
    "            \n",
    "            df_fig = df_def_acc.astype(float)\n",
    "            sns.set_theme(style='ticks', font_scale=1.0)\n",
    "            fig, ax = plt.subplots(figsize=figsize)\n",
    "            heatmap = sns.heatmap(\n",
    "                df_fig,\n",
    "                annot=True,\n",
    "                fmt=\".2f\",\n",
    "                cmap='hot',\n",
    "                linewidth=0.1,\n",
    "                linecolor='black',\n",
    "                cbar_kws={\n",
    "                    'orientation': 'horizontal',\n",
    "                    'location': 'top',\n",
    "                    'pad': 0.025,\n",
    "                    'aspect': 30\n",
    "                },\n",
    "                annot_kws={\"size\": 9},\n",
    "                ax=ax\n",
    "            )\n",
    "            ax.set_xlabel('Test Attack Strength')\n",
    "            ax.set_ylabel('Train Attack Strength')\n",
    "            heatmap_pos = heatmap.get_position()\n",
    "            ax.figure.axes[-1].set_title(\"Accuracy\")\n",
    "            ax.figure.axes[-1].tick_params()\n",
    "            for spine in ax.figure.axes[-1].spines.values():\n",
    "                spine.set_linewidth(1)\n",
    "            plt.savefig(f\"{path_save}/Evasion/{atk_type}/detectors_accuracy.png\", bbox_inches='tight', dpi=200)\n",
    "            plt.savefig(f\"{path_save}/Evasion/{atk_type}/detectors_accuracy.pdf\", bbox_inches='tight')\n",
    "            plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
