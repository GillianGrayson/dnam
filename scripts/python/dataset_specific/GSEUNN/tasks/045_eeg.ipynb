{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import plotly.express as px\n",
    "import statsmodels.formula.api as smf\n",
    "import plotly.graph_objects as go\n",
    "from scripts.python.routines.manifest import get_manifest\n",
    "from scripts.python.routines.plot.save import save_figure\n",
    "from scripts.python.routines.plot.layout import add_layout\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import kruskal, mannwhitneyu\n",
    "import plotly.io as pio\n",
    "pio.kaleido.scope.mathjax = None\n",
    "from plotly.offline import init_notebook_mode\n",
    "init_notebook_mode(connected=False)\n",
    "from scipy.stats import mannwhitneyu, median_test\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "from matplotlib.patches import Rectangle\n",
    "from tqdm import tqdm\n",
    "import plotly.colors\n",
    "from src.utils.plot.bioinfokit import mhat, volcano\n",
    "import gseapy as gp\n",
    "import mygene\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA, IncrementalPCA, KernelPCA, TruncatedSVD\n",
    "from sklearn.decomposition import MiniBatchDictionaryLearning, FastICA\n",
    "from sklearn.random_projection import GaussianRandomProjection, SparseRandomProjection\n",
    "from sklearn.manifold import MDS, Isomap, TSNE, LocallyLinearEmbedding\n",
    "import upsetplot as upset\n",
    "import missingno as msno\n",
    "from pyod.models.lunar import LUNAR\n",
    "from matplotlib_venn import venn2, venn2_circles\n",
    "from glob import glob\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "import omegaconf\n",
    "import os\n",
    "import ast\n",
    "import json\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scripts.python.routines.plot.colorscales import get_continuous_color\n",
    "from src.datamodules.cross_validation import RepeatedStratifiedKFoldCVSplitter\n",
    "from src.datamodules.tabular import TabularDataModule\n",
    "from lifelines import CoxPHFitter\n",
    "from lifelines.statistics import proportional_hazard_test\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from scipy.stats import wilcoxon, friedmanchisquare\n",
    "from suffix_trees import STree\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Collect ML results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_4704\\1415810573.py:26: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_4704\\1415810573.py:26: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_4704\\1415810573.py:32: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_4704\\1415810573.py:32: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_4704\\1415810573.py:32: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_4704\\1415810573.py:32: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_4704\\1415810573.py:32: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_4704\\1415810573.py:32: PerformanceWarning:\n",
      "\n",
      "DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = \"D:/YandexDisk/Work/eeg/alpha_ext/real\"\n",
    "model = 'widedeep_tab_mlp_trn_val_tst'\n",
    "path_runs = f\"{path}/models/{model}/multiruns\"\n",
    "\n",
    "files = glob(f\"{path_runs}/*/*/metrics_val_best_*.xlsx\")\n",
    "\n",
    "df_tmp = pd.read_excel(files[0], index_col=\"metric\")\n",
    "head, tail = os.path.split(files[0])\n",
    "cfg = OmegaConf.load(f\"{head}/.hydra/overrides.yaml\")\n",
    "params = []\n",
    "for param_pair in cfg:\n",
    "    param, val = param_pair.split('=')\n",
    "    params.append(param)\n",
    "df_res = pd.DataFrame(index=files)\n",
    "for file in files:\n",
    "    # Validation\n",
    "    df_val = pd.read_excel(file, index_col=\"metric\")\n",
    "    for metric in df_val.index.values:\n",
    "        df_res.at[file, metric + \"_val\"] = df_val.at[metric, \"val\"]\n",
    "\n",
    "    # Train\n",
    "    head, tail = os.path.split(file)\n",
    "    tail = tail.replace('val', 'trn')\n",
    "    df_trn = pd.read_excel(f\"{head}/{tail}\", index_col=\"metric\")\n",
    "    for metric in df_trn.index.values:\n",
    "        df_res.at[file, metric + \"_trn\"] = df_trn.at[metric, \"trn\"]\n",
    "\n",
    "    # Params\n",
    "    cfg = OmegaConf.load(f\"{head}/.hydra/overrides.yaml\")\n",
    "    for param_pair in cfg:\n",
    "        param, val = param_pair.split('=')\n",
    "        df_res.at[file, param] = val\n",
    "\n",
    "first_columns = [\n",
    "    'accuracy_weighted_trn',\n",
    "    'accuracy_weighted_cv_mean_trn',\n",
    "    'accuracy_weighted_cv_std_trn',\n",
    "    'accuracy_weighted_val',\n",
    "    'accuracy_weighted_cv_mean_val',\n",
    "    'accuracy_weighted_cv_std_val'\n",
    "]\n",
    "df_res = df_res[first_columns + [col for col in df_res.columns if col not in first_columns]]\n",
    "df_res.to_excel(f\"{path_runs}/summary.xlsx\", index=True, index_label=\"file\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Plot hyperparameter optimization results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path = \"D:/YandexDisk/Work/eeg/many_freqs\"\n",
    "movement_type = \"real\"\n",
    "model = 'lightgbm_trn_val_tst'\n",
    "path_runs = f\"{path}/{movement_type}/models/{model}/multiruns\"\n",
    "\n",
    "df_runs = pd.read_excel(f\"{path_runs}/summary.xlsx\", index_col=0)\n",
    "cols_dict = {\n",
    "    \"accuracy_weighted_trn\": (\"Train Best Accuracy\", \"deepskyblue\"),\n",
    "    \"accuracy_weighted_cv_mean_trn\": (\"Train Mean Accuracy\", \"dodgerblue\"),\n",
    "    \"accuracy_weighted_val\": (\"Validation Best Accuracy\", \"lightcoral\"),\n",
    "    \"accuracy_weighted_cv_mean_val\": (\"Validation Mean Accuracy\", \"crimson\"),\n",
    "}\n",
    "df_fig = df_runs.loc[:, list(cols_dict.keys())].copy()\n",
    "df_fig.rename(columns={k: v[0] for k,v in cols_dict.items()}, inplace=True)\n",
    "for col in cols_dict:\n",
    "    fig = plt.figure()\n",
    "    sns.set_theme(style='whitegrid')\n",
    "    sns.histplot(\n",
    "        data=df_fig,\n",
    "        x=cols_dict[col][0],\n",
    "        color=cols_dict[col][1],\n",
    "    )\n",
    "    plt.savefig(f\"{path_runs}/{col}.png\", bbox_inches='tight', dpi=400)\n",
    "    plt.savefig(f\"{path_runs}/{col}.pdf\", bbox_inches='tight')\n",
    "    plt.close(fig)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Plot bad splits distributions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "path = \"D:/YandexDisk/Work/eeg/alpha/real\"\n",
    "model = 'widedeep_tab_mlp_trn_val_tst'\n",
    "path_runs = f\"{path}/models/{model}/multiruns\"\n",
    "path_best_run = f\"2023-04-20_18-13-22_1337/4\"\n",
    "\n",
    "metric_main = \"val_accuracy_weighted\"\n",
    "metric_thld = 0.55\n",
    "\n",
    "df_cv_metrics = pd.read_excel(f\"{path_runs}/{path_best_run}/cv_progress.xlsx\", index_col=0)\n",
    "pathlib.Path(f\"{path_runs}/{path_best_run}/split_details\").mkdir(parents=True, exist_ok=True)\n",
    "df_fig = df_cv_metrics.loc[:, [metric_main]].copy()\n",
    "df_fig.rename(columns={metric_main: \"Validation Accuracy\"}, inplace=True)\n",
    "fig = plt.figure()\n",
    "sns.set_theme(style='whitegrid')\n",
    "sns.histplot(\n",
    "    data=df_fig,\n",
    "    x=\"Validation Accuracy\",\n",
    "    color=\"lightcoral\",\n",
    ")\n",
    "plt.savefig(f\"{path_runs}/{path_best_run}/split_details/metric_main.png\", bbox_inches='tight', dpi=400)\n",
    "plt.savefig(f\"{path_runs}/{path_best_run}/split_details/metric_main.pdf\", bbox_inches='tight')\n",
    "plt.close(fig)\n",
    "\n",
    "\n",
    "splits = df_cv_metrics.index[df_cv_metrics[metric_main] < metric_thld].values\n",
    "\n",
    "df_cv_splits = pd.read_excel(f\"{path_runs}/{path_best_run}/cv_ids.xlsx\", index_col=0)\n",
    "dict_count = {}\n",
    "for split in splits:\n",
    "    col = f\"fold_{split:04d}\"\n",
    "    subjs = set(df_cv_splits.loc[df_cv_splits[col] == \"val\", \"subject\"].values)\n",
    "    for subj in subjs:\n",
    "        if subj in dict_count:\n",
    "            dict_count[subj] += 1\n",
    "        else:\n",
    "            dict_count[subj] = 1\n",
    "df_count = pd.DataFrame(index=list(dict_count.keys()))\n",
    "df_count[\"Count\"] = list(dict_count.values())\n",
    "df_count.sort_values([f\"Count\"], ascending=[False], inplace=True)\n",
    "\n",
    "palette = {f\"S{s_id}\": px.colors.qualitative.Dark24[s_id] for s_id in range(15)}\n",
    "\n",
    "fig = plt.figure(figsize=(12, 0.4 * df_count['Count'].value_counts(dropna=True).shape[0]))\n",
    "sns.set_theme(style='whitegrid', font_scale=1)\n",
    "bar = sns.barplot(\n",
    "    data=df_count,\n",
    "    y=df_count.index,\n",
    "    x='Count',\n",
    "    edgecolor='black',\n",
    "    orient='h',\n",
    "    palette=palette,\n",
    "    dodge=True\n",
    ")\n",
    "bar.set_xlabel(\"Occurrence in Validation dataset\")\n",
    "bar.set_ylabel(\"\")\n",
    "bar.set_title(f\"\")\n",
    "plt.savefig(f\"{path_runs}/{path_best_run}/split_details/subjects_val_count_thld({metric_thld}).png\", bbox_inches='tight', dpi=400)\n",
    "plt.savefig(f\"{path_runs}/{path_best_run}/split_details/subjects_val_count_thld({metric_thld}).pdf\", bbox_inches='tight')\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Dimensionality reduction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\py39\\lib\\site-packages\\sklearn\\manifold\\_mds.py:299: FutureWarning:\n",
      "\n",
      "The default value of `normalized_stress` will change to `'auto'` in version 1.4. To suppress this warning, manually set the value of `normalized_stress`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = \"D:/YandexDisk/Work/eeg\"\n",
    "movement_type = \"real\"\n",
    "features_type = \"alpha\"\n",
    "feat_target = \"class_simp\"\n",
    "\n",
    "dim_red_methods_dict = {\n",
    "    'PCA': ['PC 1', 'PC 2'],\n",
    "    'SVD': ['SVD 1', 'SVD 2'],\n",
    "    'MDS': ['MDS 1', 'MDS 2'],\n",
    "    'T-SNE': ['t-SNE 1', 't-SNE 2'],\n",
    "}\n",
    "palette = {f\"S{s_id}\": px.colors.qualitative.Dark24[s_id] for s_id in range(15)}\n",
    "\n",
    "df_data = pd.read_excel(f\"{path}/data.xlsx\", index_col=0)\n",
    "df_feats = pd.read_excel(f\"{path}/feats_cont_{features_type}.xlsx\", index_col=0)\n",
    "feats = df_feats.index.values\n",
    "df_classes = pd.read_excel(f\"{path}/classes_{movement_type}.xlsx\", index_col=0)\n",
    "classes = df_classes.index.values\n",
    "\n",
    "df_data = df_data.loc[df_data[feat_target].isin(classes), :]\n",
    "df_data.rename(columns={'subject': 'Subject'}, inplace=True)\n",
    "data_vals = df_data.loc[:, feats].values\n",
    "\n",
    "pca = PCA(n_components=2, whiten=False)\n",
    "data_pca = pca.fit_transform(data_vals)\n",
    "df_data['PC 1'] = data_pca[:, 0]\n",
    "df_data['PC 2'] = data_pca[:, 1]\n",
    "tsvd = TruncatedSVD(n_components=2, algorithm='randomized', n_iter=5)\n",
    "tsvd.fit(data_vals)\n",
    "data_svd = tsvd.transform(data_vals)\n",
    "df_data['SVD 1'] = data_svd[:, 0]\n",
    "df_data['SVD 2'] = data_svd[:, 1]\n",
    "mds = MDS(n_components=2, metric=True)\n",
    "data_mds = mds.fit_transform(data_vals)\n",
    "df_data['MDS 1'] = data_mds[:, 0]\n",
    "df_data['MDS 2'] = data_mds[:, 1]\n",
    "tsne = TSNE(n_components=2, learning_rate=300, perplexity=30, early_exaggeration=12, init='random')\n",
    "data_tsne = tsne.fit_transform(data_vals)\n",
    "df_data['t-SNE 1'] = data_tsne[:, 0]\n",
    "df_data['t-SNE 2'] = data_tsne[:, 1]\n",
    "\n",
    "for m in dim_red_methods_dict:\n",
    "    x_name = dim_red_methods_dict[m][0]\n",
    "    y_name = dim_red_methods_dict[m][1]\n",
    "\n",
    "    plt.figure()\n",
    "    sns.set_theme(style='whitegrid')\n",
    "    scatter = sns.scatterplot(\n",
    "        data=df_data,\n",
    "        x=x_name,\n",
    "        y=y_name,\n",
    "        hue=\"Subject\",\n",
    "        linewidth=0.1,\n",
    "        palette=palette,\n",
    "        alpha=0.85,\n",
    "        edgecolor=\"k\",\n",
    "        s=10,\n",
    "        hue_order=palette\n",
    "    )\n",
    "    sns.move_legend(scatter, \"center left\", bbox_to_anchor=(1, 0.5))\n",
    "    plt.savefig(f\"{path}/{features_type}/{movement_type}/{m}.png\", bbox_inches='tight', dpi=400)\n",
    "    plt.savefig(f\"{path}/{features_type}/{movement_type}/{m}.pdf\", bbox_inches='tight')\n",
    "    plt.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
