{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Description\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import statsmodels.formula.api as smf\n",
    "import plotly.graph_objects as go\n",
    "from scripts.python.routines.manifest import get_manifest\n",
    "from scripts.python.routines.plot.save import save_figure\n",
    "from scripts.python.routines.plot.layout import add_layout\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import plotly.io as pio\n",
    "pio.kaleido.scope.mathjax = None\n",
    "from plotly.offline import init_notebook_mode\n",
    "init_notebook_mode(connected=False)\n",
    "from scipy.stats import mannwhitneyu, median_test, kruskal, wilcoxon, friedmanchisquare\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import matplotlib\n",
    "import matplotlib.patheffects as path_effects\n",
    "import random\n",
    "import pathlib\n",
    "from tqdm import tqdm\n",
    "from src.utils.plot.bioinfokit import mhat, volcano\n",
    "import gseapy as gp\n",
    "import mygene\n",
    "from sklearn.decomposition import PCA, IncrementalPCA, KernelPCA, TruncatedSVD\n",
    "from sklearn.decomposition import MiniBatchDictionaryLearning, FastICA\n",
    "from sklearn.random_projection import GaussianRandomProjection, SparseRandomProjection\n",
    "from sklearn.manifold import MDS, Isomap, TSNE, LocallyLinearEmbedding\n",
    "import upsetplot\n",
    "from matplotlib_venn import venn2, venn2_circles\n",
    "from itertools import chain\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from scripts.python.routines.plot.colorscales import get_continuous_color\n",
    "import plotly\n",
    "from scripts.python.routines.plot.p_value import add_p_value_annotation\n",
    "from scripts.python.routines.sections import get_sections\n",
    "from statannotations.Annotator import Annotator\n",
    "import functools\n",
    "import matplotlib.lines as mlines\n",
    "import patchworklib as pw\n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.decomposition import PCA, IncrementalPCA, KernelPCA, TruncatedSVD\n",
    "from sklearn.decomposition import MiniBatchDictionaryLearning, FastICA\n",
    "from sklearn.random_projection import GaussianRandomProjection, SparseRandomProjection\n",
    "from sklearn.manifold import MDS, Isomap, TSNE, LocallyLinearEmbedding\n",
    "import missingno as msno\n",
    "from openTSNE import TSNE\n",
    "\n",
    "from pyod.models.ecod import ECOD\n",
    "from pyod.models.abod import ABOD\n",
    "from pyod.models.copod import COPOD\n",
    "from pyod.models.sos import SOS\n",
    "from pyod.models.kde import KDE\n",
    "from pyod.models.sampling import Sampling\n",
    "from pyod.models.gmm import GMM\n",
    "\n",
    "from pyod.models.kpca import KPCA\n",
    "from pyod.models.mcd import MCD\n",
    "from pyod.models.ocsvm import OCSVM\n",
    "from pyod.models.lmdd import LMDD\n",
    "\n",
    "from pyod.models.lof import LOF\n",
    "from pyod.models.cof import COF\n",
    "from pyod.models.cblof import CBLOF\n",
    "from pyod.models.hbos import HBOS\n",
    "from pyod.models.knn import KNN\n",
    "from pyod.models.sod import SOD\n",
    "\n",
    "from pyod.models.iforest import IForest\n",
    "from pyod.models.inne import INNE\n",
    "from pyod.models.loda import LODA\n",
    "from pyod.models.suod import SUOD\n",
    "\n",
    "from pyod.models.auto_encoder_torch import AutoEncoder\n",
    "from pyod.models.vae import VAE\n",
    "from pyod.models.deep_svdd import DeepSVDD\n",
    "\n",
    "from pyod.models.lunar import LUNAR\n",
    "\n",
    "\n",
    "\n",
    "def conjunction(conditions):\n",
    "    return functools.reduce(np.logical_and, conditions)\n",
    "\n",
    "\n",
    "def disjunction(conditions):\n",
    "    return functools.reduce(np.logical_or, conditions)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Prepare data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.1 Load basic data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path = f\"D:/YandexDisk/Work/pydnameth/datasets/GPL21145/GSEUNN\"\n",
    "df = pd.read_excel(f\"{path}/data/immuno/df_samples(all_1052_121222)_proc(raw)_imp(fast_knn)_replace(quarter).xlsx\", index_col=0)\n",
    "df.index = df.index.map(str)\n",
    "df.rename(columns={'file': 'File'}, inplace=True)\n",
    "feats = pd.read_excel(f\"{path}/data/immuno/feats_con.xlsx\", index_col=0).index.values\n",
    "path_save = f\"{path}/special/053_proof_that_immunodata_is_shit\"\n",
    "pathlib.Path(f\"{path_save}\").mkdir(parents=True, exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Setup filtering"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "is_data_filter = False\n",
    "if is_data_filter:\n",
    "    path_save = f\"{path}/special/053_proof_that_immunodata_is_shit/filtered\"\n",
    "else:\n",
    "    path_save = f\"{path}/special/053_proof_that_immunodata_is_shit/origin\"\n",
    "pathlib.Path(f\"{path_save}\").mkdir(parents=True, exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2 Get data with nans"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path_curr = f\"{path_save}/01_data_with_nans\"\n",
    "pathlib.Path(f\"{path_curr}\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "files = [\n",
    "    \"Aging L, Q, H, I\",\n",
    "    \"Aging-Covid_05.01.2022\",\n",
    "    \"Aging-Covid-05.05.22\",\n",
    "    \"Covid_results_02_2021\",\n",
    "    \"Covid-25.11.20\",\n",
    "    \"MULTIPLEX_20_11_2020_ AGING\",\n",
    "    \"Yakutiya + TR\",\n",
    "    \"Мультиплекс_Agind&Covid\",\n",
    "]\n",
    "df_immuno_genes = pd.read_excel(f\"{path}/data/immuno/immuno_markers_genes.xlsx\")\n",
    "dict_immuno_genes = dict(zip(df_immuno_genes['immuno_marker'], df_immuno_genes['gene']))\n",
    "\n",
    "dfs_files = []\n",
    "nans_by_features = {}\n",
    "for file in files:\n",
    "    df_file = pd.read_excel(f\"{path}/data/immuno/files/processed/{file}.xlsx\", index_col=\"Sample\")\n",
    "    df_file.rename(columns=dict_immuno_genes, inplace=True)\n",
    "    df_file = df_file.loc[:, feats]\n",
    "\n",
    "    # duplicates processing\n",
    "    if file == \"MULTIPLEX_20_11_2020_ AGING\":\n",
    "        df_file_doubled_unique = df_file.loc[~df_file.index.duplicated(keep=False), :]\n",
    "        df_file_doubled_1 = df_file.loc[df_file.index.duplicated(keep='first'), :]\n",
    "        df_file_doubled_2 = df_file.loc[df_file.index.duplicated(keep='last'), :]\n",
    "        df_file_duplicates_final = pd.concat([df_file_doubled_2, df_file_doubled_unique], axis=0)\n",
    "        df_file = df_file_duplicates_final\n",
    "    df_file_duplicates = df_file.loc[df_file.index.duplicated(keep=False), :]\n",
    "    if df_file_duplicates.shape[0] > 0:\n",
    "        print(df_file_duplicates.index)\n",
    "    \n",
    "    for feat in df_file:\n",
    "        nan_vals = set(df_file.loc[df_file[feat].astype(str).str.contains(r'^([<>].*)$', regex=True), feat].values)\n",
    "        if len(nan_vals) > 0:\n",
    "            for nv in nan_vals:\n",
    "                if feat in nans_by_features:\n",
    "                    nans_by_features[feat].add(nv)\n",
    "                else:\n",
    "                    nans_by_features[feat] = {nv}\n",
    "    \n",
    "    df_file.replace(r'^([<>].*)$', 'NaN', inplace=True, regex=True)\n",
    "    df_file = df_file.apply(pd.to_numeric, errors='coerce')\n",
    "    dfs_files.append(df_file)\n",
    "\n",
    "print(nans_by_features)\n",
    "\n",
    "df_w_nans = pd.concat(dfs_files, verify_integrity=False)\n",
    "df_w_nans.index = df_w_nans.index.map(str)\n",
    "df_w_nans = df_w_nans.loc[df.index.values, :]\n",
    "df_w_nans.to_excel(f\"{path_curr}/df_w_nans.xlsx\", index_label=\"Index\")\n",
    "\n",
    "# Checking values\n",
    "df_diff = df.loc[df.index.values, feats] - df_w_nans.loc[df.index.values, feats]\n",
    "df_diff = df_diff.fillna(0.0)\n",
    "max_diff = df_diff.values.max()\n",
    "print(f\"max_diff: {max_diff}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.3 Problem definitions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_subsets(df):\n",
    "    subsets = {\n",
    "        'All Samples': {\n",
    "            'color': 'black',\n",
    "            'samples': df.index.values,\n",
    "            'path': 'All'\n",
    "        },\n",
    "        \"File Aging L, Q, H, I\": {\n",
    "            'color': px.colors.qualitative.Plotly[0],\n",
    "            'samples': df.index[df['File'] == \"Aging L, Q, H, I\"].values,\n",
    "            'path': 'Files/Aging L, Q, H, I',\n",
    "            'value': 'Aging L, Q, H, I'\n",
    "        },\n",
    "        \"File Aging-Covid_05.01.2022\": {\n",
    "            'color': px.colors.qualitative.Plotly[1],\n",
    "            'samples': df.index[df['File'] == \"Aging-Covid_05.01.2022\"].values,\n",
    "            'path': 'Files/Aging-Covid_05.01.2022',\n",
    "            'value': 'Aging-Covid_05.01.2022'\n",
    "        },\n",
    "        \"File Aging-Covid-05.05.22\": {\n",
    "            'color': px.colors.qualitative.Plotly[2],\n",
    "            'samples': df.index[df['File'] == \"Aging-Covid-05.05.22\"].values,\n",
    "            'path': 'Files/Aging-Covid-05.05.22',\n",
    "            'value': 'Aging-Covid-05.05.22'\n",
    "        },\n",
    "        \"File Covid_results_02_2021\": {\n",
    "            'color': px.colors.qualitative.Plotly[3],\n",
    "            'samples': df.index[df['File'] == \"Covid_results_02_2021\"].values,\n",
    "            'path': 'Files/Covid_results_02_2021',\n",
    "            'value': 'Covid_results_02_2021'\n",
    "        },\n",
    "        \"File Covid-25.11.20\": {\n",
    "            'color': px.colors.qualitative.Plotly[4],\n",
    "            'samples': df.index[df['File'] == \"Covid-25.11.20\"].values,\n",
    "            'path': 'Files/Covid-25.11.20',\n",
    "            'value': 'Covid-25.11.20'\n",
    "        },\n",
    "        \"File MULTIPLEX_20_11_2020_ AGING\": {\n",
    "            'color': px.colors.qualitative.Plotly[5],\n",
    "            'samples': df.index[df['File'] == \"MULTIPLEX_20_11_2020_ AGING\"].values,\n",
    "            'path': 'Files/MULTIPLEX_20_11_2020_ AGING',\n",
    "            'value': 'MULTIPLEX_20_11_2020_ AGING'\n",
    "        },\n",
    "        \"File Yakutiya + TR\": {\n",
    "            'color': px.colors.qualitative.Plotly[6],\n",
    "            'samples': df.index[df['File'] == \"Yakutiya + TR\"].values,\n",
    "            'path': 'Files/Yakutiya + TR',\n",
    "            'value': 'Yakutiya + TR'\n",
    "        },\n",
    "        \"File Мультиплекс_Agind&Covid\": {\n",
    "            'color': px.colors.qualitative.Plotly[7],\n",
    "            'samples': df.index[df['File'] == \"Мультиплекс_Agind&Covid\"].values,\n",
    "            'path': 'Files/Мультиплекс_Agind&Covid',\n",
    "            'value': 'Мультиплекс_Agind&Covid'\n",
    "        },\n",
    "        \"Controls\": {\n",
    "            'color': 'lawngreen',\n",
    "            'samples': df.index[(df['Status'] == \"Control\") | (df['COVID-19 stage'] == \"Reconvalescent\")].values,\n",
    "            'path': 'Status/Controls',\n",
    "            'value': 'Controls'\n",
    "        },\n",
    "        \"Controls Central\": {\n",
    "            'color': 'gold',\n",
    "            'samples': df.index[((df['Status'] == \"Control\") | (df['COVID-19 stage'] == \"Reconvalescent\")) & (df['Region'] == \"Central\") ].values,\n",
    "            'path': 'Controls/Central',\n",
    "            'value': 'Central'\n",
    "        },\n",
    "        \"Controls Yakutia\": {\n",
    "            'color': 'silver',\n",
    "            'samples': df.index[((df['Status'] == \"Control\") | (df['COVID-19 stage'] == \"Reconvalescent\")) & (df['Region'] == \"Yakutia\") ].values,\n",
    "            'path': 'Controls/Yakutia',\n",
    "            'value': 'Yakutia'\n",
    "        },\n",
    "        \"СOVID-19 Acute and Dynamics\": {\n",
    "            'color': 'crimson',\n",
    "            'samples': df.index[df['COVID-19 stage'].isin(['Acute', 'Dynamics'])].values,\n",
    "            'path': 'Status/COVID-19',\n",
    "            'value': 'COVID-19 Acute and Dynamics'\n",
    "        },\n",
    "        \"Down Syndrome\": {\n",
    "            'color': 'darkorchid',\n",
    "            'samples': df.index[df['Down syndrome status'].isin(['Down Syndrome'])].values,\n",
    "            'path': 'Status/DownSyndrome',\n",
    "            'value': 'Down Syndrome'\n",
    "        },\n",
    "        \"ESRD\": {\n",
    "            'color': 'saddlebrown',\n",
    "            'samples': df.index[df['Status'].isin(['ESRD'])].values,\n",
    "            'path': 'Status/ESRD',\n",
    "            'value': 'ESRD'\n",
    "        },\n",
    "    }\n",
    "    df.loc[subsets[\"Controls\"][\"samples\"], \"Controls/Cases\"] = \"Controls\"\n",
    "    df.loc[subsets[\"СOVID-19 Acute and Dynamics\"][\"samples\"], \"Controls/Cases\"] = \"COVID-19 Acute and Dynamics\"\n",
    "    df.loc[subsets[\"Down Syndrome\"][\"samples\"], \"Controls/Cases\"] = \"Down Syndrome\"\n",
    "    df.loc[subsets[\"ESRD\"][\"samples\"], \"Controls/Cases\"] = \"ESRD\"\n",
    "    for subset_name, subset in subsets.items():\n",
    "        print(f\"{subset_name}: {len(subset['samples'])}\")\n",
    "\n",
    "    return subsets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.4. Prepare data for cleanlab.ai"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "subsets = get_subsets(df)\n",
    "df_cl = df.loc[df[\"Controls/Cases\"] == \"Controls\", list(feats) + [\"Sex\", \"Region\", \"Age\"]]\n",
    "ptp = np.ptp(df_cl['Age'])\n",
    "bins = np.concatenate((\n",
    "    [np.min(df_cl['Age']) - 0.05 * ptp],\n",
    "    np.percentile(df_cl['Age'], np.linspace(10, 90, 9)),\n",
    "    [np.max(df_cl['Age']) + 0.05 * ptp]\n",
    "))\n",
    "df_cl['AgeQuantile'] = np.digitize(df_cl['Age'], bins) - 1\n",
    "df_cl.to_excel(f\"{path_save}/data_for_cleanlab.xlsx\", index_label=\"index\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. NaN analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Filter features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "thld_feats = 25\n",
    "if is_data_filter:\n",
    "    df_filter_feats = pd.read_excel(f\"{path}/special/053_proof_that_immunodata_is_shit/origin/02_nan_analysis/All/df_nan_feats.xlsx\", index_col=0)\n",
    "    feats = df_filter_feats.index[df_filter_feats['% of NaNs'] <= thld_feats].values\n",
    "    print(f\"Number of filtered features: {len(feats)}\")\n",
    "    df_feats = pd.DataFrame(index=feats)\n",
    "    df_feats.to_excel(f\"{path_save}/feats.xlsx\", index_label=\"Features\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "subsets = get_subsets(df)\n",
    "df_nan_feats_by_group = pd.DataFrame(index=list(subsets.keys()))\n",
    "for subset_name, subset in subsets.items():\n",
    "\n",
    "    path_curr = f\"{path_save}/02_nan_analysis/{subset['path']}\"\n",
    "    pathlib.Path(f\"{path_curr}\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # msno plots ===================================================================\n",
    "    df_msno = df_w_nans.loc[subset['samples'], feats]\n",
    "    msno_bar = msno.bar(\n",
    "        df=df_msno,\n",
    "        label_rotation=90,\n",
    "        color=subset['color'],\n",
    "    )\n",
    "    plt.xticks(ha='center')\n",
    "    plt.setp(msno_bar.xaxis.get_majorticklabels(), ha=\"center\")\n",
    "    msno_bar.set_title(f\"{subset_name} ({len(subset['samples'])})\", fontdict={'fontsize': 22})\n",
    "    msno_bar.set_ylabel(\"Non-outlier samples\", fontdict={'fontsize': 22})\n",
    "    plt.savefig(f\"{path_curr}/msno_bar.png\", bbox_inches='tight')\n",
    "    plt.savefig(f\"{path_curr}/msno_bar.pdf\", bbox_inches='tight')\n",
    "    plt.clf()\n",
    "\n",
    "    msno_mtx = msno.matrix(\n",
    "        df=df_msno,\n",
    "        label_rotation=90,\n",
    "        color=colors.to_rgb(subset['color']),\n",
    "    )\n",
    "    plt.xticks(ha='center')\n",
    "    plt.setp(msno_bar.xaxis.get_majorticklabels(), ha=\"center\")\n",
    "    msno_mtx.set_title(f\"{subset_name} ({len(subset['samples'])})\", fontdict={'fontsize': 22})\n",
    "    msno_mtx.set_ylabel(\"Samples\", fontdict={'fontsize': 22})\n",
    "    plt.savefig(f\"{path_curr}/msno_matrix.png\", bbox_inches='tight')\n",
    "    plt.savefig(f\"{path_curr}/msno_matrix.pdf\", bbox_inches='tight')\n",
    "    plt.clf()\n",
    "\n",
    "    msno_heatmap = msno.heatmap(\n",
    "        df=df_msno,\n",
    "        label_rotation=90,\n",
    "        cmap=\"bwr\",\n",
    "        fontsize=12\n",
    "    )\n",
    "    msno_heatmap.set_title(f\"{subset_name} ({len(subset['samples'])})\", fontdict={'fontsize': 22})\n",
    "    plt.setp(msno_heatmap.xaxis.get_majorticklabels(), ha=\"center\")\n",
    "    msno_heatmap.collections[0].colorbar.ax.tick_params(labelsize=20)\n",
    "    plt.savefig(f\"{path_curr}/msno_heatmap.png\", bbox_inches='tight')\n",
    "    plt.savefig(f\"{path_curr}/msno_heatmap.pdf\", bbox_inches='tight')\n",
    "    plt.clf()\n",
    "\n",
    "    # NaN features =================================================================\n",
    "    df_nan_feats = df_w_nans.loc[subset['samples'], feats].isna().sum(axis=0).to_frame(name=\"Number of NaNs\")\n",
    "    df_nan_feats[\"% of NaNs\"] = df_nan_feats[\"Number of NaNs\"] / len(subset['samples']) * 100\n",
    "    df_nan_feats[\"Number of not-NaNs\"] = df_w_nans.loc[subset['samples'], feats].notna().sum(axis=0)\n",
    "    df_nan_feats['Color'] = 'white'\n",
    "    df_nan_feats.loc[df_nan_feats[\"% of NaNs\"] < 100, 'Color'] = subset['color']\n",
    "    df_nan_feats.sort_values([\"% of NaNs\"], ascending=[False], inplace=True)\n",
    "    df_nan_feats.to_excel(f\"{path_curr}/df_nan_feats.xlsx\", index_label=\"Features\")\n",
    "\n",
    "    df_nan_feats_by_group.at[subset_name, \"% of NaNs\"] = df_nan_feats[\"Number of NaNs\"].sum(axis=0) / df_w_nans.loc[subset['samples'], feats].size * 100\n",
    "\n",
    "    plt.figure(figsize=(14, 4))\n",
    "    plt.xticks(rotation=90)\n",
    "    sns.set_theme(style='whitegrid')\n",
    "    barplot = sns.barplot(\n",
    "        data=df_nan_feats,\n",
    "        x=df_nan_feats.index,\n",
    "        y=f\"% of NaNs\",\n",
    "        edgecolor='black',\n",
    "        palette=df_nan_feats['Color'].values,\n",
    "        dodge=False\n",
    "    )\n",
    "    barplot.set_title(f\"{subset_name} ({len(subset['samples'])})\")\n",
    "    plt.savefig(f\"{path_curr}/feats_barplot.png\", bbox_inches='tight', dpi=200)\n",
    "    plt.savefig(f\"{path_curr}/feats_barplot.pdf\", bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # NaN samples ==================================================================\n",
    "    df_nan_spls = df_w_nans.loc[subset['samples'], feats].isna().sum(axis=1).to_frame(name=\"Features with NaNs\")\n",
    "    df_nan_spls.to_excel(f\"{path_curr}/df_nan_samples.xlsx\", index_label=\"Samples\")\n",
    "\n",
    "    hist_bins = np.linspace(0, len(feats), len(feats) + 1)\n",
    "    fig = plt.figure(figsize=(6, 4))\n",
    "    sns.set_theme(style='whitegrid')\n",
    "    histplot = sns.histplot(\n",
    "        data=df_nan_spls,\n",
    "        bins=hist_bins,\n",
    "        x=\"Features with NaNs\",\n",
    "        edgecolor='black',\n",
    "        color=subset['color'],\n",
    "    )\n",
    "    histplot.set(xlim=(-0.5, len(feats)+0.5))\n",
    "    histplot.set_title(f\"{subset_name} ({len(subset['samples'])})\")\n",
    "    histplot.set_ylabel(f\"Number of samples\")\n",
    "    plt.savefig(f\"{path_curr}/spls_histplot.png\", bbox_inches='tight', dpi=400)\n",
    "    plt.savefig(f\"{path_curr}/spls_histplot.pdf\", bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "\n",
    "# NaN features count in all subsets ============================================\n",
    "plt.figure(figsize=(4, 6))\n",
    "sns.set_theme(style='whitegrid')\n",
    "barplot = sns.barplot(\n",
    "    data=df_nan_feats_by_group,\n",
    "    y=df_nan_feats_by_group.index,\n",
    "    x=f\"% of NaNs\",\n",
    "    edgecolor='black',\n",
    "    palette={k: v['color'] for k, v in subsets.items()},\n",
    "    dodge=False,\n",
    "    orient='h'\n",
    ")\n",
    "for x in barplot.containers:\n",
    "    barplot.bar_label(x, fmt=\"%.1f\")\n",
    "plt.savefig(f\"{path_save}/02_nan_analysis/df_nan_feats_by_group.png\", bbox_inches='tight', dpi=200)\n",
    "plt.savefig(f\"{path_save}/02_nan_analysis/df_nan_feats_by_group.pdf\", bbox_inches='tight')\n",
    "plt.close()\n",
    "df_nan_feats_by_group.to_excel(f\"{path_save}/02_nan_analysis/df_nan_feats_by_group.xlsx\", index_label=\"Subset\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Filter samples"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "thld_spls = 6\n",
    "if is_data_filter:\n",
    "    df_filter_spls = pd.read_excel(f\"{path}/special/053_proof_that_immunodata_is_shit/filtered/02_nan_analysis/All/df_nan_samples.xlsx\", index_col=0)\n",
    "    samples = df_filter_spls.index[df_filter_spls['Features with NaNs'] <= thld_spls].values\n",
    "    print(f\"Number of filtered samples: {len(samples)}\")\n",
    "    df_spls_wo_nans = pd.DataFrame(index=samples)\n",
    "    df_spls_wo_nans.to_excel(f\"{path_save}/samples_wo_nans.xlsx\", index_label=\"Samples\")\n",
    "    df = df.loc[samples, :]\n",
    "    df_w_nans = df_w_nans.loc[samples, :]\n",
    "    subsets = get_subsets(df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Outlier analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.1 IQR outliers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for subset_name, subset in subsets.items():\n",
    "\n",
    "    path_curr = f\"{path_save}/03_outliers/IQR/{subset['path']}\"\n",
    "    pathlib.Path(f\"{path_curr}\").mkdir(parents=True, exist_ok=True)\n",
    "    df_curr = df.loc[subset['samples'], :].copy()\n",
    "\n",
    "    out_columns = []\n",
    "    for f in feats:\n",
    "        q1 = df_curr[f].quantile(0.25)\n",
    "        q3 = df_curr[f].quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        df_curr[f\"{f}_iqr_out\"] = True\n",
    "        out_columns.append(f\"{f}_iqr_out\")\n",
    "        filter = (df_curr[f] >= q1 - 1.5 * iqr) & (df_curr[f] <= q3 + 1.5 * iqr)\n",
    "        df_curr.loc[filter, f\"{f}_iqr_out\"] = False\n",
    "    df_curr[f\"n_iqr_outs\"] = df_curr.loc[:, out_columns].sum(axis=1)\n",
    "    df_curr.sort_values([f\"n_iqr_outs\"], ascending=[False], inplace=True)\n",
    "    df_curr.loc[:, out_columns + [\"n_iqr_outs\"]].to_excel(f\"{path_curr}/df.xlsx\", index_label=\"Sample\")\n",
    "    \n",
    "    df_feats_w_nan = pd.read_excel(f\"{path_save}/02_nan_analysis/{subset['path']}/df_nan_feats.xlsx\", index_col=0)\n",
    "    feats_w_nan = df_feats_w_nan.index[df_feats_w_nan['% of NaNs'] > 25.0].values\n",
    "    axs = {}\n",
    "    pw_rows = []\n",
    "    n_cols = 6\n",
    "    n_rows = int(np.ceil(len(feats_w_nan) / n_cols))\n",
    "    for r_id in range(n_rows):\n",
    "        pw_cols = []\n",
    "        for c_id in range(n_cols):\n",
    "            rc_id = r_id * n_cols + c_id\n",
    "            if rc_id < len(feats_w_nan):\n",
    "                feat = feats_w_nan[rc_id]\n",
    "                axs[feat] = pw.Brick(figsize=(2, 2))\n",
    "                sns.set_theme(style='whitegrid')\n",
    "                histplot = sns.histplot(\n",
    "                    data=df_curr.loc[df_curr[f\"{feat}_iqr_out\"] == False, :],\n",
    "                    x=feat,\n",
    "                    multiple=\"stack\",\n",
    "                    bins=200,\n",
    "                    edgecolor='k',\n",
    "                    linewidth=1,\n",
    "                    color=subset['color'],\n",
    "                    ax=axs[feat]\n",
    "                )          \n",
    "                val_counts = df.loc[df_w_nans[feat].isna(), feat].value_counts().to_frame(name=\"Number of NaNs\")\n",
    "                val_counts = val_counts.loc[val_counts[\"Number of NaNs\"] >= 10, :]\n",
    "                for x in val_counts.index.values:\n",
    "                    axs[feat].axvline(x, color=\"red\", linestyle=\":\", linewidth=0.5)\n",
    "                pw_cols.append(axs[feat])\n",
    "            else:\n",
    "                empty_fig = pw.Brick(figsize=(2.6, 2))\n",
    "                empty_fig.axis('off')\n",
    "                pw_cols.append(empty_fig)\n",
    "        pw_rows.append(pw.stack(pw_cols, operator=\"|\"))\n",
    "    pw_fig = pw.stack(pw_rows, operator=\"/\")\n",
    "    pw_fig.savefig(f\"{path_curr}/feats_hists.pdf\")\n",
    "    pw_fig.savefig(f\"{path_curr}/feats_hists.png\")\n",
    "\n",
    "    plt.figure(figsize=(6, 12))\n",
    "    sns.set_theme(style='whitegrid')\n",
    "    barplot = sns.barplot(\n",
    "        data=df_curr.head(50),\n",
    "        y=df_curr.head(50).index,\n",
    "        x=f\"n_iqr_outs\",\n",
    "        edgecolor='black',\n",
    "        color=subset['color'],\n",
    "        orient=\"h\",\n",
    "        dodge=False\n",
    "    )\n",
    "    barplot.set(xlim=(0, len(feats)))\n",
    "    barplot.xaxis.tick_top()\n",
    "    barplot.xaxis.set_label_position('top')\n",
    "    barplot.set_xlabel(\"Number of IQR outliers\")\n",
    "    barplot.set_ylabel(\"Samples\")\n",
    "    barplot.set_title(f\"{subset_name} ({len(subset['samples'])})\")\n",
    "    plt.savefig(f\"{path_curr}/barplot.png\", bbox_inches='tight')\n",
    "    plt.savefig(f\"{path_curr}/barplot.pdf\", bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    hist_bins = np.linspace(0, len(feats), len(feats) + 1)\n",
    "    plt.figure()\n",
    "    sns.set_theme(style='whitegrid')\n",
    "    histplot = sns.histplot(\n",
    "        data=df_curr,\n",
    "        x=f\"n_iqr_outs\",\n",
    "        multiple=\"stack\",\n",
    "        bins=hist_bins,\n",
    "        edgecolor='k',\n",
    "        linewidth=1,\n",
    "        color=subset['color'],\n",
    "    )\n",
    "    histplot.set(xlim=(-0.5, len(feats)+0.5))\n",
    "    histplot.set_title(f\"{subset_name} ({len(subset['samples'])})\")\n",
    "    histplot.set_xlabel(\"Number of IQR outliers\")\n",
    "    plt.savefig(f\"{path_curr}/histplot.png\", bbox_inches='tight')\n",
    "    plt.savefig(f\"{path_curr}/histplot.pdf\", bbox_inches='tight')\n",
    "    plt.clf()\n",
    "\n",
    "    df_msno = df_curr.loc[:, out_columns].replace({True: np.nan})\n",
    "    df_msno.rename(columns=dict(zip(out_columns, feats)), inplace=True)\n",
    "\n",
    "    msno_bar = msno.bar(\n",
    "        df=df_msno,\n",
    "        label_rotation=90,\n",
    "        color=subset['color'],\n",
    "    )\n",
    "    plt.xticks(ha='center')\n",
    "    plt.setp(msno_bar.xaxis.get_majorticklabels(), ha=\"center\")\n",
    "    msno_bar.set_title(f\"{subset_name} ({len(subset['samples'])})\", fontdict={'fontsize': 22})\n",
    "    msno_bar.set_ylabel(\"Non-outlier samples\", fontdict={'fontsize': 22})\n",
    "    plt.savefig(f\"{path_curr}/msno_bar.png\", bbox_inches='tight')\n",
    "    plt.savefig(f\"{path_curr}/msno_bar.pdf\", bbox_inches='tight')\n",
    "    plt.clf()\n",
    "\n",
    "    msno_mtx = msno.matrix(\n",
    "        df=df_msno,\n",
    "        label_rotation=90,\n",
    "        color=colors.to_rgb(subset['color']),\n",
    "    )\n",
    "    plt.xticks(ha='center')\n",
    "    plt.setp(msno_bar.xaxis.get_majorticklabels(), ha=\"center\")\n",
    "    msno_mtx.set_title(f\"{subset_name} ({len(subset['samples'])})\", fontdict={'fontsize': 22})\n",
    "    msno_mtx.set_ylabel(\"Samples\", fontdict={'fontsize': 22})\n",
    "    plt.savefig(f\"{path_curr}/msno_matrix.png\", bbox_inches='tight')\n",
    "    plt.savefig(f\"{path_curr}/msno_matrix.pdf\", bbox_inches='tight')\n",
    "    plt.clf()\n",
    "\n",
    "    msno_heatmap = msno.heatmap(\n",
    "        df=df_msno,\n",
    "        label_rotation=90,\n",
    "        cmap=\"bwr\",\n",
    "        fontsize=12\n",
    "    )\n",
    "    msno_heatmap.set_title(f\"{subset_name} ({len(subset['samples'])})\", fontdict={'fontsize': 22})\n",
    "    plt.setp(msno_heatmap.xaxis.get_majorticklabels(), ha=\"center\")\n",
    "    msno_heatmap.collections[0].colorbar.ax.tick_params(labelsize=20)\n",
    "    plt.savefig(f\"{path_curr}/msno_heatmap.png\", bbox_inches='tight')\n",
    "    plt.savefig(f\"{path_curr}/msno_heatmap.pdf\", bbox_inches='tight')\n",
    "    plt.clf()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.1 PyOD outliers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "contamination = 0.1\n",
    "epochs = 500\n",
    "\n",
    "for subset_name, subset in subsets.items():\n",
    "\n",
    "    path_curr = f\"{path_save}/03_outliers/pyod_contam({contamination})_epochs({epochs})/{subset['path']}\"\n",
    "    pathlib.Path(f\"{path_curr}\").mkdir(parents=True, exist_ok=True)\n",
    "    df_curr = df.loc[subset['samples'], :].copy()\n",
    "\n",
    "    scalers = {}\n",
    "    feats_scaled = []\n",
    "    for f in feats:\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(df_curr.loc[:, f].values.reshape(-1, 1))\n",
    "        scalers[f] = scaler\n",
    "        feats_scaled.append(f\"{f}_scaled\")\n",
    "        df_curr[f\"{f}_scaled\"] = scaler.transform(df_curr.loc[:, f].values.reshape(-1, 1))\n",
    "    with open(f\"{path_curr}/scalers.pkl\", 'wb') as handle:\n",
    "        pickle.dump(scalers, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    feats_sets = {\n",
    "        'scaled': feats_scaled\n",
    "    }\n",
    "\n",
    "    for feats_set in feats_sets:\n",
    "\n",
    "        pathlib.Path(f\"{path_curr}/{feats_set}\").mkdir(parents=True, exist_ok=True)\n",
    "        df_outs = df_curr.copy()\n",
    "\n",
    "        pyod_methods = {\n",
    "            'ECOD': ECOD(contamination=contamination),\n",
    "            'ABOD': ABOD(contamination=contamination),\n",
    "            'COPOD': COPOD(contamination=contamination),\n",
    "            'SOS': SOS(contamination=contamination),\n",
    "            'KDE': KDE(contamination=contamination),\n",
    "            'Sampling': Sampling(contamination=contamination),\n",
    "            'GMM': GMM(contamination=contamination),\n",
    "            'KPCA': KPCA(contamination=contamination),\n",
    "            'MCD': MCD(contamination=contamination),\n",
    "            'OCSVM': OCSVM(contamination=contamination),\n",
    "            'LMDD': LMDD(contamination=contamination),\n",
    "            'LOF': LOF(contamination=contamination),\n",
    "            'COF': COF(contamination=contamination),\n",
    "            'CBLOF': CBLOF(contamination=contamination),\n",
    "            'HBOS': HBOS(contamination=contamination),\n",
    "            'KNN': KNN(contamination=contamination),\n",
    "            'SOD': SOD(contamination=contamination),\n",
    "            'IForest': IForest(contamination=contamination),\n",
    "            'INNE': INNE(contamination=contamination),\n",
    "            'LODA': LODA(contamination=contamination),\n",
    "            'SUOD': SUOD(contamination=contamination, verbose=0),\n",
    "            # 'AutoEncoder': AutoEncoder(contamination=contamination, epochs=epochs),\n",
    "            'VAE': VAE(encoder_neurons=[64, 32, 16], decoder_neurons=[16, 32, 64], contamination=contamination, epochs=epochs, verbose=0),\n",
    "            'DeepSVDD': DeepSVDD(contamination=contamination, epochs=epochs, verbose=0),\n",
    "            'LUNAR': LUNAR(),\n",
    "        }\n",
    "\n",
    "        X_outliers = df_outs.loc[:, feats_sets[feats_set]].to_numpy()\n",
    "        for method in pyod_methods:\n",
    "            if subset_name == \"Down Syndrome\":\n",
    "                df_outs[f\"{method}\"] = 0\n",
    "                df_outs[f\"{method} anomaly score\"] = 0.0\n",
    "            else:\n",
    "                pyod_methods[method].fit(X_outliers)\n",
    "                df_outs[f\"{method}\"] = pyod_methods[method].predict(X_outliers)\n",
    "                df_outs[f\"{method} anomaly score\"] = pyod_methods[method].decision_function(X_outliers)\n",
    "            n_outliers = df_outs[f\"{method}\"].sum()\n",
    "            print(f\"{subset_name} {feats_set} {method}: {n_outliers}\")\n",
    "        df_outs[\"Detections\"] = df_outs.loc[:, [f\"{method}\" for method in pyod_methods]].sum(axis=1)\n",
    "        df_outs.sort_values([\"Detections\"], ascending=[False], inplace=True)\n",
    "        df_outs.loc[:, list(pyod_methods.keys()) + [f\"{x} anomaly score\" for x in pyod_methods] + [\"Detections\"]].to_excel(f\"{path_curr}/{feats_set}/df.xlsx\", index=True)\n",
    "\n",
    "        hist_bins = np.linspace(0, len(pyod_methods), len(pyod_methods) + 1)\n",
    "        plt.figure()\n",
    "        sns.set_theme(style='whitegrid')\n",
    "        histplot = sns.histplot(\n",
    "            data=df_outs,\n",
    "            x=f\"Detections\",\n",
    "            multiple=\"stack\",\n",
    "            bins=hist_bins,\n",
    "            discrete=True,\n",
    "            edgecolor='k',\n",
    "            linewidth=1,\n",
    "            color=subset['color'],\n",
    "        )\n",
    "        histplot.set(xlim=(-0.5, len(pyod_methods) + 0.5))\n",
    "        histplot.set_title(f\"{subset_name} ({len(subset['samples'])})\")\n",
    "        histplot.set_xlabel(\"Number of detections as outlier in different methods\")\n",
    "        plt.savefig(f\"{path_curr}/{feats_set}/histplot.png\", bbox_inches='tight')\n",
    "        plt.savefig(f\"{path_curr}/{feats_set}/histplot.pdf\", bbox_inches='tight')\n",
    "        plt.clf()\n",
    "\n",
    "        sns.set_theme(style='whitegrid')\n",
    "        barplot = df_outs.loc[:, [f\"{method}\" for method in pyod_methods]].head(50).iloc[::-1].plot(\n",
    "            figsize=(6, 12),\n",
    "            width=1,\n",
    "            kind='barh',\n",
    "            stacked=True,\n",
    "            color=px.colors.qualitative.Alphabet,\n",
    "            edgecolor='black',\n",
    "        )\n",
    "        barplot.set(xlim=(0, len(pyod_methods)))\n",
    "        barplot.xaxis.tick_top()\n",
    "        barplot.xaxis.set_label_position('top')\n",
    "        barplot.set_xlabel(\"Number of detections as outlier in different methods\")\n",
    "        barplot.set_ylabel(\"Samples\")\n",
    "        barplot.set_title(f\"{subset_name} ({len(subset['samples'])})\")\n",
    "        sns.move_legend(barplot, \"upper left\", bbox_to_anchor=(1, 1))\n",
    "        plt.savefig(f\"{path_curr}/{feats_set}/barplot.png\", bbox_inches='tight')\n",
    "        plt.savefig(f\"{path_curr}/{feats_set}/barplot.pdf\", bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "        colors_methods = {m: px.colors.qualitative.Alphabet[m_id] for m_id, m in enumerate(pyod_methods)}\n",
    "        n_cols = 4\n",
    "        n_rows = int(np.ceil(len(pyod_methods) / n_cols))\n",
    "        method_names = list(pyod_methods.keys())\n",
    "        pw_rows = []\n",
    "        for r_id in range(n_rows):\n",
    "            pw_cols = []\n",
    "            for c_id in range(n_cols):\n",
    "                rc_id = r_id * n_cols + c_id\n",
    "                if rc_id < len(pyod_methods):\n",
    "                    method = method_names[rc_id]\n",
    "                    print(method)\n",
    "                    brick = pw.Brick(figsize=(3, 2))\n",
    "                    sns.set_theme(style='whitegrid')\n",
    "                    data_fig = df_outs[f\"{method} anomaly score\"].values\n",
    "                    data_fig = -np.log10(data_fig)\n",
    "                    if len(np.unique(data_fig)) > 0.1 * len(data_fig):\n",
    "                        sns.histplot(\n",
    "                            data=data_fig,\n",
    "                            color=colors_methods[method],\n",
    "                            multiple=\"stack\",\n",
    "                            edgecolor='k',\n",
    "                            linewidth=1,\n",
    "                            ax=brick\n",
    "                        )\n",
    "                    brick.set_title(f\"{method}\")\n",
    "                    brick.set_xlabel(r'$-\\log_{10}(\\mathrm{Anomaly score})$')\n",
    "                    brick.set_ylabel('Count')\n",
    "                    pw_cols.append(brick)\n",
    "                else:\n",
    "                    brick = pw.Brick(figsize=(3.5, 2))\n",
    "                    brick.axis('off')\n",
    "                    pw_cols.append(brick)\n",
    "            pw_rows.append(pw.stack(pw_cols, operator=\"|\"))\n",
    "        pw_fig = pw.stack(pw_rows, operator=\"/\")\n",
    "        pw_fig.savefig(f\"{path_curr}/{feats_set}/methods_anomaly_score.pdf\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Filter samples"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "thld_outls_iqr = 6\n",
    "thld_outls_pyod = 6\n",
    "subsets_names = [\"Controls\", \"СOVID-19 Acute and Dynamics\", \"Down Syndrome\", \"ESRD\"]\n",
    "outs_all = set()\n",
    "if is_data_filter:\n",
    "    for subset_name in subsets_names:\n",
    "        df_outs_iqr = pd.read_excel(f\"{path}/special/053_proof_that_immunodata_is_shit/filtered/03_outliers/IQR/{subsets[subset_name]['path']}/df.xlsx\", index_col=0)\n",
    "        outs_iqr = df_outs_iqr.index[df_outs_iqr['n_iqr_outs'] > thld_outls_iqr].values\n",
    "        print(f\"{subset_name} IQR outliers: {len(outs_iqr)}\")\n",
    "        df_outs_pyod = pd.read_excel(f\"{path}/special/053_proof_that_immunodata_is_shit/filtered/03_outliers/pyod_contam(0.1)_epochs(500)/{subsets[subset_name]['path']}/scaled/df.xlsx\", index_col=0)\n",
    "        outs_pyod = df_outs_pyod.index[df_outs_pyod['Detections'] > thld_outls_pyod].values\n",
    "        print(f\"{subset_name} PyOD outliers: {len(outs_pyod)}\")\n",
    "        outs_union = set.union(set(outs_iqr), set(outs_pyod))\n",
    "        outs_all.update(outs_union)\n",
    "        print(f\"{subset_name} union outliers: {len(outs_union)}\")\n",
    "        outs_intxn = set.intersection(set(outs_iqr), set(outs_pyod))\n",
    "        print(f\"{subset_name} intersection outliers: {len(outs_intxn)}\")\n",
    "        \n",
    "    samples = list(set(df.index.values) - set(outs_all))\n",
    "    df_spls_wo_nans_wo_outs = pd.DataFrame(index=samples)\n",
    "    df_spls_wo_nans_wo_outs.to_excel(f\"{path_save}/samples_wo_nans_wo_outs.xlsx\", index_label=\"Samples\")\n",
    "    df = df.loc[samples, :]\n",
    "    df_w_nans = df_w_nans.loc[samples, :]\n",
    "    subsets = get_subsets(df)\n",
    "    df.to_excel(f\"{path_save}/df_wo_nans_wo_outs.xlsx\", index_label=\"Samples\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Dimensionality reduction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "subsets_dimred = {\n",
    "    'All Samples': df.index.values,\n",
    "    \"Controls\": df.index[(df['Status'] == \"Control\") | (df['COVID-19 stage'] == \"Reconvalescent\") ].values\n",
    "}\n",
    "\n",
    "colors_file = {}\n",
    "colors_status = {}\n",
    "colors_region = {}\n",
    "for subset_name, subset in subsets.items():\n",
    "    if subset_name.startswith(\"File \"):\n",
    "        colors_file[subset['value']] = subset['color']\n",
    "    elif subset_name.startswith(\"Controls \"):\n",
    "        colors_region[subset['value']] = subset['color']\n",
    "    elif subset_name in [\"Controls\", \"СOVID-19 Acute and Dynamics\", \"Down Syndrome\", \"ESRD\"]:\n",
    "        colors_status[subset['value']] = subset['color']\n",
    "\n",
    "for subset_name, samples in subsets_dimred.items():\n",
    "    path_curr = f\"{path_save}/04_dim_red/{subset_name}\"\n",
    "    pathlib.Path(f\"{path_curr}\").mkdir(parents=True, exist_ok=True)\n",
    "    df_dim_red = df.loc[samples, :].copy()\n",
    "\n",
    "    dim_red_labels = {\n",
    "        'PCA': ['PC 1', 'PC 2'],\n",
    "        'SVD': ['SVD 1', 'SVD 2'],\n",
    "        't-SNE': ['t-SNE 1', 't-SNE 2'],\n",
    "        'MDS': ['MDS 1', 'MDS 2'],\n",
    "        'GRP': ['GRP 1', 'GRP 2'],\n",
    "        'SRP': ['SRP 1', 'SRP 2'],\n",
    "        'IsoMap': ['IsoMap 1', 'IsoMap 2'],\n",
    "        'MBDL': ['MBDL 1', 'MBDL 2'],\n",
    "        'ICA': ['ICA 1', 'ICA 2'],\n",
    "    }\n",
    "    dim_red_models = {}\n",
    "    data_dim_red = df_dim_red.loc[:, feats].values\n",
    "\n",
    "    dim_red_models['PCA'] = PCA(n_components=2, whiten=False).fit(data_dim_red)\n",
    "    dim_red_models['SVD'] = TruncatedSVD(n_components=2, algorithm='randomized', n_iter=5).fit(data_dim_red)\n",
    "    dim_red_models['t-SNE'] = TSNE(n_components=2).fit(data_dim_red)\n",
    "    dim_red_models['MDS'] = MDS(n_components=2, metric=True)\n",
    "    dim_red_models['GRP'] = GaussianRandomProjection(n_components=2, eps=0.5).fit(data_dim_red)\n",
    "    dim_red_models['SRP'] = SparseRandomProjection(n_components=2, density='auto', eps=0.5, dense_output=False).fit(data_dim_red)\n",
    "    dim_red_models['IsoMap'] = Isomap(n_components=2, n_neighbors=5).fit(data_dim_red)\n",
    "    dim_red_models['MBDL'] = MiniBatchDictionaryLearning(n_components=2, batch_size=100, alpha=1, n_iter=25).fit(data_dim_red)\n",
    "    dim_red_models['ICA'] = FastICA(n_components=2, algorithm='parallel', whiten=True, tol=1e-3, max_iter=1000)\n",
    "\n",
    "    dim_red_cols = []\n",
    "    for m, drm in dim_red_models.items():\n",
    "        if m in ['MDS', 'ICA']:\n",
    "            dim_red_res = drm.fit_transform(data_dim_red)\n",
    "        else:\n",
    "            dim_red_res = drm.transform(data_dim_red)\n",
    "        df_dim_red.loc[:, dim_red_labels[m][0]] = dim_red_res[:, 0]\n",
    "        df_dim_red.loc[:, dim_red_labels[m][1]] = dim_red_res[:, 1]\n",
    "        dim_red_cols += dim_red_labels[m]\n",
    "    df_dim_red.loc[:, dim_red_cols].to_excel(f\"{path_curr}/df_dim_red.xlsx\")\n",
    "\n",
    "    if subset_name == \"All Samples\":\n",
    "        pathlib.Path(f\"{path_curr}/Files\").mkdir(parents=True, exist_ok=True)\n",
    "        pathlib.Path(f\"{path_curr}/Status\").mkdir(parents=True, exist_ok=True)\n",
    "        for m, drm in dim_red_models.items():\n",
    "            fig = plt.figure(figsize=(8, 6))\n",
    "            sns.set_theme(style='whitegrid')\n",
    "            scatterplot = sns.scatterplot(\n",
    "                data=df_dim_red,\n",
    "                x=dim_red_labels[m][0],\n",
    "                y=dim_red_labels[m][1],\n",
    "                palette=colors_file,\n",
    "                hue='File',\n",
    "                style='File',\n",
    "                linewidth=0.5,\n",
    "                alpha=0.75,\n",
    "                edgecolor=\"k\",\n",
    "                marker='o',\n",
    "                s=40,\n",
    "            )\n",
    "            sns.move_legend(scatterplot, \"lower center\", bbox_to_anchor=(.5, 1), ncol=4, frameon=False)\n",
    "            for ha in scatterplot.legend_.legendHandles:\n",
    "                ha.set_edgecolor(\"k\")\n",
    "                ha.set_linewidth(0.5)\n",
    "                ha._sizes = [60]\n",
    "            plt.setp(scatterplot.get_legend().get_texts(), fontsize='8') # for legend text\n",
    "            plt.setp(scatterplot.get_legend().get_title(), fontsize='15')\n",
    "            plt.savefig(f\"{path_curr}/Files/{m}.png\", bbox_inches='tight', dpi=200)\n",
    "            plt.savefig(f\"{path_curr}/Files/{m}.pdf\", bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "            fig = plt.figure(figsize=(8, 6))\n",
    "            sns.set_theme(style='whitegrid')\n",
    "            scatterplot = sns.scatterplot(\n",
    "                data=df_dim_red.loc[df_dim_red[\"Controls/Cases\"].isin([\"Controls\", \"COVID-19 Acute and Dynamics\", \"Down Syndrome\", \"ESRD\"]), :],\n",
    "                x=dim_red_labels[m][0],\n",
    "                y=dim_red_labels[m][1],\n",
    "                palette=colors_status,\n",
    "                hue='Controls/Cases',\n",
    "                style='Controls/Cases',\n",
    "                linewidth=0.5,\n",
    "                alpha=0.75,\n",
    "                edgecolor=\"k\",\n",
    "                marker='o',\n",
    "                s=40,\n",
    "            )\n",
    "            sns.move_legend(scatterplot, \"lower center\", bbox_to_anchor=(.5, 1), ncol=4, frameon=False)\n",
    "            for ha in scatterplot.legend_.legendHandles:\n",
    "                ha.set_edgecolor(\"k\")\n",
    "                ha.set_linewidth(0.5)\n",
    "                ha._sizes = [60]\n",
    "            plt.setp(scatterplot.get_legend().get_texts(), fontsize='8') # for legend text\n",
    "            plt.setp(scatterplot.get_legend().get_title(), fontsize='15')\n",
    "            plt.savefig(f\"{path_curr}/Status/{m}.png\", bbox_inches='tight', dpi=200)\n",
    "            plt.savefig(f\"{path_curr}/Status/{m}.pdf\", bbox_inches='tight')\n",
    "            plt.close()\n",
    "    elif subset_name == \"Controls\":\n",
    "        pathlib.Path(f\"{path_curr}/Region\").mkdir(parents=True, exist_ok=True)\n",
    "        for m, drm in dim_red_models.items():\n",
    "            fig = plt.figure(figsize=(8, 6))\n",
    "            sns.set_theme(style='whitegrid')\n",
    "            scatterplot = sns.scatterplot(\n",
    "                data=df_dim_red,\n",
    "                x=dim_red_labels[m][0],\n",
    "                y=dim_red_labels[m][1],\n",
    "                palette=colors_region,\n",
    "                hue='Region',\n",
    "                style='Region',\n",
    "                linewidth=0.5,\n",
    "                alpha=0.75,\n",
    "                edgecolor=\"k\",\n",
    "                marker='o',\n",
    "                s=40,\n",
    "            )\n",
    "            sns.move_legend(scatterplot, \"lower center\", bbox_to_anchor=(.5, 1), ncol=4, frameon=False)\n",
    "            for ha in scatterplot.legend_.legendHandles:\n",
    "                ha.set_edgecolor(\"k\")\n",
    "                ha.set_linewidth(0.5)\n",
    "                ha._sizes = [60]\n",
    "            plt.setp(scatterplot.get_legend().get_texts(), fontsize='8') # for legend text\n",
    "            plt.setp(scatterplot.get_legend().get_title(), fontsize='15')\n",
    "            plt.savefig(f\"{path_curr}/Region/{m}.png\", bbox_inches='tight', dpi=200)\n",
    "            plt.savefig(f\"{path_curr}/Region/{m}.pdf\", bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "\n",
    "            legend_handles = []\n",
    "            norm = plt.Normalize(df_dim_red['Age'].min(), df_dim_red['Age'].max())\n",
    "            sm = plt.cm.ScalarMappable(cmap=\"spring\", norm=norm)\n",
    "            sm.set_array([])\n",
    "            fig = plt.figure(figsize=(8, 6))\n",
    "            sns.set_theme(style='whitegrid')\n",
    "            scatter = sns.scatterplot(\n",
    "                data=df_dim_red.loc[df_dim_red['Region'] == 'Central', :],\n",
    "                x=dim_red_labels[m][0],\n",
    "                y=dim_red_labels[m][1],\n",
    "                palette='spring',\n",
    "                hue='Age',\n",
    "                linewidth=0.5,\n",
    "                alpha=0.75,\n",
    "                edgecolor=\"k\",\n",
    "                marker='o',\n",
    "                s=50,\n",
    "            )\n",
    "            scatter.get_legend().remove()\n",
    "            legend_handles.append(mlines.Line2D([], [], marker='o', linestyle='None', markeredgecolor='k', markerfacecolor='lightgrey', markersize=10, label='Central'))\n",
    "            scatter = sns.scatterplot(\n",
    "                data=df_dim_red.loc[df_dim_red['Region'] == 'Yakutia', :],\n",
    "                x=dim_red_labels[m][0],\n",
    "                y=dim_red_labels[m][1],\n",
    "                palette='spring',\n",
    "                hue='Age',\n",
    "                linewidth=0.5,\n",
    "                alpha=0.75,\n",
    "                edgecolor=\"k\",\n",
    "                marker='X',\n",
    "                s=50,\n",
    "            )\n",
    "            scatter.get_legend().remove()\n",
    "            legend_handles.append(mlines.Line2D([], [], marker='X', linestyle='None', markeredgecolor='k', markerfacecolor='lightgrey', markersize=10, label='Yakutia'))\n",
    "            plt.legend(handles=legend_handles, title=\"Region\", bbox_to_anchor=(0, 1.02, 1, 0.2), loc=\"lower left\", mode=\"expand\", borderaxespad=0, ncol=2, frameon=False)\n",
    "            fig.colorbar(sm, label=\"Age\")\n",
    "            plt.savefig(f\"{path_curr}/Region/{m}_colorAge.png\", bbox_inches='tight', dpi=200)\n",
    "            plt.savefig(f\"{path_curr}/Region/{m}_colorAge.pdf\", bbox_inches='tight')\n",
    "            plt.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5. Region tests"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path_curr = f\"{path_save}/05_region_tests\"\n",
    "pathlib.Path(f\"{path_curr}/feats\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df_curr = df.loc[subsets['Controls']['samples'], :].copy()\n",
    "\n",
    "colors_region['Central'] = subsets['Controls Central']['color']\n",
    "colors_region['Yakutia'] = subsets['Controls Yakutia']['color']\n",
    "\n",
    "df_stat = pd.DataFrame(index=list(feats))\n",
    "for feat in list(feats) + ['SImAge acceleration']:\n",
    "    vals = {}\n",
    "    for group in ['Central', 'Yakutia']:\n",
    "        vals[group] = df_curr.loc[df_curr['Region'] == group, feat].values\n",
    "        df_stat.at[feat, f\"mean_{group}\"] = np.mean(vals[group])\n",
    "        df_stat.at[feat, f\"median_{group}\"] = np.median(vals[group])\n",
    "        df_stat.at[feat, f\"q75_{group}\"], df_stat.at[feat, f\"q25_{group}\"] = np.percentile(vals[group], [75 , 25])\n",
    "        df_stat.at[feat, f\"iqr_{group}\"] = df_stat.at[feat, f\"q75_{group}\"] - df_stat.at[feat, f\"q25_{group}\"]\n",
    "        if feat == 'SImAge acceleration':\n",
    "            df_stat.at[feat, f\"MAE_{group}\"] = mean_absolute_error(df_curr.loc[df_curr['Region'] == group, 'Age'].values, df_curr.loc[df_curr['Region'] == group, 'SImAge'].values)\n",
    "    _, df_stat.at[feat, \"mw_pval\"] = mannwhitneyu(vals['Central'], vals['Yakutia'], alternative='two-sided')\n",
    "\n",
    "_, df_stat.loc[feats, \"mw_pval_fdr_bh\"], _, _ = multipletests(df_stat.loc[feats, \"mw_pval\"], 0.05, method='fdr_bh')\n",
    "df_stat.sort_values([f\"mw_pval_fdr_bh\"], ascending=[True], inplace=True)\n",
    "df_stat.to_excel(f\"{path_curr}/kw_mw.xlsx\", index_label='Features')\n",
    "\n",
    "feat = 'SImAge acceleration'\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.set_theme(style='whitegrid')\n",
    "violin = sns.violinplot(\n",
    "    data=df_curr,\n",
    "    x='Region',\n",
    "    y=feat,\n",
    "    palette=colors_region,\n",
    "    scale='width',\n",
    "    order=list(colors_region.keys()),\n",
    "    saturation=0.75,\n",
    ")\n",
    "violin.set_xlabel(f\"Region\")\n",
    "mw_pval = df_stat.at[feat, \"mw_pval\"]\n",
    "pval_formatted = [f'{mw_pval:.2e}']\n",
    "annotator = Annotator(\n",
    "    violin,\n",
    "    pairs=[('Central', 'Yakutia')],\n",
    "    data=df_curr,\n",
    "    x='Region',\n",
    "    y=feat,\n",
    "    order=list(colors_region.keys())\n",
    ")\n",
    "annotator.set_custom_annotations(pval_formatted)\n",
    "annotator.configure(loc='outside')\n",
    "annotator.annotate()\n",
    "plt.savefig(f\"{path_curr}/{feat}.png\", bbox_inches='tight', dpi=200)\n",
    "plt.savefig(f\"{path_curr}/{feat}.pdf\", bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "feats_sorted = df_stat.index[df_stat.index.isin(feats)].values\n",
    "axs = {}\n",
    "pw_rows = []\n",
    "n_cols = 4\n",
    "n_rows = int(np.ceil(len(feats_sorted) / n_cols))\n",
    "for r_id in range(n_rows):\n",
    "    pw_cols = []\n",
    "    for c_id in range(n_cols):\n",
    "        rc_id = r_id * n_cols + c_id\n",
    "        if rc_id < len(feats_sorted):\n",
    "            feat = feats_sorted[rc_id]\n",
    "            axs[feat] = pw.Brick(figsize=(3, 2))\n",
    "            sns.set_theme(style='whitegrid')\n",
    "            sns.violinplot(\n",
    "                data=df_curr,\n",
    "                x='Region',\n",
    "                y=feat,\n",
    "                palette=colors_region,\n",
    "                scale='width',\n",
    "                order=list(colors_region.keys()),\n",
    "                saturation=0.75,\n",
    "                ax=axs[feat]\n",
    "            )\n",
    "            axs[feat].set_ylabel(feat)\n",
    "            axs[feat].set_xlabel(f\"Region\")\n",
    "            mw_pval = df_stat.at[feat, \"mw_pval_fdr_bh\"]\n",
    "            pval_formatted = [f'{mw_pval:.2e}']\n",
    "            annotator = Annotator(\n",
    "                axs[feat],\n",
    "                pairs=[('Central', 'Yakutia')],\n",
    "                data=df_curr,\n",
    "                x='Region',\n",
    "                y=feat,\n",
    "                order=list(colors_region.keys()),\n",
    "            )\n",
    "            annotator.set_custom_annotations(pval_formatted)\n",
    "            annotator.configure(loc='outside')\n",
    "            annotator.annotate()\n",
    "            pw_cols.append(axs[feat])\n",
    "        else:\n",
    "            empty_fig = pw.Brick(figsize=(3.6, 2))\n",
    "            empty_fig.axis('off')\n",
    "            pw_cols.append(empty_fig)\n",
    "\n",
    "    pw_rows.append(pw.stack(pw_cols, operator=\"|\"))\n",
    "pw_fig = pw.stack(pw_rows, operator=\"/\")\n",
    "pw_fig.savefig(f\"{path_curr}/feats.pdf\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
