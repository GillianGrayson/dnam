{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src.utils.outliers.iqr import add_iqr_outs_to_df, plot_iqr_outs, plot_iqr_outs_regression_error\n",
    "from src.utils.outliers.pyod import add_pyod_outs_to_df, plot_pyod_outs, plot_pyod_outs_regression_error\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy import stats\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import importlib\n",
    "pio.kaleido.scope.mathjax = None\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "from scipy.interpolate import interp1d\n",
    "from src.utils.verbose import NoStdStreams\n",
    "init_notebook_mode(connected=False)\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from omegaconf import OmegaConf\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "import pathlib\n",
    "import patchworklib as pw\n",
    "import os\n",
    "import functools\n",
    "from scipy.stats import iqr\n",
    "from statannotations.Annotator import Annotator\n",
    "from scipy.stats import mannwhitneyu\n",
    "import shap\n",
    "from slugify import slugify\n",
    "from src.models.tabular.widedeep.ft_transformer import WDFTTransformerModel\n",
    "from art.estimators.regression.pytorch import PyTorchRegressor\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "from art.estimators.regression.blackbox import BlackBoxRegressor\n",
    "from art.attacks.evasion import ProjectedGradientDescentNumpy, FastGradientMethod, BasicIterativeMethod, MomentumIterativeMethod\n",
    "from art.attacks.evasion import ZooAttack, CarliniL2Method, ElasticNet, NewtonFool\n",
    "import torch\n",
    "from src.tasks.metrics import get_cls_pred_metrics, get_cls_prob_metrics, get_reg_metrics\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "from pyod.models.ecod import ECOD\n",
    "from pyod.models.copod import COPOD\n",
    "from pyod.models.sos import SOS\n",
    "from pyod.models.qmcd import QMCD as QMCDOD\n",
    "from pyod.models.sampling import Sampling\n",
    "from pyod.models.gmm import GMM\n",
    "from pyod.models.pca import PCA\n",
    "from pyod.models.mcd import MCD\n",
    "from pyod.models.cd import CD\n",
    "from pyod.models.lmdd import LMDD\n",
    "from pyod.models.lof import LOF\n",
    "from pyod.models.cof import COF\n",
    "from pyod.models.cblof import CBLOF\n",
    "from pyod.models.hbos import HBOS\n",
    "from pyod.models.knn import KNN\n",
    "from pyod.models.sod import SOD\n",
    "from pyod.models.rod import ROD\n",
    "from pyod.models.iforest import IForest\n",
    "from pyod.models.inne import INNE\n",
    "from pyod.models.dif import DIF\n",
    "from pyod.models.feature_bagging import FeatureBagging\n",
    "from pyod.models.loda import LODA\n",
    "from pyod.models.lunar import LUNAR\n",
    "\n",
    "from pythresh.thresholds.iqr import IQR\n",
    "from pythresh.thresholds.mad import MAD\n",
    "from pythresh.thresholds.fwfm import FWFM\n",
    "from pythresh.thresholds.yj import YJ\n",
    "from pythresh.thresholds.zscore import ZSCORE\n",
    "from pythresh.thresholds.aucp import AUCP\n",
    "from pythresh.thresholds.qmcd import QMCD\n",
    "from pythresh.thresholds.fgd import FGD\n",
    "from pythresh.thresholds.dsn import DSN\n",
    "from pythresh.thresholds.clf import CLF\n",
    "from pythresh.thresholds.filter import FILTER\n",
    "from pythresh.thresholds.wind import WIND\n",
    "from pythresh.thresholds.eb import EB\n",
    "from pythresh.thresholds.regr import REGR\n",
    "from pythresh.thresholds.boot import BOOT\n",
    "from pythresh.thresholds.mcst import MCST\n",
    "from pythresh.thresholds.hist import HIST\n",
    "from pythresh.thresholds.moll import MOLL\n",
    "from pythresh.thresholds.chau import CHAU\n",
    "from pythresh.thresholds.gesd import GESD\n",
    "from pythresh.thresholds.mtt import MTT\n",
    "from pythresh.thresholds.karch import KARCH\n",
    "from pythresh.thresholds.ocsvm import OCSVM\n",
    "from pythresh.thresholds.clust import CLUST\n",
    "from pythresh.thresholds.decomp import DECOMP\n",
    "from pythresh.thresholds.meta import META\n",
    "from pythresh.thresholds.vae import VAE\n",
    "from pythresh.thresholds.cpd import CPD\n",
    "from pythresh.thresholds.gamgmm import GAMGMM\n",
    "from pythresh.thresholds.mixmod import MIXMOD\n",
    "\n",
    "from pytorch_tabular.config import DataConfig, OptimizerConfig, TrainerConfig\n",
    "from pytorch_tabular.models.common.heads import LinearHeadConfig\n",
    "from pytorch_tabular import model_sweep\n",
    "import warnings\n",
    "\n",
    "\n",
    "def conjunction(conditions):\n",
    "    return functools.reduce(np.logical_and, conditions)\n",
    "\n",
    "\n",
    "def disjunction(conditions):\n",
    "    return functools.reduce(np.logical_or, conditions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Load data and model, define PyTorchRegressor, setup colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = \"D:/YandexDisk/Work/pydnameth/datasets/GPL21145/GSEUNN\"\n",
    "path_model = f\"{path}/data/immuno/models/SImAge\"\n",
    "path_save = f\"{path}/special/064_tai_report_4/immuno\"\n",
    "pathlib.Path(f\"{path_save}\").mkdir(parents=True, exist_ok=True)\n",
    "df = pd.read_excel(f\"{path}/data/immuno/models/SImAge/data.xlsx\", index_col='sample_id')\n",
    "feats = pd.read_excel(f\"{path}/data/immuno/models/SImAge/feats_con_top10.xlsx\", index_col=0).index.values\n",
    "ids_feat = list(range(len(feats)))\n",
    "col_trgt = 'Age'\n",
    "col_pred = 'SImAge'\n",
    "\n",
    "df_preds = pd.read_excel(f\"{path}/data/immuno/models/SImAge/results/predictions.xlsx\", index_col=0)\n",
    "ids_trn = df_preds.index[df_preds['fold_0002'] == 'trn'].values\n",
    "ids_val = df_preds.index[df_preds['fold_0002'] == 'val'].values\n",
    "ids_tst = df_preds.index[df_preds['fold_0002'] == 'tst_ctrl_central'].values\n",
    "ids_all = df_preds.index[df_preds['fold_0002'].isin(['trn', 'val', 'tst_ctrl_central'])].values\n",
    "ids_trn_val = df_preds.index[df_preds['fold_0002'].isin(['trn', 'val'])].values\n",
    "ids_dict = {\n",
    "    'all': ids_all,\n",
    "    'trn_val': ids_trn_val,\n",
    "    'tst': ids_tst\n",
    "}\n",
    "\n",
    "df = df.loc[ids_all, :]\n",
    "df[\"SImAge Error\"] = df[\"SImAge\"] - df[\"Age\"]\n",
    "df[\"|SImAge Error|\"] = df[\"SImAge Error\"].abs()\n",
    "df['Data'] = 'Real'\n",
    "df['Eps'] = 'Origin'\n",
    "\n",
    "model = WDFTTransformerModel.load_from_checkpoint(checkpoint_path=f\"{path}/data/immuno/models/SImAge/best_fold_0002.ckpt\")\n",
    "model.eval()\n",
    "model.freeze()\n",
    "\n",
    "def predict_func_regression(X):\n",
    "    model.produce_probabilities = True\n",
    "    batch = {\n",
    "        'all': torch.from_numpy(np.float32(X[:, ids_feat])),\n",
    "        'continuous': torch.from_numpy(np.float32(X[:, ids_feat])),\n",
    "        'categorical': torch.from_numpy(np.int32(X[:, []])),\n",
    "    }\n",
    "    tmp = model(batch)\n",
    "    return tmp.cpu().detach().numpy()\n",
    "\n",
    "art_regressor = PyTorchRegressor(\n",
    "    model=model,\n",
    "    loss=model.loss_fn,\n",
    "    input_shape=[len(feats)],\n",
    "    optimizer=torch.optim.Adam(\n",
    "        params=model.parameters(),\n",
    "        lr=model.hparams.optimizer_lr,\n",
    "        weight_decay=model.hparams.optimizer_weight_decay\n",
    "    ),\n",
    "    use_amp=False,\n",
    "    opt_level=\"O1\",\n",
    "    loss_scale=\"dynamic\",\n",
    "    channels_first=True,\n",
    "    clip_values=None,\n",
    "    preprocessing_defences=None,\n",
    "    postprocessing_defences=None,\n",
    "    preprocessing=(0.0, 1.0),\n",
    "    device_type=\"cpu\",\n",
    ")\n",
    "\n",
    "colors_atks = {\n",
    "    \"MomentumIterative\": px.colors.qualitative.D3[0],\n",
    "    \"BasicIterative\": px.colors.qualitative.D3[1],\n",
    "    \"FastGradient\": px.colors.qualitative.D3[3],\n",
    "}\n",
    "\n",
    "df.to_excel(f\"{path_save}/df_origin.xlsx\", index_label='sample_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Create pyod and pythresh models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    'ECDF-Based (ECOD)': ECOD(),\n",
    "    'Copula-Based (COPOD)': COPOD(),\n",
    "    # 'Stochastic (SOS)': SOS(),\n",
    "    'Quasi-Monte Carlo Discrepancy (QMCD)': QMCDOD(),\n",
    "    'Rapid distance-based via Sampling': Sampling(),\n",
    "    'Probabilistic Mixture Modeling (GMM)': GMM(),\n",
    "    'Principal Component Analysis (PCA)': PCA(),\n",
    "    'Minimum Covariance Determinant (MCD)': MCD(),\n",
    "    'Cook\\'s Distance (CD)': CD(),\n",
    "    'Deviation-based Outlier Detection (LMDD)': LMDD(),\n",
    "    'Local Outlier Factor (LOF)': LOF(),\n",
    "    'Connectivity-Based Outlier Factor (COF)': COF(),\n",
    "    'Clustering-Based Local Outlier Factor (CBLOF)': CBLOF(),\n",
    "    'Histogram-based Outlier Score (HBOS)': HBOS(),\n",
    "    'k Nearest Neighbors (kNN)': KNN(),\n",
    "    'Subspace Outlier Detection (SOD)': SOD(),\n",
    "    # 'Rotation-based Outlier Detection (ROD)': ROD(),\n",
    "    'Isolation Forest': IForest(),\n",
    "    # 'Isolation-Based with Nearest-Neighbor Ensembles (INNE)': INNE(),\n",
    "    'Deep Isolation Forest for Anomaly Detection (DIF)': DIF(),\n",
    "    'Feature Bagging': FeatureBagging(),\n",
    "    'Lightweight On-line Detector of Anomalies (LODA)': LODA(),\n",
    "    'LUNAR': LUNAR()\n",
    "}\n",
    "\n",
    "thresholders = {\n",
    "        'Inter-Quartile Region (IQR)':IQR(),\n",
    "        'Median Absolute Deviation (MAD)':MAD(),\n",
    "        'Full Width at Full Minimum (FWFM)':FWFM(),\n",
    "        'Yeo-Johnson Transformation (YJ)': YJ(),\n",
    "        'Z Score (ZSCORE)': ZSCORE(),\n",
    "        'AUC Percentage (AUCP)': AUCP(),\n",
    "        'Quasi-Monte Carlo Discreperancy (QMCD)': QMCD(),\n",
    "        'Fixed Gradient Descent (FGD)': FGD(),\n",
    "        'Distance Shift from Normal (DSN)': DSN(),\n",
    "        'Trained Classifier (CLF)': CLF(),\n",
    "        'Filtering Based (FILTER)': FILTER(),\n",
    "        'Topological Winding Number (WIND)': WIND(),\n",
    "        'Elliptical Boundary (EB)': EB(),\n",
    "        'Regression Intercept (REGR)': REGR(),\n",
    "        # 'Bootstrap Method (BOOT)': BOOT(),\n",
    "        'Monte Carlo Statistical Tests (MCST)': MCST(),\n",
    "        # 'Histogram Based Methods (HIST)': HIST(),\n",
    "        'Mollifier (MOLL)': MOLL(),\n",
    "        \"Chauvenet's Criterion (CHAU)\": CHAU(),\n",
    "        'Generalized Extreme Studentized Deviate (GESD)': GESD(),\n",
    "        # 'Modified Thompson Tau Test (MTT)': MTT(),\n",
    "        'Karcher Mean (KARCH)': KARCH(),\n",
    "        'One-Class SVM (OCSVM)': OCSVM(),\n",
    "        'Clustering (CLUST)': CLUST(),\n",
    "        'Decomposition (DECOMP)': DECOMP(),\n",
    "        'Meta-model (META)': META(),\n",
    "        'Variational Autoencoder (VAE)': VAE(),\n",
    "        'Change Point Detection (CPD)': CPD(),\n",
    "        # 'Bayesian Gamma GMM (GAMGMM)': GAMGMM(skip=True),\n",
    "        'Mixture Models (MIXMOD)': MIXMOD(),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outliers for original data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "df_outs = pd.DataFrame(index=list(classifiers.keys()), columns=list(thresholders.keys()))\n",
    "for pyod_m_name, pyod_m in classifiers.items():\n",
    "    scores = pyod_m.fit(df.loc[:, feats].values).decision_scores_\n",
    "    for pythresh_m_name, pythresh_m in thresholders.items():\n",
    "        labels = pythresh_m.eval(scores)\n",
    "        df_outs.at[pyod_m_name, pythresh_m_name] = sum(labels) / len(labels) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_outs.to_excel(f\"{path_save}/outliers.xlsx\")\n",
    "df_fig = df_outs.astype(float)\n",
    "sns.set_theme(style='ticks', font_scale=1.0)\n",
    "fig, ax = plt.subplots(figsize=(16, 12))\n",
    "heatmap = sns.heatmap(\n",
    "    df_fig,\n",
    "    annot=True,\n",
    "    fmt=\".1f\",\n",
    "    cmap='hot',\n",
    "    linewidth=0.1,\n",
    "    linecolor='black',\n",
    "    cbar_kws={\n",
    "        'orientation': 'horizontal',\n",
    "        'location': 'top',\n",
    "        'pad': 0.025,\n",
    "        'aspect': 30\n",
    "    },\n",
    "    annot_kws={\"size\": 12},\n",
    "    ax=ax\n",
    ")\n",
    "ax.set_xlabel('Outliers Detection Algorithms')\n",
    "ax.set_ylabel('Thresholding Algorithms')\n",
    "heatmap_pos = heatmap.get_position()\n",
    "ax.figure.axes[-1].set_title(\"Outliers' percentage\")\n",
    "ax.figure.axes[-1].tick_params()\n",
    "for spine in ax.figure.axes[-1].spines.values():\n",
    "    spine.set_linewidth(1)\n",
    "plt.savefig(f\"{path_save}/outliers.png\", bbox_inches='tight', dpi=200)\n",
    "plt.savefig(f\"{path_save}/outliers.pdf\", bbox_inches='tight')\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Adversarial attacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epsilons = sorted(list(set.union(\n",
    "    set(np.linspace(0.1, 1.0, 10)), \n",
    "    set(np.linspace(0.01, 0.1, 10)),\n",
    ")))\n",
    "df_eps = pd.DataFrame(index=epsilons)\n",
    "\n",
    "for eps_raw in epsilons:\n",
    "\n",
    "    eps = np.array([eps_raw * iqr(df.loc[:, feat].values) for feat in feats])\n",
    "    eps_step = np.array([0.2 * eps_raw * iqr(df.loc[:, feat].values) for feat in feats])\n",
    "\n",
    "    attacks = {\n",
    "        'MomentumIterative': MomentumIterativeMethod(\n",
    "            estimator=art_regressor,\n",
    "            norm=np.inf,\n",
    "            eps=eps,\n",
    "            eps_step=eps_step,\n",
    "            decay=0.1,\n",
    "            max_iter=100,\n",
    "            targeted=False,\n",
    "            batch_size=512,\n",
    "            verbose=True\n",
    "        ),\n",
    "        'BasicIterative': BasicIterativeMethod(\n",
    "            estimator=art_regressor,\n",
    "            eps=eps,\n",
    "            eps_step=eps_step,\n",
    "            max_iter=100,\n",
    "            targeted=False,\n",
    "            batch_size=512,\n",
    "            verbose=True\n",
    "        ),\n",
    "        'FastGradient': FastGradientMethod(\n",
    "            estimator=art_regressor,\n",
    "            norm=np.inf,\n",
    "            eps=eps,\n",
    "            eps_step=eps_step,\n",
    "            targeted=False,\n",
    "            num_random_init=0,\n",
    "            batch_size=512,\n",
    "            minimal=False,\n",
    "            summary_writer=False,\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    for attack_name, attack in attacks.items():\n",
    "        path_curr = f\"{path_save}/Evasion/{attack_name}/eps_{eps_raw:0.4f}\"\n",
    "        pathlib.Path(f\"{path_curr}\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        X_adv = attack.generate(np.float32(df.loc[:, feats].values))\n",
    "        \n",
    "        df_adv = df.loc[:, ['Age']].copy()\n",
    "        df_adv.loc[:, feats] = X_adv\n",
    "        df_adv[\"SImAge\"] = model(torch.from_numpy(np.float32(df_adv.loc[:, feats].values))).cpu().detach().numpy().ravel()\n",
    "        df_adv[\"SImAge Error\"] = df_adv[\"SImAge\"] - df_adv[\"Age\"]\n",
    "        df_adv[\"|SImAge Error|\"] = df_adv[\"SImAge Error\"].abs()\n",
    "        df_adv.loc[:, \"Error Origin\"] = df.loc[:, \"SImAge\"] - df.loc[:, \"Age\"]\n",
    "        df_adv.loc[:, \"Error Attack\"] = df_adv.loc[:, \"SImAge\"] - df_adv.loc[:, \"Age\"]\n",
    "        df_adv['Error Diff'] = df_adv['Error Attack'] - df_adv['Error Origin']\n",
    "        df_adv['|Error Diff|'] = df_adv['Error Diff'].abs()\n",
    "            \n",
    "        df_adv.to_excel(f\"{path_curr}/df.xlsx\", index_label='sample_id')\n",
    "\n",
    "        metrics = get_reg_metrics()\n",
    "        metrics_cols = [f\"{m}_{p}\" for m in metrics for p in ids_dict]\n",
    "        df_metrics = pd.DataFrame(index=metrics_cols)\n",
    "        for p, ids_part in ids_dict.items():\n",
    "            for m in metrics:\n",
    "                m_val = float(metrics[m][0](torch.from_numpy(np.float32(df.loc[ids_part, \"SImAge\"].values)), torch.from_numpy(np.float32(df.loc[ids_part, \"Age\"].values))).numpy())\n",
    "                df_metrics.at[f\"{m}_{p}\", 'Origin'] = m_val\n",
    "                metrics[m][0].reset()\n",
    "                m_val = float(metrics[m][0](torch.from_numpy(np.float32(df_adv.loc[ids_part, \"SImAge\"].values)), torch.from_numpy(np.float32(df.loc[ids_part, \"Age\"].values))).numpy())\n",
    "                df_metrics.at[f\"{m}_{p}\", 'Attack'] = m_val\n",
    "                metrics[m][0].reset()\n",
    "        df_metrics.to_excel(f\"{path_curr}/metrics.xlsx\", index_label='Metrics')\n",
    "        \n",
    "        for p in ids_dict:\n",
    "            if attack_name == 'MomentumIterative':\n",
    "                df_eps.loc[eps_raw, f\"Origin_MAE_{p}\"] = df_metrics.at[f'mean_absolute_error_{p}', 'Origin']\n",
    "            df_eps.loc[eps_raw, f\"{attack_name}_MAE_{p}\"] = df_metrics.at[f'mean_absolute_error_{p}', 'Attack']\n",
    "            \n",
    "df_eps.to_excel(f\"{path_save}/Evasion/df_eps.xlsx\", index_label='eps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Error from Eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in ids_dict:\n",
    "    df_fig = df_eps.loc[:, [f\"{x}_MAE_{p}\" for x in colors_atks]].copy()\n",
    "    df_fig.rename(columns={f\"{x}_MAE_{p}\": x for x in colors_atks}, inplace=True)\n",
    "    df_fig['Eps'] = df_fig.index.values\n",
    "    df_fig = df_fig.melt(id_vars=\"Eps\", var_name='Method', value_name=\"MAE\")\n",
    "    sns.set_theme(style='ticks', font_scale=1)\n",
    "    fig = plt.figure()\n",
    "    lines = sns.lineplot(\n",
    "        data=df_fig,\n",
    "        x='Eps',\n",
    "        y=\"MAE\",\n",
    "        hue=f\"Method\",\n",
    "        style=f\"Method\",\n",
    "        palette=colors_atks,\n",
    "        hue_order=list(colors_atks.keys()),\n",
    "        markers=True,\n",
    "        dashes=False,\n",
    "    )\n",
    "    plt.xscale('log')\n",
    "    lines.set_xlabel(r'$\\epsilon$')\n",
    "    x_min = 0.009\n",
    "    x_max = 1.05\n",
    "    mae_basic = df_eps.at[0.01, f\"Origin_MAE_{p}\"]\n",
    "    lines.set_xlim(x_min, x_max)\n",
    "    plt.gca().plot(\n",
    "        [x_min, x_max],\n",
    "        [mae_basic, mae_basic],\n",
    "        color='k',\n",
    "        linestyle='dashed',\n",
    "        linewidth=1\n",
    "    )\n",
    "    plt.savefig(f\"{path_save}/Evasion/line_mae_vs_eps_{p}.png\", bbox_inches='tight', dpi=200)\n",
    "    plt.savefig(f\"{path_save}/Evasion/line_mae_vs_eps_{p}.pdf\", bbox_inches='tight')\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Plot distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "epsilons_hglt = [0.01, 0.02, 0.05, 0.1, 0.2, 0.5]\n",
    "colors_epsilons = {x: px.colors.qualitative.G10[x_id] for x_id, x in enumerate(['Origin'] + epsilons_hglt)}\n",
    "\n",
    "df['Eps'] = 'Origin'\n",
    "df['MarkerSize'] = 40\n",
    "\n",
    "for atk in colors_atks:\n",
    "\n",
    "    for eps in epsilons_hglt:\n",
    "        path_curr = f\"{path_save}/Evasion/{atk}/eps_{eps:0.4f}\"\n",
    "        pathlib.Path(f\"{path_curr}/SImAgeError\").mkdir(parents=True, exist_ok=True)\n",
    "        df_adv = pd.read_excel(f\"{path_curr}/df.xlsx\", index_col='sample_id')\n",
    "        df_adv.index += f'_eps_{eps:0.4f}'\n",
    "        df_adv['Eps'] = eps\n",
    "        df_adv['MarkerSize'] = 30\n",
    "        df_ori_adv = pd.concat([df, df_adv])\n",
    "        \n",
    "        pw_brick_kdes = {}\n",
    "        pw_brick_scatters = {}\n",
    "        for f in feats:\n",
    "            \n",
    "            pw_brick_kdes[f] = pw.Brick(figsize=(3, 2))\n",
    "            sns.set_theme(style='whitegrid')\n",
    "            kdeplot = sns.kdeplot(\n",
    "                data=df_ori_adv,\n",
    "                x=f,\n",
    "                hue='Eps',\n",
    "                palette={'Origin': 'grey', eps: colors_epsilons[eps]},\n",
    "                hue_order=['Origin', eps],\n",
    "                fill=True,\n",
    "                common_norm=False,\n",
    "                ax=pw_brick_kdes[f]\n",
    "            )\n",
    "            \n",
    "            pw_brick_scatters[f] = pw.Brick(figsize=(3, 2))\n",
    "            sns.set_theme(style='whitegrid')\n",
    "            scatterplot = sns.scatterplot(\n",
    "                data=df_ori_adv,\n",
    "                x=f,\n",
    "                y='Age',\n",
    "                hue='Eps',\n",
    "                palette={'Origin': 'grey', eps: colors_epsilons[eps]},\n",
    "                hue_order=['Origin', eps],\n",
    "                linewidth=0.85,\n",
    "                alpha=0.75,\n",
    "                edgecolor=\"k\",\n",
    "                marker='o',\n",
    "                s=30,\n",
    "                ax=pw_brick_scatters[f]\n",
    "            )\n",
    "        \n",
    "        n_cols = 5\n",
    "        n_rows = int(np.ceil(len(feats)/ n_cols))\n",
    "        pw_rows_kdes = []\n",
    "        pw_rows_scatters = []\n",
    "        for r_id in range(n_rows):\n",
    "            pw_cols_kdes = []\n",
    "            pw_cols_scatters = []\n",
    "            for c_id in range(n_cols):\n",
    "                rc_id = r_id * n_cols + c_id\n",
    "                if rc_id < len(feats):\n",
    "                    f = feats[rc_id]\n",
    "                    pw_cols_kdes.append(pw_brick_kdes[f])\n",
    "                    pw_cols_scatters.append(pw_brick_scatters[f])\n",
    "                else:\n",
    "                    empty_fig = pw.Brick(figsize=(4.67, 3))\n",
    "                    empty_fig.axis('off')\n",
    "                    pw_cols_kdes.append(empty_fig)\n",
    "                    pw_cols_scatters.append(empty_fig)\n",
    "            pw_rows_kdes.append(pw.stack(pw_cols_kdes, operator=\"|\"))\n",
    "            pw_rows_scatters.append(pw.stack(pw_cols_scatters, operator=\"|\"))\n",
    "        pw_fig_kde = pw.stack(pw_rows_kdes, operator=\"/\")\n",
    "        pw_fig_kde.savefig(f\"{path_curr}/feats_kde.png\", bbox_inches='tight', dpi=200)\n",
    "        pw_fig_kde.savefig(f\"{path_curr}/feats_kde.pdf\", bbox_inches='tight')\n",
    "        pw_fig_scatter = pw.stack(pw_rows_scatters, operator=\"/\")\n",
    "        pw_fig_scatter.savefig(f\"{path_curr}/feats_scatter.png\", bbox_inches='tight', dpi=200)\n",
    "        pw_fig_scatter.savefig(f\"{path_curr}/feats_scatter.pdf\", bbox_inches='tight')\n",
    "        pw.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers for attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T10:55:48.450734Z",
     "start_time": "2024-07-05T10:33:43.269988Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "epsilons_hglt = [0.05, 0.1, 0.5, 1.0]\n",
    "\n",
    "for atk in colors_atks:\n",
    "    for eps in epsilons_hglt:\n",
    "        path_curr = f\"{path_save}/Evasion/{atk}/eps_{eps:0.4f}\"\n",
    "        pathlib.Path(f\"{path_curr}/SImAgeError\").mkdir(parents=True, exist_ok=True)\n",
    "        df_adv = pd.read_excel(f\"{path_curr}/df.xlsx\", index_col='sample_id')\n",
    "        \n",
    "        df_outs = pd.DataFrame(index=list(classifiers.keys()), columns=list(thresholders.keys()))\n",
    "        for pyod_m_name, pyod_m in classifiers.items():\n",
    "            scores = pyod_m.fit(df_adv.loc[:, feats].values).decision_scores_\n",
    "            for pythresh_m_name, pythresh_m in thresholders.items():\n",
    "                labels = pythresh_m.eval(scores)\n",
    "                df_outs.at[pyod_m_name, pythresh_m_name] = sum(labels) / len(labels) * 100\n",
    "                \n",
    "        df_outs.to_excel(f\"{path_curr}/outliers.xlsx\")\n",
    "        \n",
    "        df_fig = df_outs.astype(float)\n",
    "        sns.set_theme(style='ticks', font_scale=1.0)\n",
    "        fig, ax = plt.subplots(figsize=(16, 12))\n",
    "        heatmap = sns.heatmap(\n",
    "            df_fig,\n",
    "            annot=True,\n",
    "            fmt=\".1f\",\n",
    "            cmap='hot',\n",
    "            linewidth=0.1,\n",
    "            linecolor='black',\n",
    "            cbar_kws={\n",
    "                'orientation': 'horizontal',\n",
    "                'location': 'top',\n",
    "                'pad': 0.025,\n",
    "                'aspect': 30\n",
    "            },\n",
    "            annot_kws={\"size\": 12},\n",
    "            ax=ax\n",
    "        )\n",
    "        ax.set_xlabel('Outliers Detection Algorithms')\n",
    "        ax.set_ylabel('Thresholding Algorithms')\n",
    "        heatmap_pos = heatmap.get_position()\n",
    "        ax.figure.axes[-1].set_title(\"Outliers' percentage\")\n",
    "        ax.figure.axes[-1].tick_params()\n",
    "        for spine in ax.figure.axes[-1].spines.values():\n",
    "            spine.set_linewidth(1)\n",
    "        plt.savefig(f\"{path_curr}/outliers.png\", bbox_inches='tight', dpi=200)\n",
    "        plt.savefig(f\"{path_curr}/outliers.pdf\", bbox_inches='tight')\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial defences from attacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate detectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ori = df[feats].copy()\n",
    "df_ori['Class'] = 'Original'\n",
    "\n",
    "for atk in colors_atks:\n",
    "    \n",
    "    df_def_acc = pd.DataFrame(index=epsilons, columns=['Model'] + list(epsilons))\n",
    "    \n",
    "    for eps in tqdm(epsilons):\n",
    "        \n",
    "        path_curr = f\"{path_save}/Evasion/{atk}/eps_{eps:0.4f}\"\n",
    "        df_adv = pd.read_excel(f\"{path_curr}/df.xlsx\", index_col='sample_id')\n",
    "        df_adv = df_adv[feats]\n",
    "        df_adv['Class'] = 'Attack'\n",
    "        df_def_trn_val = pd.concat([df_ori.loc[ids_trn_val, :], df_adv.loc[ids_trn_val, :]])\n",
    "        df_def_tst = pd.concat([df_ori.loc[ids_tst, :], df_adv.loc[ids_tst, :]])\n",
    "        \n",
    "        data_config = DataConfig(\n",
    "            target=['Class'],\n",
    "            continuous_cols=list(feats),\n",
    "            continuous_feature_transform='yeo-johnson',\n",
    "            normalize_continuous_features=True,\n",
    "        )\n",
    "        \n",
    "        trainer_config = TrainerConfig(\n",
    "            batch_size=1024,\n",
    "            max_epochs=100,\n",
    "            min_epochs=1,\n",
    "            auto_lr_find=True,\n",
    "            early_stopping='valid_loss',\n",
    "            early_stopping_min_delta=0.0001,\n",
    "            early_stopping_mode='min',\n",
    "            early_stopping_patience=100,\n",
    "            checkpoints='valid_loss',\n",
    "            checkpoints_path=f\"{path_curr}/detector\",\n",
    "            load_best=True,\n",
    "            progress_bar='none',\n",
    "            seed=42\n",
    "        )\n",
    "        \n",
    "        optimizer_config = OptimizerConfig(\n",
    "            optimizer='Adam',\n",
    "            lr_scheduler='CosineAnnealingWarmRestarts',\n",
    "            lr_scheduler_params={\n",
    "                'T_0': 10,\n",
    "                'T_mult': 1,\n",
    "                'eta_min': 0.00001,\n",
    "            },\n",
    "            lr_scheduler_monitor_metric='valid_loss'\n",
    "        )\n",
    "\n",
    "        head_config = LinearHeadConfig(\n",
    "            layers='',\n",
    "            activation='ReLU',\n",
    "            dropout=0.1,\n",
    "            use_batch_norm=False,\n",
    "            initialization='xavier',\n",
    "        ).__dict__\n",
    "\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            sweep_df, best_model = model_sweep(\n",
    "                task=\"classification\",\n",
    "                train=df_def_trn_val,\n",
    "                test=df_def_tst,\n",
    "                data_config=data_config,\n",
    "                optimizer_config=optimizer_config,\n",
    "                trainer_config=trainer_config,\n",
    "                model_list=\"standard\",\n",
    "                common_model_args=dict(head=\"LinearHead\", head_config=head_config),\n",
    "                metrics=[\n",
    "                    'accuracy',\n",
    "                    'f1_score',\n",
    "                    'precision',\n",
    "                    'recall',\n",
    "                    'specificity',\n",
    "                    'cohen_kappa',\n",
    "                    'auroc'\n",
    "                ],\n",
    "                metrics_prob_input=[True, True, True, True, True, True, True],\n",
    "                metrics_params=[\n",
    "                    {'task': 'multiclass', 'num_classes': 2, 'average': 'weighted'},\n",
    "                    {'task': 'multiclass', 'num_classes': 2, 'average': 'weighted'},\n",
    "                    {'task': 'multiclass', 'num_classes': 2, 'average': 'weighted'},\n",
    "                    {'task': 'multiclass', 'num_classes': 2, 'average': 'weighted'},\n",
    "                    {'task': 'multiclass', 'num_classes': 2, 'average': 'weighted'},\n",
    "                    {'task': 'multiclass', 'num_classes': 2},\n",
    "                    {'task': 'multiclass', 'num_classes': 2, 'average': 'weighted'},\n",
    "                ],\n",
    "                rank_metric=(\"accuracy\", \"higher_is_better\"),\n",
    "                progress_bar=False,\n",
    "                verbose=False,\n",
    "                suppress_lightning_logger=True,\n",
    "            )\n",
    "        ckpts = glob(f\"{path_curr}/detector/*\")\n",
    "        for ckpt in ckpts:\n",
    "            os.remove(ckpt)\n",
    "        # best_model.save_model(f\"{path_curr}/detector\")\n",
    "        df_def_acc.at[eps, 'Model'] = best_model.config['_model_name']\n",
    "        \n",
    "        for tst_eps in epsilons:\n",
    "            if tst_eps != eps:\n",
    "                path_tst = f\"{path_save}/Evasion/{atk}/eps_{tst_eps:0.4f}\"\n",
    "                df_adv_tst = pd.read_excel(f\"{path_tst}/df.xlsx\", index_col='sample_id')\n",
    "                df_adv_tst = df_adv_tst[feats]\n",
    "                df_adv_tst['Class'] = 'Attack'\n",
    "                df_def_tst_eps = pd.concat([df_ori, df_adv_tst])\n",
    "                metrics = best_model.evaluate(test=df_def_tst_eps, verbose=False)[0]\n",
    "                df_def_acc.at[eps, tst_eps] = metrics['test_accuracy']\n",
    "    df_def_acc.to_excel(f\"{path_save}/Evasion/{atk}/detectors_accuracy.xlsx\")            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot detectors accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for atk in colors_atks:\n",
    "    df_def_acc = pd.read_excel(f\"{path_save}/Evasion/{atk}/detectors_accuracy.xlsx\", index_col=0)\n",
    "    df_def_acc['Eps'] = [f\"{x:.2f}\" for x in df_def_acc.index.values]\n",
    "    df_def_acc['index'] = df_def_acc['Model'] + '\\n' + df_def_acc['Eps']\n",
    "    df_def_acc.set_index('index', inplace=True)\n",
    "    df_def_acc.drop(['Model', 'Eps'], axis=1, inplace=True)\n",
    "    df_def_acc.rename(columns={x: f\"{x:.2f}\" for x in df_def_acc.columns}, inplace=True)\n",
    "    \n",
    "    df_fig = df_def_acc.astype(float)\n",
    "    sns.set_theme(style='ticks', font_scale=1.0)\n",
    "    fig, ax = plt.subplots(figsize=(13, 12))\n",
    "    heatmap = sns.heatmap(\n",
    "        df_fig,\n",
    "        annot=True,\n",
    "        fmt=\".2f\",\n",
    "        cmap='hot',\n",
    "        linewidth=0.1,\n",
    "        linecolor='black',\n",
    "        cbar_kws={\n",
    "            'orientation': 'horizontal',\n",
    "            'location': 'top',\n",
    "            'pad': 0.025,\n",
    "            'aspect': 30\n",
    "        },\n",
    "        annot_kws={\"size\": 12},\n",
    "        ax=ax\n",
    "    )\n",
    "    ax.set_xlabel('Test Attack Strength')\n",
    "    ax.set_ylabel('Training Model and Data')\n",
    "    heatmap_pos = heatmap.get_position()\n",
    "    ax.figure.axes[-1].set_title(\"Accuracy\")\n",
    "    ax.figure.axes[-1].tick_params()\n",
    "    for spine in ax.figure.axes[-1].spines.values():\n",
    "        spine.set_linewidth(1)\n",
    "    plt.savefig(f\"{path_save}/Evasion/{atk}/detectors_accuracy.png\", bbox_inches='tight', dpi=200)\n",
    "    plt.savefig(f\"{path_save}/Evasion/{atk}/detectors_accuracy.pdf\", bbox_inches='tight')\n",
    "    plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
