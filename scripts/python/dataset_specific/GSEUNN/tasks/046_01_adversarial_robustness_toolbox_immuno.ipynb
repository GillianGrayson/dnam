{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src.utils.outliers.iqr import add_iqr_outs_to_df, plot_iqr_outs, plot_iqr_outs_regression_error\n",
    "from src.utils.outliers.pyod import add_pyod_outs_to_df, plot_pyod_outs, plot_pyod_outs_regression_error\n",
    "from scripts.python.dataset_specific.GSEUNN.tasks.routines_046 import plot_regression_error_distributions\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy import stats\n",
    "import plotly.express as px\n",
    "from scripts.python.routines.plot.scatter import add_scatter_trace\n",
    "import plotly.graph_objects as go\n",
    "from scripts.python.routines.plot.save import save_figure\n",
    "from scripts.python.routines.plot.layout import add_layout, get_axis\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import plotly.io as pio\n",
    "import importlib\n",
    "pio.kaleido.scope.mathjax = None\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "from scipy.interpolate import interp1d\n",
    "from src.utils.verbose import NoStdStreams\n",
    "init_notebook_mode(connected=False)\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from omegaconf import OmegaConf\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "import pathlib\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.decomposition import MiniBatchDictionaryLearning, FastICA\n",
    "from sklearn.random_projection import GaussianRandomProjection, SparseRandomProjection\n",
    "from sklearn.manifold import MDS, Isomap\n",
    "from openTSNE import TSNE\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from scipy import stats\n",
    "import patchworklib as pw\n",
    "import os\n",
    "import functools\n",
    "from scipy.stats import iqr\n",
    "from statannotations.Annotator import Annotator\n",
    "from scipy.stats import mannwhitneyu\n",
    "import shap\n",
    "from slugify import slugify\n",
    "from src.models.tabular.widedeep.ft_transformer import WDFTTransformerModel\n",
    "from src.models.tabular.widedeep.tab_net import WDTabNetModel\n",
    "from art.estimators.regression.pytorch import PyTorchRegressor\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "from art.estimators.regression.blackbox import BlackBoxRegressor\n",
    "from art.attacks.evasion import ProjectedGradientDescentNumpy, FastGradientMethod, BasicIterativeMethod, MomentumIterativeMethod\n",
    "from art.attacks.evasion import ZooAttack, CarliniL2Method, ElasticNet, NewtonFool\n",
    "import torch\n",
    "from src.tasks.metrics import get_cls_pred_metrics, get_cls_prob_metrics, get_reg_metrics\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "from sdv.metadata import SingleTableMetadata\n",
    "from sdv.lite import SingleTablePreset\n",
    "from sdv.single_table import GaussianCopulaSynthesizer, CTGANSynthesizer, TVAESynthesizer, CopulaGANSynthesizer\n",
    "from sdv.evaluation.single_table import evaluate_quality\n",
    "from sdv.evaluation.single_table import get_column_plot\n",
    "from sdv.evaluation.single_table import get_column_pair_plot\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scripts.python.routines.mvals import expit2\n",
    "\n",
    "import missingno as msno\n",
    "\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "from pyod.models.ecod import ECOD\n",
    "from pyod.models.abod import ABOD\n",
    "from pyod.models.copod import COPOD\n",
    "from pyod.models.sos import SOS\n",
    "from pyod.models.kde import KDE\n",
    "from pyod.models.sampling import Sampling\n",
    "from pyod.models.gmm import GMM\n",
    "\n",
    "from pyod.models.kpca import KPCA\n",
    "from pyod.models.mcd import MCD\n",
    "from pyod.models.ocsvm import OCSVM\n",
    "from pyod.models.lmdd import LMDD\n",
    "\n",
    "from pyod.models.lof import LOF\n",
    "from pyod.models.cof import COF\n",
    "from pyod.models.cblof import CBLOF\n",
    "from pyod.models.hbos import HBOS\n",
    "from pyod.models.knn import KNN\n",
    "from pyod.models.sod import SOD\n",
    "\n",
    "from pyod.models.iforest import IForest\n",
    "from pyod.models.inne import INNE\n",
    "from pyod.models.loda import LODA\n",
    "from pyod.models.suod import SUOD\n",
    "\n",
    "from pyod.models.auto_encoder_torch import AutoEncoder\n",
    "from pyod.models.vae import VAE\n",
    "from pyod.models.deep_svdd import DeepSVDD\n",
    "\n",
    "from pyod.models.lunar import LUNAR\n",
    "\n",
    "from torchmetrics import BootStrapper\n",
    "\n",
    "\n",
    "def conjunction(conditions):\n",
    "    return functools.reduce(np.logical_and, conditions)\n",
    "\n",
    "\n",
    "def disjunction(conditions):\n",
    "    return functools.reduce(np.logical_or, conditions)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Adversarial examples for immunology data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.1. Original data, models and functions\n",
    "### Load data and model, define PyTorchRegressor, setup colors for different data "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "path = \"D:/YandexDisk/Work/pydnameth/datasets/GPL21145/GSEUNN\"\n",
    "path_model = f\"{path}/data/immuno/models/SImAge\"\n",
    "path_save = f\"{path}/special/046_adversarial_robustness_toolbox/immunology\"\n",
    "pathlib.Path(f\"{path_save}\").mkdir(parents=True, exist_ok=True)\n",
    "df = pd.read_excel(f\"{path}/data/immuno/models/SImAge/data.xlsx\", index_col='sample_id')\n",
    "feats = pd.read_excel(f\"{path}/data/immuno/models/SImAge/feats_con_top10.xlsx\", index_col=0).index.values\n",
    "ids_feat = list(range(len(feats)))\n",
    "col_trgt = 'Age'\n",
    "col_pred = 'SImAge'\n",
    "\n",
    "df_preds = pd.read_excel(f\"{path}/data/immuno/models/SImAge/results/predictions.xlsx\", index_col=0)\n",
    "ids_trn = df_preds.index[df_preds['fold_0002'] == 'trn'].values\n",
    "ids_val = df_preds.index[df_preds['fold_0002'] == 'val'].values\n",
    "ids_tst = df_preds.index[df_preds['fold_0002'] == 'tst_ctrl_central'].values\n",
    "ids_all = df_preds.index[df_preds['fold_0002'].isin(['trn', 'val', 'tst_ctrl_central'])].values\n",
    "ids_trn_val = df_preds.index[df_preds['fold_0002'].isin(['trn', 'val'])].values\n",
    "ids_dict = {\n",
    "    'all': ids_all,\n",
    "    'trn_val': ids_trn_val,\n",
    "    'tst': ids_tst\n",
    "}\n",
    "\n",
    "df = df.loc[ids_all, :]\n",
    "df[\"SImAge Error\"] = df[\"SImAge\"] - df[\"Age\"]\n",
    "df[\"abs(SImAge Error)\"] = df[\"SImAge Error\"].abs()\n",
    "df['Data'] = 'Real'\n",
    "df['Eps'] = 'Origin'\n",
    "\n",
    "model = WDFTTransformerModel.load_from_checkpoint(checkpoint_path=f\"{path}/data/immuno/models/SImAge/best_fold_0002.ckpt\")\n",
    "model.eval()\n",
    "model.freeze()\n",
    "\n",
    "def predict_func_regression(X):\n",
    "    model.produce_probabilities = True\n",
    "    batch = {\n",
    "        'all': torch.from_numpy(np.float32(X[:, ids_feat])),\n",
    "        'continuous': torch.from_numpy(np.float32(X[:, ids_feat])),\n",
    "        'categorical': torch.from_numpy(np.int32(X[:, []])),\n",
    "    }\n",
    "    tmp = model(batch)\n",
    "    return tmp.cpu().detach().numpy()\n",
    "\n",
    "art_regressor = PyTorchRegressor(\n",
    "    model=model,\n",
    "    loss=model.loss_fn,\n",
    "    input_shape=[len(feats)],\n",
    "    optimizer=torch.optim.Adam(\n",
    "        params=model.parameters(),\n",
    "        lr=model.hparams.optimizer_lr,\n",
    "        weight_decay=model.hparams.optimizer_weight_decay\n",
    "    ),\n",
    "    use_amp=False,\n",
    "    opt_level=\"O1\",\n",
    "    loss_scale=\"dynamic\",\n",
    "    channels_first=True,\n",
    "    clip_values=None,\n",
    "    preprocessing_defences=None,\n",
    "    postprocessing_defences=None,\n",
    "    preprocessing=(0.0, 1.0),\n",
    "    device_type=\"cpu\",\n",
    ")\n",
    "\n",
    "colors_augs = {\n",
    "    'FAST_ML': px.colors.qualitative.Light24[0],\n",
    "    'GaussianCopula': px.colors.qualitative.Light24[1],\n",
    "    'CTGANSynthesizer': px.colors.qualitative.Light24[2],\n",
    "    'TVAESynthesizer': px.colors.qualitative.Light24[3],\n",
    "    'CopulaGANSynthesizer': px.colors.qualitative.Light24[4],\n",
    "}\n",
    "colors_atks = {\n",
    "    \"MomentumIterative\": px.colors.qualitative.D3[0],\n",
    "    \"BasicIterative\": px.colors.qualitative.D3[1],\n",
    "    \"ProjectedGradientDescent\": px.colors.qualitative.D3[2],\n",
    "    \"FastGradient\": px.colors.qualitative.D3[3],\n",
    "}\n",
    "\n",
    "dim_red_labels = {\n",
    "    'PCA': ['PC 1', 'PC 2'],\n",
    "    'SVD': ['SVD 1', 'SVD 2'],\n",
    "    't-SNE': ['t-SNE 1', 't-SNE 2'],\n",
    "    'GRP': ['GRP 1', 'GRP 2'],\n",
    "    'SRP': ['SRP 1', 'SRP 2'],\n",
    "    'IsoMap': ['IsoMap 1', 'IsoMap 2'],\n",
    "    'MBDL': ['MBDL 1', 'MBDL 2'],\n",
    "}\n",
    "\n",
    "# Create Scalers trained on trn_val samples ===================================\n",
    "scalers = {}\n",
    "feats_scaled = []\n",
    "for f in feats:\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(df.loc[:, f].values.reshape(-1, 1))\n",
    "    scalers[f] = scaler\n",
    "    feats_scaled.append(f\"{f}_scaled\")\n",
    "    df[f\"{f}_scaled\"] = scalers[f].transform(df.loc[:, f].values.reshape(-1, 1))\n",
    "with open(f\"{path_save}/scalers.pkl\", 'wb') as handle:\n",
    "    pickle.dump(scalers, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "thld_outs_iqr = 1/3\n",
    "thld_outs_pyod = 1/3"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create PyOD models, trained on trn_val samples"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "contamination = 0.1\n",
    "\n",
    "pyod_methods = {\n",
    "    'ECOD': ECOD(contamination=contamination),\n",
    "    'LUNAR': LUNAR(),\n",
    "    'DeepSVDD': DeepSVDD(contamination=contamination, verbose=0),\n",
    "    'VAE': VAE(encoder_neurons=[32, 16, 8], decoder_neurons=[8, 16, 32], contamination=contamination),\n",
    "    'LODA': LODA(contamination=contamination),\n",
    "    'INNE': INNE(contamination=contamination),\n",
    "    'IForest': IForest(contamination=contamination),\n",
    "    'SOD': SOD(contamination=contamination),\n",
    "    'KNN': KNN(contamination=contamination),\n",
    "    'CBLOF': CBLOF(contamination=contamination),\n",
    "    'COF': COF(contamination=contamination),\n",
    "    'LOF': LOF(contamination=contamination),\n",
    "    'LMDD': LMDD(contamination=contamination),\n",
    "    'MCD': MCD(contamination=contamination),\n",
    "    'GMM': GMM(contamination=contamination),\n",
    "    'Sampling': Sampling(contamination=contamination),\n",
    "    'SOS': SOS(contamination=contamination),\n",
    "    'COPOD': COPOD(contamination=contamination),\n",
    "}\n",
    "\n",
    "for method_name, method in (pbar := tqdm(pyod_methods.items())):\n",
    "    pbar.set_description(f\"Processing {method_name}\")\n",
    "    \n",
    "    method.fit(df.loc[ids_trn_val, feats_scaled].values)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create dimensionality reduction models, trained on trn_val samples"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_dim_red = df.loc[ids_trn_val, feats].values\n",
    "dim_red_models = {\n",
    "    'PCA': PCA(n_components=2, whiten=False).fit(X_dim_red),\n",
    "    'SVD': TruncatedSVD(n_components=2, algorithm='randomized', n_iter=5).fit(X_dim_red),\n",
    "    't-SNE': TSNE(n_components=2).fit(X_dim_red),\n",
    "    'GRP': GaussianRandomProjection(n_components=2, eps=0.5).fit(X_dim_red),\n",
    "    'SRP': SparseRandomProjection(n_components=2, density='auto', eps=0.5, dense_output=False).fit(X_dim_red),\n",
    "    'IsoMap': Isomap(n_components=2, n_neighbors=5).fit(X_dim_red),\n",
    "    'MBDL': MiniBatchDictionaryLearning(n_components=2, batch_size=100, alpha=1, n_iter=25).fit(X_dim_red),\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Apply and save or load processed data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Load data with dim_red columns ==============================================\n",
    "df = pd.read_excel(f\"{path_save}/df_origin.xlsx\", index_col=0)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Add to df_origin.xlsx IQR outliers columns ==================================\n",
    "add_iqr_outs_to_df(df, df.loc[ids_trn_val, :], feats)\n",
    "df.to_excel(f\"{path_save}/df_origin.xlsx\", index_label='sample_id')"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Add to df_origin.xlsx PyOD outliers columns =================================\n",
    "add_pyod_outs_to_df(df, pyod_methods, feats_scaled)\n",
    "df.to_excel(f\"{path_save}/df_origin.xlsx\", index_label='sample_id')"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Add to df_origin.xlsx dimensionality reduction columns ======================\n",
    "for m, drm in dim_red_models.items():\n",
    "    dim_red_res = drm.transform(df.loc[:, feats].values)\n",
    "    df.loc[:, dim_red_labels[m][0]] = dim_red_res[:, 0]\n",
    "    df.loc[:, dim_red_labels[m][1]] = dim_red_res[:, 1]\n",
    "df.to_excel(f\"{path_save}/df_origin.xlsx\", index_label='sample_id')"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Outliers analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# IQR plots\n",
    "pathlib.Path(f\"{path_save}/Origin/outliers_iqr\").mkdir(parents=True, exist_ok=True)\n",
    "plot_iqr_outs(df, feats, 'grey', 'Origin', f\"{path_save}/Origin/outliers_iqr\")\n",
    "plot_iqr_outs_regression_error(df, feats, 'Origin', f\"{path_save}/Origin/outliers_iqr\", thld_outs_iqr, 'Age', 'SImAge', 'SImAge Error')\n",
    "\n",
    "# PyOD plots\n",
    "pathlib.Path(f\"{path_save}/Origin/outliers_pyod\").mkdir(parents=True, exist_ok=True)\n",
    "plot_pyod_outs(df, pyod_methods, 'grey', 'Origin', f\"{path_save}/Origin/outliers_pyod\")\n",
    "plot_pyod_outs_regression_error(df, pyod_methods, 'Origin', f\"{path_save}/Origin/outliers_pyod\", thld_outs_pyod, 'Age', 'SImAge', 'SImAge Error')"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Regression error analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pathlib.Path(f\"{path_save}/Origin/errors\").mkdir(parents=True, exist_ok=True)\n",
    "plot_regression_error_distributions(df, feats, 'grey', 'Origin', f\"{path_save}/Origin/errors\", \"abs(SImAge Error)\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Confidence"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "torch.manual_seed(42)\n",
    "quantiles = torch.tensor([0.05, 0.95])\n",
    "\n",
    "pathlib.Path(f\"{path_save}/Origin/confidence\").mkdir(parents=True, exist_ok=True)\n",
    "metrics = get_reg_metrics()\n",
    "df_metrics = pd.DataFrame(index=list(metrics.keys()), columns=['mean', 'std', 'q0.05', 'q0.95'])\n",
    "y_real = torch.from_numpy(np.float32(df['Age'].values))\n",
    "y_pred = torch.from_numpy(np.float32(df['SImAge'].values))\n",
    "for metric_name, metric_pair in metrics.items():\n",
    "    metric = metric_pair[0]\n",
    "    bootstrap = BootStrapper(\n",
    "        metric,\n",
    "        num_bootstraps=200,\n",
    "        sampling_strategy=\"multinomial\",\n",
    "        quantile=quantiles\n",
    "    )\n",
    "    bootstrap.update(y_pred, y_real)\n",
    "    bootstrap_output = bootstrap.compute()\n",
    "    df_metrics.at[metric_name, 'mean'] = bootstrap_output['mean'].detach().cpu().numpy()\n",
    "    df_metrics.at[metric_name, 'std'] = bootstrap_output['std'].detach().cpu().numpy()\n",
    "    df_metrics.at[metric_name, 'q0.05'] = bootstrap_output['quantile'].detach().cpu().numpy()[0]\n",
    "    df_metrics.at[metric_name, 'q0.95'] = bootstrap_output['quantile'].detach().cpu().numpy()[1]\n",
    "df_metrics.to_excel(f\"{path_save}/Origin/confidence/metrics.xlsx\", index_label='Metrics')"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2. Augmented data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Naive augmented data: the same distribution of original feats"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "path_curr = f\"{path_save}/Augmentation/Naive\"\n",
    "pathlib.Path(f\"{path_curr}\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "n_bins = 100\n",
    "n_smps = 10000\n",
    "\n",
    "df_aug_naive = pd.DataFrame(columns=feats)\n",
    "for f in feats:\n",
    "    f_vals = df.loc[ids_trn_val, f].values\n",
    "    counts, bin_edges = np.histogram(df.loc[ids_trn_val, f].values, bins=n_bins)\n",
    "    df_aug_naive[f] = np.random.choice(bin_edges[:-1], size=n_smps, p=counts/len(f_vals))\n",
    "df_aug_naive[\"SImAge\"] = model(torch.from_numpy(np.float32(df_aug_naive.loc[:, feats].values))).cpu().detach().numpy().ravel()\n",
    "for m, drm in dim_red_models.items():\n",
    "    dim_red_res = drm.transform(df_aug_naive.loc[:, feats].values)\n",
    "    df_aug_naive.loc[:, dim_red_labels[m][0]] = dim_red_res[:, 0]\n",
    "    df_aug_naive.loc[:, dim_red_labels[m][1]] = dim_red_res[:, 1]\n",
    "df_aug_naive.to_excel(f\"{path_curr}/df.xlsx\", index_label='sample_id')"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Augmented data with Synthetic Data Vault (SDV)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "n_smps = 10000\n",
    "\n",
    "df_aug_sdv_input = df.loc[:, np.concatenate((feats, ['Age']))]\n",
    "\n",
    "metadata = SingleTableMetadata()\n",
    "metadata.detect_from_dataframe(data=df_aug_sdv_input)\n",
    "\n",
    "synthesizers = {\n",
    "    'FAST_ML': SingleTablePreset(metadata, name='FAST_ML'),\n",
    "    'GaussianCopula': GaussianCopulaSynthesizer(metadata),\n",
    "    'CTGANSynthesizer': CTGANSynthesizer(metadata),\n",
    "    'TVAESynthesizer': TVAESynthesizer(metadata),\n",
    "    'CopulaGANSynthesizer': CopulaGANSynthesizer(metadata),\n",
    "}\n",
    "for s_name, s in (pbar := tqdm(synthesizers.items())):\n",
    "    pbar.set_description(f\"Processing {s_name}\")\n",
    "    path_curr = f\"{path_save}/Augmentation/{s_name}\"\n",
    "    pathlib.Path(f\"{path_curr}\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    s.fit(\n",
    "        data=df_aug_sdv_input\n",
    "    )\n",
    "    s.save(\n",
    "        filepath=f\"{path_curr}/synthesizer.pkl\"\n",
    "    )\n",
    "    df_aug_sdv = s.sample(\n",
    "        num_rows=n_smps\n",
    "    )\n",
    "    quality_report = evaluate_quality(\n",
    "        df_aug_sdv_input,\n",
    "        df_aug_sdv,\n",
    "        metadata\n",
    "    )\n",
    "    \n",
    "    q_rep_prop = quality_report.get_properties()\n",
    "    q_rep_prop.set_index('Property', inplace=True)\n",
    "    \n",
    "    df_col_shapes = quality_report.get_details(property_name='Column Shapes')\n",
    "    df_col_shapes.sort_values([\"Score\"], ascending=[False], inplace=True)\n",
    "    df_col_shapes.to_excel(f\"{path_curr}/ColumnShapes.xlsx\", index=False)\n",
    "    fig = plt.figure(figsize=(3, 5))\n",
    "    sns.set_theme(style='whitegrid')\n",
    "    barplot = sns.barplot(\n",
    "        data=df_col_shapes,\n",
    "        x=\"Score\",\n",
    "        y=\"Column\",\n",
    "        edgecolor='black',\n",
    "        color=colors_augs[s_name],\n",
    "        dodge=False,\n",
    "        orient='h'\n",
    "    )\n",
    "    barplot.set_title(f\"{s_name} Average Score: {q_rep_prop.at['Column Shapes', 'Score']:0.2f}\")\n",
    "    barplot.set_xlabel(f\"KSComplement\")\n",
    "    barplot.set_ylabel(f\"Features\")\n",
    "    plt.savefig(f\"{path_curr}/ColumnShapes.png\", bbox_inches='tight', dpi=200)\n",
    "    plt.savefig(f\"{path_curr}/ColumnShapes.pdf\", bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    df_col_pair_trends = quality_report.get_details(property_name='Column Pair Trends')\n",
    "    df_col_pair_trends.to_excel(f\"{path_curr}/ColumnPairTrends.xlsx\", index=False)\n",
    "    feats_plot = np.concatenate((feats, ['Age']))\n",
    "    df_corr_mtx = pd.DataFrame(data=np.zeros(shape=(len(feats_plot), len(feats_plot))), index=feats_plot, columns=feats_plot)\n",
    "    df_pair_mtx = pd.DataFrame(index=feats_plot, columns=feats_plot)\n",
    "    for index, row in df_col_pair_trends.iterrows():\n",
    "        df_corr_mtx.at[row['Column 1'], row['Column 2']] = row['Real Correlation']\n",
    "        df_corr_mtx.at[row['Column 2'], row['Column 1']] = row['Synthetic Correlation']\n",
    "        df_pair_mtx.at[row['Column 1'], row['Column 2']] = row['Score']\n",
    "        df_pair_mtx.at[row['Column 2'], row['Column 1']] = row['Score']\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    df_pair_mtx.fillna(value=np.nan, inplace=True)\n",
    "    sns.set_theme(style='whitegrid')\n",
    "    heatmap = sns.heatmap(\n",
    "        data=df_pair_mtx,\n",
    "        cmap='plasma',\n",
    "        annot=True,\n",
    "        fmt=\"0.2f\",\n",
    "        cbar_kws={'label': \"Correlation Similarity\"},\n",
    "        mask=df_pair_mtx.isnull()\n",
    "    )\n",
    "    heatmap.set(xlabel=\"\", ylabel=\"\")\n",
    "    heatmap.tick_params(axis='x', rotation=90)\n",
    "    heatmap.set_title(f\"{s_name} Average Score: {q_rep_prop.at['Column Pair Trends', 'Score']:0.2f}\")\n",
    "    plt.savefig(f\"{path_curr}/ColumnPairTrends.png\", bbox_inches='tight', dpi=200)\n",
    "    plt.savefig(f\"{path_curr}/ColumnPairTrends.pdf\", bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    sns.set_theme(style='whitegrid')\n",
    "    mtx_to_plot = df_corr_mtx.to_numpy()\n",
    "    mtx_triu = np.triu(mtx_to_plot, +1)\n",
    "    mtx_triu_mask = np.ma.masked_array(mtx_triu, mtx_triu==0)\n",
    "    cmap_triu = plt.get_cmap(\"seismic\").copy()\n",
    "    mtx_tril = np.tril(mtx_to_plot, -1)\n",
    "    mtx_tril_mask = np.ma.masked_array(mtx_tril, mtx_tril==0)\n",
    "    cmap_tril = plt.get_cmap(\"PRGn\").copy()\n",
    "    fig, ax = plt.subplots()\n",
    "    im_triu = ax.imshow(mtx_triu_mask, cmap=cmap_triu, vmin=-1, vmax=1)\n",
    "    cbar_triu = ax.figure.colorbar(im_triu, ax=ax, location='right', shrink=0.7, pad=0.1)\n",
    "    cbar_triu.ax.tick_params(labelsize=10)\n",
    "    cbar_triu.set_label(\"Real Correlation\", horizontalalignment='center', fontsize=12)\n",
    "    im_tril = ax.imshow(mtx_tril_mask, cmap=cmap_tril, vmin=-1, vmax=1)\n",
    "    cbar_tril = ax.figure.colorbar(im_tril, ax=ax, location='right', shrink=0.7, pad=0.1)\n",
    "    cbar_tril.ax.tick_params(labelsize=10)\n",
    "    cbar_tril.set_label(\"Synthetic Correlation\", horizontalalignment='center', fontsize=12)\n",
    "    ax.grid(None)\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.set_xticks(np.arange(df_corr_mtx.shape[1]))\n",
    "    ax.set_yticks(np.arange(df_corr_mtx.shape[0]))\n",
    "    ax.set_xticklabels(df_corr_mtx.columns.values)\n",
    "    ax.set_yticklabels(df_corr_mtx.index.values)\n",
    "    plt.setp(ax.get_xticklabels(), rotation=90)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=10)\n",
    "    ax.tick_params(axis='both', which='minor', labelsize=10)\n",
    "    for i in range(df_corr_mtx.shape[0]):\n",
    "        for j in range(df_corr_mtx.shape[1]):\n",
    "            color = \"black\"\n",
    "            if i != j:\n",
    "                color = \"black\"\n",
    "                if np.abs(mtx_tril[i, j]) > 0.5:\n",
    "                    color = 'white'\n",
    "                text = ax.text(j, i, f\"{mtx_to_plot[i, j]:0.2f}\", ha=\"center\", va=\"center\", color=color, fontsize=7)\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(f\"{path_curr}/Correlations.png\", bbox_inches='tight', dpi=200)\n",
    "    plt.savefig(f\"{path_curr}/Correlations.pdf\", bbox_inches='tight')\n",
    "    plt.clf()\n",
    "    \n",
    "    df_aug_sdv[\"SImAge\"] = model(torch.from_numpy(np.float32(df_aug_sdv.loc[:, feats].values))).cpu().detach().numpy().ravel()\n",
    "    df_aug_sdv[\"SImAge Error\"] = df_aug_sdv[\"SImAge\"] - df_aug_sdv[\"Age\"]\n",
    "    df_aug_sdv[\"abs(SImAge Error)\"] = df_aug_sdv[\"SImAge Error\"].abs()\n",
    "    for m, drm in dim_red_models.items():\n",
    "        dim_red_res = drm.transform(df_aug_sdv.loc[:, feats].values)\n",
    "        df_aug_sdv.loc[:, dim_red_labels[m][0]] = dim_red_res[:, 0]\n",
    "        df_aug_sdv.loc[:, dim_red_labels[m][1]] = dim_red_res[:, 1]\n",
    "    \n",
    "    for f in feats:\n",
    "        df_aug_sdv[f\"{f}_scaled\"] = scalers[f].transform(df_aug_sdv.loc[:, f].values.reshape(-1, 1))\n",
    "    \n",
    "    add_iqr_outs_to_df(df_aug_sdv, df.loc[ids_trn_val, :], feats)\n",
    "    add_pyod_outs_to_df(df_aug_sdv, pyod_methods, feats_scaled)\n",
    "    \n",
    "    df_aug_sdv.to_excel(f\"{path_curr}/df.xlsx\", index_label='sample_id')"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot in reduced dimension"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for s_name in (pbar := tqdm(colors_augs)):\n",
    "    pbar.set_description(f\"Processing {s_name}\")\n",
    "    \n",
    "    path_curr = f\"{path_save}/Augmentation/{s_name}\"\n",
    "    df_aug_sdv = pd.read_excel(f\"{path_curr}/df.xlsx\", index_col='sample_id')\n",
    "    df_ori_aug = pd.concat([df, df_aug_sdv])\n",
    "    for m in ['t-SNE']:\n",
    "        n_bins = 100\n",
    "        x_xtd = (df_aug_sdv[dim_red_labels[m][0]].max() - df_aug_sdv[dim_red_labels[m][0]].min()) * 0.075\n",
    "        x_min = df_aug_sdv[dim_red_labels[m][0]].min() - x_xtd\n",
    "        x_max = df_aug_sdv[dim_red_labels[m][0]].max() + x_xtd\n",
    "        x_shift = (x_max - x_min) / n_bins\n",
    "        x_bin_centers = np.linspace(\n",
    "            start=x_min + 0.5 * x_shift,\n",
    "            stop=x_max - 0.5 * x_shift,\n",
    "            num=n_bins\n",
    "        )\n",
    "        y_xtd = (df_aug_sdv[dim_red_labels[m][1]].max() - df_aug_sdv[dim_red_labels[m][1]].min()) * 0.075\n",
    "        y_min = df_aug_sdv[dim_red_labels[m][1]].min() - y_xtd\n",
    "        y_max = df_aug_sdv[dim_red_labels[m][1]].max() + y_xtd\n",
    "        y_shift = (y_max - y_min) / n_bins\n",
    "        y_bin_centers = np.linspace(\n",
    "            start=y_min + 0.5 * y_shift,\n",
    "            stop=y_max - 0.5 * y_shift,\n",
    "            num=n_bins\n",
    "        )\n",
    "        df_heatmap_sum = pd.DataFrame(index=x_bin_centers, columns=y_bin_centers, data=np.zeros((n_bins, n_bins)))\n",
    "        df_heatmap_cnt = pd.DataFrame(index=x_bin_centers, columns=y_bin_centers, data=np.zeros((n_bins, n_bins)))\n",
    "        xs = df_aug_sdv.loc[:, dim_red_labels[m][0]].values\n",
    "        xs_ids = np.floor((xs - x_min) / (x_shift + 1e-10)).astype(int)\n",
    "        ys = df_aug_sdv.loc[:, dim_red_labels[m][1]].values\n",
    "        ys_ids = np.floor((ys - y_min) / (y_shift + 1e-10)).astype(int)\n",
    "        zs = df_aug_sdv.loc[:, \"SImAge Error\"].values\n",
    "        for d_id in range(len(xs_ids)):\n",
    "            df_heatmap_sum.iat[xs_ids[d_id], ys_ids[d_id]] += zs[d_id]\n",
    "            df_heatmap_cnt.iat[xs_ids[d_id], ys_ids[d_id]] += 1\n",
    "        df_heatmap = pd.DataFrame(data=df_heatmap_sum.values / df_heatmap_cnt.values, columns=df_heatmap_sum.columns, index=df_heatmap_sum.index)\n",
    "        df_heatmap.to_excel(f\"{path_curr}/{m}_heatmap.xlsx\")\n",
    "        \n",
    "        norm = plt.Normalize(df_ori_aug[\"SImAge Error\"].min(), df_ori_aug[\"SImAge Error\"].max())\n",
    "        sm = plt.cm.ScalarMappable(cmap=\"spring\", norm=norm)\n",
    "        sm.set_array([])\n",
    "        fig, ax = plt.subplots(figsize=(5, 4))\n",
    "        sns.set_theme(style='whitegrid')\n",
    "\n",
    "        ax.imshow(\n",
    "            X=df_heatmap.transpose().iloc[::-1].values,\n",
    "            extent=[x_min, x_max, y_min, y_max],\n",
    "            vmin=df_ori_aug[\"SImAge Error\"].min(),\n",
    "            vmax=df_ori_aug[\"SImAge Error\"].max(),\n",
    "            aspect=x_shift/y_shift,\n",
    "            cmap=\"spring\",\n",
    "            alpha=1.0\n",
    "        )\n",
    "        \n",
    "        scatter_colors = {sample: colors.rgb2hex(sm.to_rgba(row[\"SImAge Error\"])) for sample, row in df.iterrows()}\n",
    "        scatter = sns.scatterplot(\n",
    "            data=df,\n",
    "            x=dim_red_labels[m][0],\n",
    "            y=dim_red_labels[m][1],\n",
    "            palette=scatter_colors,\n",
    "            hue=df.index,\n",
    "            linewidth=1,\n",
    "            alpha=0.85,\n",
    "            edgecolor=\"k\",\n",
    "            marker='o',\n",
    "            s=30,\n",
    "            ax=ax\n",
    "        )\n",
    "        scatter.get_legend().remove()\n",
    "        fig.colorbar(sm, label=\"SImAge Error\")\n",
    "        plt.title(f'{s_name}', y=1.2, fontsize = 14)\n",
    "        \n",
    "        legend_handles = [\n",
    "            mlines.Line2D([], [], marker='o', linestyle='None', markeredgecolor='k', markerfacecolor='lightgrey', markersize=10, label='Real'),\n",
    "            mlines.Line2D([], [], marker='s', linestyle='None', markeredgewidth=0, markerfacecolor='lightgrey', markersize=10, label='Synthetic')\n",
    "        ]\n",
    "        plt.legend(handles=legend_handles, title=\"Samples\", bbox_to_anchor=(0, 1.02, 1, 0.2), loc=\"lower left\", borderaxespad=0, mode=\"expand\", ncol=2, frameon=False)\n",
    "        \n",
    "        plt.savefig(f\"{path_curr}/{m}.png\", bbox_inches='tight', dpi=200)\n",
    "        plt.savefig(f\"{path_curr}/{m}.pdf\", bbox_inches='tight')\n",
    "        plt.close(fig)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot distributions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for s_name in (pbar := tqdm(colors_augs)):\n",
    "    pbar.set_description(f\"Processing {s_name}\")\n",
    "    \n",
    "    path_curr = f\"{path_save}/Augmentation/{s_name}\"\n",
    "    df_aug_sdv = pd.read_excel(f\"{path_curr}/df.xlsx\", index_col='sample_id')\n",
    "    df_aug_sdv['Data'] = s_name\n",
    "    df_ori_aug = pd.concat([df, df_aug_sdv])\n",
    "    \n",
    "    pw_brick_kdes = {}\n",
    "    pw_brick_scatters = {}\n",
    "    for f in feats:\n",
    "    \n",
    "        pw_brick_kdes[f] = pw.Brick(figsize=(4, 3))\n",
    "        sns.set_theme(style='whitegrid')\n",
    "        kdeplot = sns.kdeplot(\n",
    "            data=df_ori_aug,\n",
    "            x=f,\n",
    "            hue='Data',\n",
    "            palette={'Real': 'grey', s_name: colors_augs[s_name]},\n",
    "            hue_order=['Real', s_name],\n",
    "            fill=True,\n",
    "            common_norm=False,\n",
    "            ax=pw_brick_kdes[f]\n",
    "        )\n",
    "        \n",
    "        pw_brick_scatters[f] = pw.Brick(figsize=(4, 3))\n",
    "        sns.set_theme(style='whitegrid')\n",
    "        sns.histplot(\n",
    "            data=df_aug_sdv,\n",
    "            x=f,\n",
    "            y='Age',\n",
    "            bins=30,\n",
    "            discrete=(False, False),\n",
    "            log_scale=(False, False),\n",
    "            cbar=True,\n",
    "            color=colors_augs[s_name],\n",
    "            ax=pw_brick_scatters[f],\n",
    "        )\n",
    "        scatterplot = sns.scatterplot(\n",
    "            data=df,\n",
    "            x=f,\n",
    "            y='Age',\n",
    "            hue='Data',\n",
    "            palette={'Real': 'grey', s_name: colors_augs[s_name]},\n",
    "            hue_order=['Real', s_name],\n",
    "            linewidth=0.85,\n",
    "            alpha=0.85,\n",
    "            edgecolor=\"k\",\n",
    "            marker='o',\n",
    "            s=20,\n",
    "            ax=pw_brick_scatters[f]\n",
    "        )\n",
    "\n",
    "    n_cols = 3\n",
    "    n_rows = int(np.ceil(len(feats)/ n_cols))\n",
    "    pw_rows_kdes = []\n",
    "    pw_rows_scatters = []\n",
    "    for r_id in range(n_rows):\n",
    "        pw_cols_kdes = []\n",
    "        pw_cols_scatters = []\n",
    "        for c_id in range(n_cols):\n",
    "            rc_id = r_id * n_cols + c_id\n",
    "            if rc_id < len(feats):\n",
    "                f = feats[rc_id]\n",
    "                pw_cols_kdes.append(pw_brick_kdes[f])\n",
    "                pw_cols_scatters.append(pw_brick_scatters[f])\n",
    "            else:\n",
    "                empty_fig = pw.Brick(figsize=(4.67, 3))\n",
    "                empty_fig.axis('off')\n",
    "                pw_cols_kdes.append(empty_fig)\n",
    "                pw_cols_scatters.append(empty_fig)\n",
    "        pw_rows_kdes.append(pw.stack(pw_cols_kdes, operator=\"|\"))\n",
    "        pw_rows_scatters.append(pw.stack(pw_cols_scatters, operator=\"|\"))\n",
    "    pw_fig_kde = pw.stack(pw_rows_kdes, operator=\"/\")\n",
    "    pw_fig_kde.savefig(f\"{path_curr}/feats_kde.png\", bbox_inches='tight', dpi=200)\n",
    "    pw_fig_kde.savefig(f\"{path_curr}/feats_kde.pdf\", bbox_inches='tight')\n",
    "    pw_fig_scatter = pw.stack(pw_rows_scatters, operator=\"/\")\n",
    "    pw_fig_scatter.savefig(f\"{path_curr}/feats_scatter.png\", bbox_inches='tight', dpi=200)\n",
    "    pw_fig_scatter.savefig(f\"{path_curr}/feats_scatter.pdf\", bbox_inches='tight')\n",
    "    \n",
    "    fig = plt.figure(figsize=(6, 4))\n",
    "    sns.set_theme(style='whitegrid')\n",
    "    kdeplot = sns.kdeplot(\n",
    "        data=df_ori_aug,\n",
    "        x='Age',\n",
    "        hue='Data',\n",
    "        palette={'Real': 'grey', s_name: colors_augs[s_name]},\n",
    "        hue_order=['Real', s_name],\n",
    "        fill=True,\n",
    "        common_norm=False,\n",
    "    )\n",
    "    plt.savefig(f\"{path_curr}/Age_kde.png\", bbox_inches='tight', dpi=200)\n",
    "    plt.savefig(f\"{path_curr}/Age_kde.pdf\", bbox_inches='tight')\n",
    "    plt.close(fig)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot Error distributions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dfs_fig = [df.loc[:, ['Data', 'SImAge Error']].copy()]\n",
    "df_stat = pd.DataFrame(index=list(colors_augs.keys()), columns=['mw_pval'])\n",
    "mae_dict = {'Real': mean_absolute_error(df.loc[:, 'Age'].values, df.loc[:, 'SImAge'].values)}\n",
    "for s_name in (pbar := tqdm(colors_augs)):\n",
    "    pbar.set_description(f\"Processing {s_name}\")\n",
    "    \n",
    "    path_curr = f\"{path_save}/Augmentation/{s_name}\"\n",
    "    df_aug_sdv = pd.read_excel(f\"{path_curr}/df.xlsx\", index_col='sample_id')\n",
    "    mae_dict[s_name] = mean_absolute_error(df_aug_sdv.loc[:, 'Age'].values, df_aug_sdv.loc[:, 'SImAge'].values)\n",
    "    df_fig = df_aug_sdv.loc[:, ['SImAge Error']].copy()\n",
    "    df_fig.set_index(df_fig.index.astype(str).values + f'_{s_name}', inplace=True)\n",
    "    df_fig['Data'] = s_name\n",
    "    dfs_fig.append(df_fig)\n",
    "    \n",
    "    _, df_stat.at[s_name, 'mw_pval'] = mannwhitneyu(df['SImAge Error'].values, df_fig['SImAge Error'].values, alternative='two-sided')\n",
    "\n",
    "_, df_stat.loc[:, \"mw_pval_fdr_bh\"], _, _ = multipletests(df_stat.loc[:, \"mw_pval\"], 0.05, method='fdr_bh')\n",
    "\n",
    "df_fig = pd.concat(dfs_fig)\n",
    "\n",
    "rename_dict = {x: f\"{x}\\nMAE={mae_dict[x]:0.2f}\" for x in mae_dict}\n",
    "colors_dict_old = {'Real': 'grey'} | colors_augs\n",
    "colors_dict_new = {f\"{x}\\nMAE={mae_dict[x]:0.2f}\": colors_dict_old[x] for x in rename_dict}\n",
    "df_fig['Data'].replace(rename_dict, inplace=True)\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "sns.set_theme(style='whitegrid')\n",
    "violin = sns.violinplot(\n",
    "    data=df_fig,\n",
    "    x='Data',\n",
    "    y='SImAge Error',\n",
    "    palette=colors_dict_new,\n",
    "    scale='width',\n",
    "    order=list(colors_dict_new.keys()),\n",
    "    saturation=0.75,\n",
    ")\n",
    "pval_formatted = [f\"{df_stat.at[x, 'mw_pval_fdr_bh']:.2e}\" for x in colors_augs]\n",
    "annotator = Annotator(\n",
    "    violin,\n",
    "    pairs=[(rename_dict['Real'], rename_dict[x]) for x in colors_augs],\n",
    "    data=df_fig,\n",
    "    x='Data',\n",
    "    y='SImAge Error',\n",
    "    order=list(colors_dict_new.keys()),\n",
    ")\n",
    "annotator.set_custom_annotations(pval_formatted)\n",
    "annotator.configure(loc='outside')\n",
    "annotator.annotate()\n",
    "plt.savefig(f\"{path_save}/Augmentation/SImAgeError.png\", bbox_inches='tight', dpi=200)\n",
    "plt.savefig(f\"{path_save}/Augmentation/SImAgeError.pdf\", bbox_inches='tight')\n",
    "plt.close(fig)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Outliers analysis for augmented samples"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for s_name in (pbar := tqdm(colors_augs)):\n",
    "    pbar.set_description(f\"Processing {s_name}\")\n",
    "\n",
    "    path_curr = f\"{path_save}/Augmentation/{s_name}\"\n",
    "    df_aug_sdv = pd.read_excel(f\"{path_curr}/df.xlsx\", index_col='sample_id')\n",
    "    \n",
    "    # IQR outliers\n",
    "    pathlib.Path(f\"{path_curr}/outliers_iqr\").mkdir(parents=True, exist_ok=True)\n",
    "    plot_iqr_outs(df_aug_sdv, feats, colors_augs[s_name], s_name, f\"{path_curr}/outliers_iqr\")\n",
    "    plot_iqr_outs_regression_error(df_aug_sdv, feats, s_name, f\"{path_curr}/outliers_iqr\", thld_outs_iqr, 'Age', 'SImAge', 'SImAge Error')\n",
    "    \n",
    "    # PyOD plots\n",
    "    pathlib.Path(f\"{path_curr}/outliers_pyod\").mkdir(parents=True, exist_ok=True)\n",
    "    plot_pyod_outs(df_aug_sdv, pyod_methods, colors_augs[s_name], s_name, f\"{path_curr}/outliers_pyod\")\n",
    "    plot_pyod_outs_regression_error(df_aug_sdv, pyod_methods, s_name, f\"{path_curr}/outliers_pyod\", thld_outs_pyod, 'Age', 'SImAge', 'SImAge Error')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Regression error analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for s_name in (pbar := tqdm(colors_augs)):\n",
    "    pbar.set_description(f\"Processing {s_name}\")\n",
    "\n",
    "    path_curr = f\"{path_save}/Augmentation/{s_name}\"\n",
    "    df_aug_sdv = pd.read_excel(f\"{path_curr}/df.xlsx\", index_col='sample_id')\n",
    "    \n",
    "    pathlib.Path(f\"{path_curr}/errors\").mkdir(parents=True, exist_ok=True)\n",
    "    plot_regression_error_distributions(df_aug_sdv, feats, colors_augs[s_name], s_name, f\"{path_curr}/errors\", \"abs(SImAge Error)\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Confidence"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "torch.manual_seed(42)\n",
    "quantiles = torch.tensor([0.05, 0.95])\n",
    "\n",
    "for s_name in (pbar := tqdm(colors_augs)):\n",
    "    pbar.set_description(f\"Processing {s_name}\")\n",
    "    \n",
    "    path_curr = f\"{path_save}/Augmentation/{s_name}\"\n",
    "    df_aug_sdv = pd.read_excel(f\"{path_curr}/df.xlsx\", index_col='sample_id')\n",
    "    \n",
    "    pathlib.Path(f\"{path_curr}/confidence\").mkdir(parents=True, exist_ok=True)\n",
    "    metrics = get_reg_metrics()\n",
    "    df_metrics = pd.DataFrame(index=list(metrics.keys()), columns=['mean', 'std', 'q0.05', 'q0.95'])\n",
    "    y_real = torch.from_numpy(np.float32(df_aug_sdv['Age'].values))\n",
    "    y_pred = torch.from_numpy(np.float32(df_aug_sdv['SImAge'].values))\n",
    "    for metric_name, metric_pair in metrics.items():\n",
    "        metric = metric_pair[0]\n",
    "        bootstrap = BootStrapper(\n",
    "            metric,\n",
    "            num_bootstraps=200,\n",
    "            sampling_strategy=\"multinomial\",\n",
    "            quantile=quantiles\n",
    "        )\n",
    "        bootstrap.update(y_pred, y_real)\n",
    "        bootstrap_output = bootstrap.compute()\n",
    "        df_metrics.at[metric_name, 'mean'] = bootstrap_output['mean'].detach().cpu().numpy()\n",
    "        df_metrics.at[metric_name, 'std'] = bootstrap_output['std'].detach().cpu().numpy()\n",
    "        df_metrics.at[metric_name, 'q0.05'] = bootstrap_output['quantile'].detach().cpu().numpy()[0]\n",
    "        df_metrics.at[metric_name, 'q0.95'] = bootstrap_output['quantile'].detach().cpu().numpy()[1]\n",
    "    df_metrics.to_excel(f\"{path_curr}/confidence/metrics.xlsx\", index_label='Metrics')"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "metrics_names = {\n",
    "    'mean_absolute_error': 'MAE',\n",
    "    'pearson_corr_coef': 'Pearson rho'\n",
    "}\n",
    "quantiles = [0.05, 0.95]\n",
    "\n",
    "df_conf = pd.DataFrame(index=['Real'] + list(colors_augs.keys()), columns=[f\"{m}_{q}\" for m in metrics_names for q in quantiles])\n",
    "\n",
    "df_metrics = pd.read_excel(f\"{path_save}/Origin/confidence/metrics.xlsx\", index_col='Metrics')\n",
    "for m in metrics_names:\n",
    "    for q in quantiles:\n",
    "        df_conf.at[\"Real\", f\"{m}_{q}\"] = df_metrics.at[m, f\"q{q}\"]\n",
    "\n",
    "for s_name in (pbar := tqdm(colors_augs)):\n",
    "    pbar.set_description(f\"Processing {s_name}\")\n",
    "    \n",
    "    df_metrics = pd.read_excel(f\"{path_save}/Augmentation/{s_name}/confidence/metrics.xlsx\", index_col='Metrics')\n",
    "    for m in metrics_names:\n",
    "        for q in quantiles:\n",
    "            df_conf.at[s_name, f\"{m}_{q}\"] = df_metrics.at[m, f\"q{q}\"]\n",
    "\n",
    "colors_dict = {'Real': 'grey'} | colors_augs\n",
    "for m in metrics_names:\n",
    "    df_fig = df_conf.loc[:, [f\"{m}_{q}\" for q in quantiles]].copy()\n",
    "    df_fig['Type'] = df_fig.index\n",
    "    df_fig = df_fig.melt(id_vars=['Type'], value_name=metrics_names[m])\n",
    "    fig, ax = plt.subplots(figsize=(3, 2))\n",
    "    sns.set_theme(style='ticks') \n",
    "    scatter = sns.scatterplot(\n",
    "        data=df_fig,\n",
    "        x=metrics_names[m],\n",
    "        y='Type',\n",
    "        hue='Type',\n",
    "        palette=colors_dict,\n",
    "        hue_order=list(colors_dict.keys()),\n",
    "        linewidth=0.2,\n",
    "        alpha=0.95,\n",
    "        edgecolor=\"black\",\n",
    "        s=16,\n",
    "        ax=ax\n",
    "    )\n",
    "    scatter.get_legend().set_visible(False)\n",
    "    line = sns.lineplot(\n",
    "        data=df_fig,\n",
    "        x=metrics_names[m],\n",
    "        y='Type',\n",
    "        hue='Type',\n",
    "        palette=colors_dict,\n",
    "        hue_order=list(colors_dict.keys()),\n",
    "        linewidth=2,\n",
    "        ax=ax\n",
    "    )\n",
    "    line.get_legend().set_visible(False)\n",
    "    ax.set_xlabel(f\"Confidence Intervals for {metrics_names[m]}\")\n",
    "    plt.savefig(f\"{path_save}/Augmentation/confidence_{m}.png\", bbox_inches='tight', dpi=400)\n",
    "    plt.savefig(f\"{path_save}/Augmentation/confidence_{m}.pdf\", bbox_inches='tight')\n",
    "    plt.close(fig)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.3. Attacks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generate attacks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "epsilons = sorted(list(set.union(\n",
    "    set(np.linspace(0.1, 1.0, 10)), \n",
    "    set(np.linspace(0.01, 0.1, 10)),\n",
    ")))\n",
    "df_eps = pd.DataFrame(index=epsilons)\n",
    "\n",
    "for eps_raw in epsilons:\n",
    "\n",
    "    eps = np.array([eps_raw * iqr(df.loc[:, feat].values) for feat in feats])\n",
    "    eps_step = np.array([0.2 * eps_raw * iqr(df.loc[:, feat].values) for feat in feats])\n",
    "\n",
    "    attacks = {\n",
    "        'MomentumIterative': MomentumIterativeMethod(\n",
    "            estimator=art_regressor,\n",
    "            norm=np.inf,\n",
    "            eps=eps,\n",
    "            eps_step=eps_step,\n",
    "            decay=0.1,\n",
    "            max_iter=100,\n",
    "            targeted=False,\n",
    "            batch_size=512,\n",
    "            verbose=True\n",
    "        ),\n",
    "        'BasicIterative': BasicIterativeMethod(\n",
    "            estimator=art_regressor,\n",
    "            eps=eps,\n",
    "            eps_step=eps_step,\n",
    "            max_iter=100,\n",
    "            targeted=False,\n",
    "            batch_size=512,\n",
    "            verbose=True\n",
    "        ),\n",
    "        'ProjectedGradientDescent': ProjectedGradientDescentNumpy(\n",
    "            estimator=art_regressor,\n",
    "            norm=np.inf,\n",
    "            eps=eps,\n",
    "            eps_step=eps_step,\n",
    "            decay=None,\n",
    "            max_iter=100,\n",
    "            targeted=False,\n",
    "            num_random_init=0,\n",
    "            batch_size=512,\n",
    "            random_eps=False,\n",
    "            summary_writer=False,\n",
    "            verbose=True\n",
    "        ),\n",
    "        'FastGradient': FastGradientMethod(\n",
    "            estimator=art_regressor,\n",
    "            norm=np.inf,\n",
    "            eps=eps,\n",
    "            eps_step=eps_step,\n",
    "            targeted=False,\n",
    "            num_random_init=0,\n",
    "            batch_size=512,\n",
    "            minimal=False,\n",
    "            summary_writer=False,\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    for attack_name, attack in attacks.items():\n",
    "        path_curr = f\"{path_save}/Evasion/{attack_name}/eps_{eps_raw:0.4f}\"\n",
    "        pathlib.Path(f\"{path_curr}\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        X_adv = attack.generate(np.float32(df.loc[:, feats].values))\n",
    "        \n",
    "        df_adv = df.loc[:, ['Age']].copy()\n",
    "        df_adv.loc[:, feats] = X_adv\n",
    "        df_adv[\"SImAge\"] = model(torch.from_numpy(np.float32(df_adv.loc[:, feats].values))).cpu().detach().numpy().ravel()\n",
    "        df_adv[\"SImAge Error\"] = df_adv[\"SImAge\"] - df_adv[\"Age\"]\n",
    "        df_adv[\"abs(SImAge Error)\"] = df_adv[\"SImAge Error\"].abs()\n",
    "        df_adv.loc[:, \"Error Origin\"] = df.loc[:, \"SImAge\"] - df.loc[:, \"Age\"]\n",
    "        df_adv.loc[:, \"Error Attack\"] = df_adv.loc[:, \"SImAge\"] - df_adv.loc[:, \"Age\"]\n",
    "        df_adv['Error Diff'] = df_adv['Error Attack'] - df_adv['Error Origin']\n",
    "        df_adv['abs(Error Diff)'] = df_adv['Error Diff'].abs()\n",
    "        for m, drm in dim_red_models.items():\n",
    "            dim_red_res = drm.transform(df_adv.loc[:, feats].values)\n",
    "            df_adv.loc[:, dim_red_labels[m][0]] = dim_red_res[:, 0]\n",
    "            df_adv.loc[:, dim_red_labels[m][1]] = dim_red_res[:, 1]\n",
    "            \n",
    "        for f in feats:\n",
    "            df_adv[f\"{f}_scaled\"] = scalers[f].transform(df_adv.loc[:, f].values.reshape(-1, 1))\n",
    "        \n",
    "        add_iqr_outs_to_df(df_adv, df.loc[ids_trn_val, :], feats)\n",
    "        add_pyod_outs_to_df(df_adv, pyod_methods, feats_scaled)\n",
    "            \n",
    "        df_adv.to_excel(f\"{path_curr}/df.xlsx\", index_label='sample_id')\n",
    "\n",
    "        metrics = get_reg_metrics()\n",
    "        metrics_cols = [f\"{m}_{p}\" for m in metrics for p in ids_dict]\n",
    "        df_metrics = pd.DataFrame(index=metrics_cols)\n",
    "        for p, ids_part in ids_dict.items():\n",
    "            for m in metrics:\n",
    "                m_val = float(metrics[m][0](torch.from_numpy(np.float32(df.loc[ids_part, \"SImAge\"].values)), torch.from_numpy(np.float32(df.loc[ids_part, \"Age\"].values))).numpy())\n",
    "                df_metrics.at[f\"{m}_{p}\", 'Origin'] = m_val\n",
    "                metrics[m][0].reset()\n",
    "                m_val = float(metrics[m][0](torch.from_numpy(np.float32(df_adv.loc[ids_part, \"SImAge\"].values)), torch.from_numpy(np.float32(df.loc[ids_part, \"Age\"].values))).numpy())\n",
    "                df_metrics.at[f\"{m}_{p}\", 'Attack'] = m_val\n",
    "                metrics[m][0].reset()\n",
    "        df_metrics.to_excel(f\"{path_curr}/metrics.xlsx\", index_label='Metrics')\n",
    "        \n",
    "        for p in ids_dict:\n",
    "            if attack_name == 'MomentumIterative':\n",
    "                df_eps.loc[eps_raw, f\"Origin_MAE_{p}\"] = df_metrics.at[f'mean_absolute_error_{p}', 'Origin']\n",
    "            df_eps.loc[eps_raw, f\"{attack_name}_MAE_{p}\"] = df_metrics.at[f'mean_absolute_error_{p}', 'Attack']\n",
    "            \n",
    "df_eps.to_excel(f\"{path_save}/Evasion/df_eps.xlsx\", index_label='eps')\n",
    "\n",
    "for p in ids_dict:\n",
    "    df_fig = df_eps.loc[:, [f\"{x}_MAE_{p}\" for x in colors_atks]].copy()\n",
    "    df_fig.rename(columns={f\"{x}_MAE_{p}\": x for x in colors_atks}, inplace=True)\n",
    "    df_fig['Eps'] = df_fig.index.values\n",
    "    df_fig = df_fig.melt(id_vars=\"Eps\", var_name='Method', value_name=\"MAE\")\n",
    "    fig = plt.figure()\n",
    "    sns.set_theme(style='whitegrid', font_scale=1)\n",
    "    lines = sns.lineplot(\n",
    "        data=df_fig,\n",
    "        x='Eps',\n",
    "        y=\"MAE\",\n",
    "        hue=f\"Method\",\n",
    "        style=f\"Method\",\n",
    "        palette=colors_atks,\n",
    "        hue_order=list(colors_atks.keys()),\n",
    "        markers=True,\n",
    "        dashes=False,\n",
    "    )\n",
    "    plt.xscale('log')\n",
    "    lines.set_xlabel(r'$\\epsilon$')\n",
    "    x_min = 0.009\n",
    "    x_max = 1.05\n",
    "    mae_basic = df_eps.at[0.01, f\"Origin_MAE_{p}\"]\n",
    "    lines.set_xlim(x_min, x_max)\n",
    "    plt.gca().plot(\n",
    "        [x_min, x_max],\n",
    "        [mae_basic, mae_basic],\n",
    "        color='k',\n",
    "        linestyle='dashed',\n",
    "        linewidth=1\n",
    "    )\n",
    "    plt.savefig(f\"{path_save}/Evasion/line_mae_vs_eps_{p}.png\", bbox_inches='tight', dpi=200)\n",
    "    plt.savefig(f\"{path_save}/Evasion/line_mae_vs_eps_{p}.pdf\", bbox_inches='tight')\n",
    "    plt.close(fig)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot in reduced dimension"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "epsilons_hglt = [0.01, 0.02, 0.05, 0.1, 0.2, 0.5]\n",
    "colors_epsilons = {x: px.colors.qualitative.G10[x_id] for x_id, x in enumerate(['Origin'] + epsilons_hglt)}\n",
    "\n",
    "for atk in colors_atks:\n",
    "    for m in ['t-SNE']:\n",
    "        df_fig_ori = df.loc[:, ['SImAge Error', dim_red_labels[m][0], dim_red_labels[m][1]]].copy()\n",
    "        df_fig_ori['Symbol'] = 'o'\n",
    "        df_fig_ori['index_origin'] = df_fig_ori.index\n",
    "        df_fig_ori['Eps'] = 'Origin'\n",
    "        \n",
    "        dfs_fig_adv = [df_fig_ori]\n",
    "        for eps in epsilons_hglt:\n",
    "            path_curr = f\"{path_save}/Evasion/{atk}/eps_{eps:0.4f}\"\n",
    "            pathlib.Path(f\"{path_curr}/SImAgeError\").mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            df_adv = pd.read_excel(f\"{path_curr}/df.xlsx\", index_col='sample_id')\n",
    "            df_fig_adv = df_adv.loc[:, ['SImAge Error', 'abs(Error Diff)', dim_red_labels[m][0], dim_red_labels[m][1]]].copy()\n",
    "            df_fig_adv['Eps'] = eps\n",
    "            df_fig_adv['index_origin'] = df_fig_adv.index\n",
    "            df_fig_adv.set_index(df_fig_adv.index.values + f'_adv_eps_{eps:0.4f}', inplace=True)\n",
    "            df_fig_adv['Symbol'] = 'X'\n",
    "            dfs_fig_adv.append(df_fig_adv)\n",
    "            df_fig_all = pd.concat([df_fig_ori, df_fig_adv])\n",
    "            \n",
    "            norm = plt.Normalize(df_fig_all['SImAge Error'].min(), df_fig_all['SImAge Error'].max())\n",
    "            sm = plt.cm.ScalarMappable(cmap=\"spring\", norm=norm)\n",
    "            sm.set_array([])\n",
    "            \n",
    "            fig, ax = plt.subplots(figsize=(5, 4))\n",
    "            \n",
    "            sns.set_theme(style='whitegrid')\n",
    "            scatter = sns.scatterplot(\n",
    "                data=df_fig_all,\n",
    "                x=dim_red_labels[m][0],\n",
    "                y=dim_red_labels[m][1],\n",
    "                palette='spring',\n",
    "                hue='SImAge Error',\n",
    "                linewidth=1,\n",
    "                alpha=0.75,\n",
    "                edgecolor=\"k\",\n",
    "                style=df_fig_all.loc[:, 'Symbol'].values,\n",
    "                s=40,\n",
    "                ax=ax\n",
    "            )\n",
    "            scatter.get_legend().remove()\n",
    "            scatter.figure.colorbar(sm, label='SImAge Error')\n",
    "            scatter.set_title(fr'$\\epsilon={eps:0.2f}$', loc='left', fontdict={'fontsize': 20})\n",
    "\n",
    "            legend_handles = [\n",
    "                mlines.Line2D([], [], marker='o', linestyle='None', markeredgecolor='k', markerfacecolor='lightgrey', markersize=10, label='Real'),\n",
    "                mlines.Line2D([], [], marker='X', linestyle='None', markeredgecolor='k', markerfacecolor='lightgrey', markersize=10, label='Attack')\n",
    "            ]\n",
    "            plt.legend(handles=legend_handles, title=\"Samples\", bbox_to_anchor=(0.4, 1.02, 1, 0.2), loc=\"lower left\", borderaxespad=0, ncol=2, frameon=False)\n",
    "            \n",
    "            plt.savefig(f\"{path_curr}/SImAgeError/{m}.png\", bbox_inches='tight', dpi=200)\n",
    "            plt.savefig(f\"{path_curr}/SImAgeError/{m}.pdf\", bbox_inches='tight')\n",
    "            plt.close(fig)  \n",
    "        \n",
    "        df_fig_adv_eps = pd.concat(dfs_fig_adv)\n",
    "        fig, ax = plt.subplots(figsize=(6, 4))\n",
    "        sns.set_theme(style='whitegrid')\n",
    "        kdeplot = sns.kdeplot(\n",
    "            data=df_fig_adv_eps,\n",
    "            x='SImAge Error',\n",
    "            palette=colors_epsilons,\n",
    "            hue='Eps',\n",
    "            linewidth=2,\n",
    "            fill=False,\n",
    "            ax=ax\n",
    "        )\n",
    "        plt.savefig(f\"{path_save}/Evasion/{atk}/SImAgeError_{m}.png\", bbox_inches='tight', dpi=200)\n",
    "        plt.savefig(f\"{path_save}/Evasion/{atk}/SImAgeError_{m}.pdf\", bbox_inches='tight')\n",
    "        plt.close(fig)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot distributions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "epsilons_hglt = [0.01, 0.02, 0.05, 0.1, 0.2, 0.5]\n",
    "colors_epsilons = {x: px.colors.qualitative.G10[x_id] for x_id, x in enumerate(['Origin'] + epsilons_hglt)}\n",
    "\n",
    "df['Eps'] = 'Origin'\n",
    "df['MarkerSize'] = 40\n",
    "\n",
    "for atk in colors_atks:\n",
    "\n",
    "    for eps in epsilons_hglt:\n",
    "        path_curr = f\"{path_save}/Evasion/{atk}/eps_{eps:0.4f}\"\n",
    "        pathlib.Path(f\"{path_curr}/SImAgeError\").mkdir(parents=True, exist_ok=True)\n",
    "        df_adv = pd.read_excel(f\"{path_curr}/df.xlsx\", index_col='sample_id')\n",
    "        df_adv.index += f'_eps_{eps:0.4f}'\n",
    "        df_adv['Eps'] = eps\n",
    "        df_adv['MarkerSize'] = 30\n",
    "        df_ori_adv = pd.concat([df, df_adv])\n",
    "        \n",
    "        pw_brick_kdes = {}\n",
    "        pw_brick_scatters = {}\n",
    "        for f in feats:\n",
    "            \n",
    "            pw_brick_kdes[f] = pw.Brick(figsize=(4, 3))\n",
    "            sns.set_theme(style='whitegrid')\n",
    "            kdeplot = sns.kdeplot(\n",
    "                data=df_ori_adv,\n",
    "                x=f,\n",
    "                hue='Eps',\n",
    "                palette={'Origin': 'grey', eps: colors_epsilons[eps]},\n",
    "                hue_order=['Origin', eps],\n",
    "                fill=True,\n",
    "                common_norm=False,\n",
    "                ax=pw_brick_kdes[f]\n",
    "            )\n",
    "            \n",
    "            pw_brick_scatters[f] = pw.Brick(figsize=(4, 3))\n",
    "            sns.set_theme(style='whitegrid')\n",
    "            scatterplot = sns.scatterplot(\n",
    "                data=df_ori_adv,\n",
    "                x=f,\n",
    "                y='Age',\n",
    "                hue='Eps',\n",
    "                palette={'Origin': 'grey', eps: colors_epsilons[eps]},\n",
    "                hue_order=['Origin', eps],\n",
    "                linewidth=0.85,\n",
    "                alpha=0.75,\n",
    "                edgecolor=\"k\",\n",
    "                marker='o',\n",
    "                s=30,\n",
    "                ax=pw_brick_scatters[f]\n",
    "            )\n",
    "        \n",
    "        n_cols = 3\n",
    "        n_rows = int(np.ceil(len(feats)/ n_cols))\n",
    "        pw_rows_kdes = []\n",
    "        pw_rows_scatters = []\n",
    "        for r_id in range(n_rows):\n",
    "            pw_cols_kdes = []\n",
    "            pw_cols_scatters = []\n",
    "            for c_id in range(n_cols):\n",
    "                rc_id = r_id * n_cols + c_id\n",
    "                if rc_id < len(feats):\n",
    "                    f = feats[rc_id]\n",
    "                    pw_cols_kdes.append(pw_brick_kdes[f])\n",
    "                    pw_cols_scatters.append(pw_brick_scatters[f])\n",
    "                else:\n",
    "                    empty_fig = pw.Brick(figsize=(4.67, 3))\n",
    "                    empty_fig.axis('off')\n",
    "                    pw_cols_kdes.append(empty_fig)\n",
    "                    pw_cols_scatters.append(empty_fig)\n",
    "            pw_rows_kdes.append(pw.stack(pw_cols_kdes, operator=\"|\"))\n",
    "            pw_rows_scatters.append(pw.stack(pw_cols_scatters, operator=\"|\"))\n",
    "        pw_fig_kde = pw.stack(pw_rows_kdes, operator=\"/\")\n",
    "        pw_fig_kde.savefig(f\"{path_curr}/feats_kde.png\", bbox_inches='tight', dpi=200)\n",
    "        pw_fig_kde.savefig(f\"{path_curr}/feats_kde.pdf\", bbox_inches='tight')\n",
    "        pw_fig_scatter = pw.stack(pw_rows_scatters, operator=\"/\")\n",
    "        pw_fig_scatter.savefig(f\"{path_curr}/feats_scatter.png\", bbox_inches='tight', dpi=200)\n",
    "        pw_fig_scatter.savefig(f\"{path_curr}/feats_scatter.pdf\", bbox_inches='tight')\n",
    "        pw.clear()"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Outliers analysis for attacks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "epsilons_hglt = [0.01, 0.02, 0.05, 0.1, 0.2, 0.5]\n",
    "colors_epsilons = {x: px.colors.qualitative.G10[x_id] for x_id, x in enumerate(['Origin'] + epsilons_hglt)}\n",
    "\n",
    "for atk in colors_atks:\n",
    "\n",
    "    for eps in epsilons_hglt:\n",
    "        path_curr = f\"{path_save}/Evasion/{atk}/eps_{eps:0.4f}\"\n",
    "        pathlib.Path(f\"{path_curr}/SImAgeError\").mkdir(parents=True, exist_ok=True)\n",
    "        df_adv = pd.read_excel(f\"{path_curr}/df.xlsx\", index_col='sample_id')\n",
    "        \n",
    "        # IQR outliers\n",
    "        pathlib.Path(f\"{path_curr}/outliers_iqr\").mkdir(parents=True, exist_ok=True)\n",
    "        plot_iqr_outs(df_adv, feats, colors_epsilons[eps], f\"{atk} Eps({eps})\", f\"{path_curr}/outliers_iqr\")\n",
    "        \n",
    "        # PyOD plots\n",
    "        pathlib.Path(f\"{path_curr}/outliers_pyod\").mkdir(parents=True, exist_ok=True)\n",
    "        plot_pyod_outs(df_adv, pyod_methods, colors_epsilons[eps], f\"{atk} Eps({eps})\", f\"{path_curr}/outliers_pyod\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Regression error analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "epsilons_hglt = [0.01, 0.02, 0.05, 0.1, 0.2, 0.5]\n",
    "colors_epsilons = {x: px.colors.qualitative.G10[x_id] for x_id, x in enumerate(['Origin'] + epsilons_hglt)}\n",
    "\n",
    "for atk in colors_atks:\n",
    "\n",
    "    for eps in epsilons_hglt:\n",
    "        path_curr = f\"{path_save}/Evasion/{atk}/eps_{eps:0.4f}\"\n",
    "        pathlib.Path(f\"{path_curr}/errors\").mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        df_adv = pd.read_excel(f\"{path_curr}/df.xlsx\", index_col='sample_id')\n",
    "\n",
    "        plot_regression_error_distributions(df_adv, feats, colors_epsilons[eps], f\"{atk} Eps({eps})\", f\"{path_curr}/errors\", \"abs(SImAge Error)\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Confidence"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "torch.manual_seed(42)\n",
    "quantiles = torch.tensor([0.05, 0.95])\n",
    "\n",
    "epsilons = sorted(list(set.union(\n",
    "    set(np.linspace(0.1, 1.0, 10)), \n",
    "    set(np.linspace(0.01, 0.1, 10)),\n",
    ")))\n",
    "\n",
    "for atk in colors_atks:\n",
    "\n",
    "    for eps in epsilons:\n",
    "        path_curr = f\"{path_save}/Evasion/{atk}/eps_{eps:0.4f}\"\n",
    "        pathlib.Path(f\"{path_curr}/confidence\").mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        df_adv = pd.read_excel(f\"{path_curr}/df.xlsx\", index_col='sample_id')\n",
    "\n",
    "        metrics = get_reg_metrics()\n",
    "        df_metrics = pd.DataFrame(index=list(metrics.keys()), columns=['mean', 'std', 'q0.05', 'q0.95'])\n",
    "        y_real = torch.from_numpy(np.float32(df_adv['Age'].values))\n",
    "        y_pred = torch.from_numpy(np.float32(df_adv['SImAge'].values))\n",
    "        for metric_name, metric_pair in metrics.items():\n",
    "            metric = metric_pair[0]\n",
    "            bootstrap = BootStrapper(\n",
    "                metric,\n",
    "                num_bootstraps=200,\n",
    "                sampling_strategy=\"multinomial\",\n",
    "                quantile=quantiles\n",
    "            )\n",
    "            bootstrap.update(y_pred, y_real)\n",
    "            bootstrap_output = bootstrap.compute()\n",
    "            df_metrics.at[metric_name, 'mean'] = bootstrap_output['mean'].detach().cpu().numpy()\n",
    "            df_metrics.at[metric_name, 'std'] = bootstrap_output['std'].detach().cpu().numpy()\n",
    "            df_metrics.at[metric_name, 'q0.05'] = bootstrap_output['quantile'].detach().cpu().numpy()[0]\n",
    "            df_metrics.at[metric_name, 'q0.95'] = bootstrap_output['quantile'].detach().cpu().numpy()[1]\n",
    "        df_metrics.to_excel(f\"{path_curr}/confidence/metrics.xlsx\", index_label='Metrics')"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "metrics_names = {\n",
    "    'mean_absolute_error': 'MAE',\n",
    "    'pearson_corr_coef': 'Pearson rho'\n",
    "}\n",
    "quantiles = [0.05, 0.95]\n",
    "epsilons = sorted(list(set.union(\n",
    "    set(np.linspace(0.1, 1.0, 10)), \n",
    "    set(np.linspace(0.01, 0.1, 10)),\n",
    ")))\n",
    "\n",
    "for atk in colors_atks:\n",
    "    df_conf = pd.DataFrame(index=epsilons, columns=[f\"{m}_{q}\" for m in metrics_names for q in quantiles])\n",
    "    for eps in (pbar := tqdm(epsilons)):\n",
    "        pbar.set_description(f\"Processing Eps: {eps}\")\n",
    "        df_metrics = pd.read_excel(f\"{path_save}/Evasion/{atk}/eps_{eps:0.4f}/confidence/metrics.xlsx\", index_col='Metrics')\n",
    "        for m in metrics_names:\n",
    "            for q in quantiles:\n",
    "                df_conf.at[eps, f\"{m}_{q}\"] = df_metrics.at[m, f\"q{q}\"]\n",
    "    \n",
    "    for m in metrics_names:\n",
    "        df_fig = df_conf.loc[:, [f\"{m}_{q}\" for q in quantiles]].copy()\n",
    "        df_fig['Type'] = df_fig.index\n",
    "        df_fig = df_fig.melt(id_vars=['Type'], value_name=metrics_names[m])\n",
    "        fig, ax = plt.subplots(figsize=(5, 4))\n",
    "        sns.set_theme(style='ticks') \n",
    "        scatter = sns.scatterplot(\n",
    "            data=df_fig,\n",
    "            y=metrics_names[m],\n",
    "            x='Type',\n",
    "            hue='Type',\n",
    "            palette={x: colors_atks[atk] for x in epsilons},\n",
    "            hue_order=epsilons,\n",
    "            linewidth=0.2,\n",
    "            alpha=0.95,\n",
    "            edgecolor=\"black\",\n",
    "            s=16,\n",
    "            ax=ax\n",
    "        )\n",
    "        scatter.get_legend().set_visible(False)\n",
    "        line = sns.lineplot(\n",
    "            data=df_fig,\n",
    "            y=metrics_names[m],\n",
    "            x='Type',\n",
    "            hue='Type',\n",
    "            palette={x: colors_atks[atk] for x in epsilons},\n",
    "            hue_order=epsilons,\n",
    "            linewidth=3,\n",
    "            ax=ax\n",
    "        )\n",
    "        line.get_legend().set_visible(False)\n",
    "        plt.xscale('log')\n",
    "        ax.set_xlabel(r'$\\epsilon$')\n",
    "        x_min = 0.009\n",
    "        x_max = 1.05\n",
    "        ax.set_ylabel(f\"Confidence Intervals for {metrics_names[m]}\")\n",
    "        plt.savefig(f\"{path_save}/Evasion/{atk}/confidence_{m}.png\", bbox_inches='tight', dpi=400)\n",
    "        plt.savefig(f\"{path_save}/Evasion/{atk}/confidence_{m}.pdf\", bbox_inches='tight')\n",
    "        plt.close(fig)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
