{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy import stats\n",
    "import plotly.express as px\n",
    "from scripts.python.routines.plot.scatter import add_scatter_trace\n",
    "import plotly.graph_objects as go\n",
    "from scripts.python.routines.plot.save import save_figure\n",
    "from scripts.python.routines.plot.layout import add_layout, get_axis\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import plotly.io as pio\n",
    "pio.kaleido.scope.mathjax = None\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=False)\n",
    "import matplotlib.pyplot as plt\n",
    "from omegaconf import OmegaConf\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "import pathlib\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from scipy import stats\n",
    "import patchworklib as pw\n",
    "import os\n",
    "import functools\n",
    "from statannotations.Annotator import Annotator\n",
    "from scipy.stats import mannwhitneyu\n",
    "import shap\n",
    "from slugify import slugify\n",
    "\n",
    "\n",
    "def conjunction(conditions):\n",
    "    return functools.reduce(np.logical_and, conditions)\n",
    "\n",
    "\n",
    "def disjunction(conditions):\n",
    "    return functools.reduce(np.logical_or, conditions)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 0. Setup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path = \"D:/YandexDisk/Work/pydnameth/datasets/GPL21145/GSEUNN/special/044_small_immuno_clocks_revision\"\n",
    "pathlib.Path(f\"{path}\").mkdir(parents=True, exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Prepare additional test data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_origin = pd.read_excel(f\"{path}/data_origin/260_imp(fast_knn)_replace(quarter).xlsx\", index_col=0)\n",
    "df_all = pd.read_excel(f\"{path}/df_samples(all_1052_121222)_proc(raw)_imp(fast_knn)_replace(quarter).xlsx\", index_col=0)\n",
    "indexes_not_origin = df_all.index.difference(df_origin.index)\n",
    "df_all[\"parts_danet\"] = df_all[\"Region\"].str.cat(df_all[[\"Status\"]].astype(str), sep=\"_\")\n",
    "df_all[\"Split\"] = \"tst\"\n",
    "\n",
    "df_new = pd.concat([df_origin, df_all.loc[indexes_not_origin, :]])\n",
    "df_new.to_excel(f\"{path}/all_for_test.xlsx\", index_label=\"index\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Create new dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_origin = pd.read_excel(f\"{path}/origin/260_imp(fast_knn)_replace(quarter).xlsx\", index_col=0)\n",
    "df_all = pd.read_excel(f\"{path}/origin/df_samples(all_1052_121222)_proc(raw)_imp(fast_knn)_replace(quarter).xlsx\", index_col=0)\n",
    "\n",
    "df_tst_central_include = pd.read_excel(f\"{path}/origin/samples_test_slctd.xlsx\", index_col=0)\n",
    "df_tst_central_include[\"index\"] = df_tst_central_include.index.values\n",
    "df_tst_central_include[\"index\"] = df_tst_central_include[\"index\"].str.rstrip('_copy')\n",
    "indexes_test_ctrl_central = df_tst_central_include[\"index\"].values\n",
    "print(len(indexes_test_ctrl_central))\n",
    "df_test_ctrl_central = df_all.loc[indexes_test_ctrl_central, :].copy()\n",
    "df_test_ctrl_central[\"parts_danet\"] = 'tst_ctrl_central'\n",
    "df_test_ctrl_central[\"Split\"] = 'tst_ctrl_central'\n",
    "\n",
    "df_res = pd.read_excel(f\"{path}/origin/models/danet_inference/runs/2023-04-12_12-16-05/df.xlsx\", index_col=0)\n",
    "indexes_test_ctrl_yakutia = df_res.index[(df_res[\"parts_danet\"] == \"Yakutia_Control\")].values\n",
    "print(len(indexes_test_ctrl_yakutia))\n",
    "df_test_ctrl_yakutia = df_all.loc[indexes_test_ctrl_yakutia, :].copy()\n",
    "df_test_ctrl_yakutia[\"parts_danet\"] = 'tst_ctrl_yakutia'\n",
    "df_test_ctrl_yakutia[\"Split\"] = 'tst_ctrl_yakutia'\n",
    "\n",
    "indexes_test_esrd = df_all.index[df_all[\"Status\"] == \"ESRD\"].values\n",
    "print(len(indexes_test_esrd))\n",
    "df_test_esrd = df_all.loc[indexes_test_esrd, :]\n",
    "df_test_esrd[\"parts_danet\"] = 'tst_esrd'\n",
    "df_test_esrd[\"Split\"] = 'tst_esrd'\n",
    "\n",
    "df_new = pd.concat([df_origin, df_test_ctrl_central, df_test_ctrl_yakutia, df_test_esrd])\n",
    "\n",
    "df_dead_alive = pd.read_excel(f\"{path}/origin/df_samples_dead_or_alive.xlsx\", index_col=0)\n",
    "inds_dead_alive = df_dead_alive.index[df_dead_alive[\"Dead_Alive\"] == \"Dead\"].values\n",
    "df_new.loc[inds_dead_alive, \"Dead_Alive\"] = \"Dead\"\n",
    "\n",
    "df_new.to_excel(f\"{path}/data_wtf.xlsx\", index_label=\"index\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Collect ML results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = 'widedeep_ft_transformer_trn_val_tst'\n",
    "\n",
    "part_check = \"tst_ctrl_central\"\n",
    "part_check_thld_mean = 7.5\n",
    "df = pd.read_excel(f\"{path}/data_final.xlsx\", index_col=0)\n",
    "samples_tst_ctrl_central = df.index[df[\"Split\"] == \"tst_ctrl_central\"].values\n",
    "\n",
    "path_runs = f\"{path}/models/10_trn_val_tst/best_{model}/multiruns\"\n",
    "\n",
    "files = glob(f\"{path_runs}/*/*/metrics_all_best_*.xlsx\")\n",
    "\n",
    "df_tmp = pd.read_excel(files[0], index_col=\"metric\")\n",
    "head, tail = os.path.split(files[0])\n",
    "cfg = OmegaConf.load(f\"{head}/.hydra/overrides.yaml\")\n",
    "params = []\n",
    "for param_pair in cfg:\n",
    "    param, val = param_pair.split('=')\n",
    "    params.append(param)\n",
    "df_res = pd.DataFrame(index=files)\n",
    "\n",
    "for file in files:\n",
    "\n",
    "    head, tail = os.path.split(file)\n",
    "    df_pred = pd.read_excel(f\"{head}/predictions.xlsx\", index_col=0)\n",
    "    df_pred[\"Error\"] = df_pred[\"Prediction\"] - df_pred[\"Age\"]\n",
    "    df_pred[\"AbsError\"] = df_pred[\"Error\"].abs()\n",
    "    part_col = df_pred.columns[0]\n",
    "    df_pred_tst_ctrl_central = df_pred.loc[df_pred[part_col] == part_check, :].copy()\n",
    "    df_pred_tst_ctrl_central.sort_values([\"AbsError\"], ascending=[True], inplace=True)\n",
    "    df_pred_tst_ctrl_central[\"MeanAbsErrorExpanding\"] = df_pred_tst_ctrl_central[\"AbsError\"].expanding().mean()\n",
    "    samples_tst_ctrl_central_passed = df_pred_tst_ctrl_central.index[df_pred_tst_ctrl_central[\"MeanAbsErrorExpanding\"] < part_check_thld_mean].values\n",
    "    n_samples_passed = len(samples_tst_ctrl_central_passed)\n",
    "\n",
    "    df_res.at[file, \"passed_test_samples\"] = n_samples_passed\n",
    "\n",
    "    # tst_ctrl_central\n",
    "    y_real = df_pred.loc[samples_tst_ctrl_central, \"Age\"]\n",
    "    y_pred = df_pred.loc[samples_tst_ctrl_central, \"Prediction\"]\n",
    "    mae_tst = mean_absolute_error(y_real, y_pred)\n",
    "    rho_tst = stats.pearsonr(y_real, y_pred).statistic\n",
    "    df_res.at[file, 'mean_absolute_error_tst_ctrl_central'] = mae_tst\n",
    "    df_res.at[file, 'pearson_corr_coef_tst_ctrl_central'] = rho_tst\n",
    "\n",
    "    # Metrics\n",
    "    df_metrics = pd.read_excel(file, index_col=\"metric\")\n",
    "    for metric in df_metrics.index.values:\n",
    "        df_res.at[file, metric + \"_val\"] = df_metrics.at[metric, \"val\"]\n",
    "        df_res.at[file, metric + \"_trn\"] = df_metrics.at[metric, \"trn\"]\n",
    "        df_res.at[file, metric + \"_tst_ctrl_central\"] = df_metrics.at[metric, \"tst_ctrl_central\"]\n",
    "        df_res.at[file, metric + \"_trn_val_tst_ctrl_central\"] = df_metrics.at[metric, \"trn_val_tst_ctrl_central\"]\n",
    "        df_res.at[file, metric + \"_val_tst_ctrl_central\"] = df_metrics.at[metric, \"val_tst_ctrl_central\"]\n",
    "\n",
    "    # Params\n",
    "    cfg = OmegaConf.load(f\"{head}/.hydra/overrides.yaml\")\n",
    "    for param_pair in cfg:\n",
    "        param, val = param_pair.split('=')\n",
    "        df_res.at[file, param] = val\n",
    "\n",
    "df_res[\"train_more_val\"] = False\n",
    "df_res[\"selected\"] = False\n",
    "df_res.loc[df_res[\"mean_absolute_error_trn\"] > df_res[\"mean_absolute_error_val\"], \"train_more_val\"] = True\n",
    "\n",
    "first_columns = [\n",
    "    'selected',\n",
    "    'passed_test_samples',\n",
    "    'train_more_val',\n",
    "    'mean_absolute_error_trn',\n",
    "    'mean_absolute_error_val',\n",
    "    'mean_absolute_error_tst_ctrl_central',\n",
    "    'mean_absolute_error_val_tst_ctrl_central',\n",
    "    'mean_absolute_error_trn_val_tst_ctrl_central',\n",
    "    'pearson_corr_coef_trn',\n",
    "    'pearson_corr_coef_val',\n",
    "    'pearson_corr_coef_tst_ctrl_central',\n",
    "    'pearson_corr_coef_val_tst_ctrl_central',\n",
    "    'pearson_corr_coef_trn_val_tst_ctrl_central',\n",
    "    'mean_absolute_error_cv_mean_trn',\n",
    "    'mean_absolute_error_cv_std_trn',\n",
    "    'mean_absolute_error_cv_mean_val',\n",
    "    'mean_absolute_error_cv_std_val',\n",
    "    'pearson_corr_coef_cv_mean_trn',\n",
    "    'pearson_corr_coef_cv_std_trn',\n",
    "    'pearson_corr_coef_cv_mean_val',\n",
    "    'pearson_corr_coef_cv_std_val',\n",
    "]\n",
    "df_res = df_res[first_columns + [col for col in df_res.columns if col not in first_columns]]\n",
    "df_res.to_excel(f\"{path_runs}/summary.xlsx\", index=True, index_label=\"file\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Decider for central controls"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "part_check = \"tst_ctrl_all\"\n",
    "part_check_thld_mean = 8.43\n",
    "\n",
    "df = pd.read_excel(f\"{path}/data.xlsx\", index_col=0)\n",
    "samples_test = df.index[df[\"Split\"] == \"tst_ctrl_all\"].values\n",
    "\n",
    "models_all = [\n",
    "    \"elastic_net\",\n",
    "    \"xgboost\",\n",
    "    \"lightgbm\",\n",
    "    \"catboost\",\n",
    "    \"widedeep_tab_mlp\",\n",
    "    \"nam\",\n",
    "    \"nbm_spam_nam\",\n",
    "    \"pytorch_tabular_node\",\n",
    "    \"danet\",\n",
    "    \"widedeep_tab_net\",\n",
    "    \"pytorch_tabular_autoint\",\n",
    "    \"widedeep_saint\",\n",
    "    \"widedeep_ft_transformer\"\n",
    "]\n",
    "\n",
    "models_main = [\n",
    "    \"danet\",\n",
    "    \"widedeep_saint\",\n",
    "    \"widedeep_ft_transformer\"\n",
    "]\n",
    "\n",
    "path_models = f\"{path}/models/46_trn_val_tst\"\n",
    "\n",
    "df_res = pd.DataFrame(index=models_all)\n",
    "df_samples_test = pd.DataFrame(index=samples_test, columns=models_all)\n",
    "\n",
    "for m in models_all:\n",
    "    df_summary = pd.read_excel(f\"{path_models}/{m}_trn_val_tst/multiruns/summary.xlsx\", index_col=0)\n",
    "    files_slctd = df_summary.index[df_summary[\"selected\"] == True].values\n",
    "    if len(files_slctd) != 1:\n",
    "        raise ValueError(f\"{m} model selection error\")\n",
    "    file_slctd = files_slctd[0]\n",
    "    path_head, _ = os.path.split(file_slctd)\n",
    "    path_head = path_head.replace('/46/', '/46_trn_val_tst/', 1)\n",
    "\n",
    "    file_val = glob(f\"{path_head}/metrics_val_best_*.xlsx\")[0]\n",
    "    df_res_val = pd.read_excel(file_val, index_col=0)\n",
    "\n",
    "    df_res.at[m, 'val_mae_best'] = df_res_val.at['mean_absolute_error', 'val']\n",
    "    df_res.at[m, 'val_mae_mean'] = df_res_val.at['mean_absolute_error_cv_mean', 'val']\n",
    "    df_res.at[m, 'val_mae_std'] = df_res_val.at['mean_absolute_error_cv_std', 'val']\n",
    "    df_res.at[m, 'val_rho_best'] = df_res_val.at['pearson_corr_coef', 'val']\n",
    "    df_res.at[m, 'val_rho_mean'] = df_res_val.at['pearson_corr_coef_cv_mean', 'val']\n",
    "    df_res.at[m, 'val_rho_std'] = df_res_val.at['pearson_corr_coef_cv_std', 'val']\n",
    "\n",
    "    df_pred = pd.read_excel(f\"{path_head}/predictions.xlsx\", index_col=0)\n",
    "    df_pred[\"Error\"] = df_pred[\"Prediction\"] - df_pred[\"Age\"]\n",
    "    df_pred[\"AbsError\"] = df_pred[\"Error\"].abs()\n",
    "    part_col = df_pred.columns[0]\n",
    "    df_pred[part_col].replace({\"tst_ctrl_central\": part_check}, inplace=True)\n",
    "    df_pred = df_pred.loc[df_pred[part_col] == part_check, :]\n",
    "    df_pred.sort_values([\"AbsError\"], ascending=[True], inplace=True)\n",
    "    df_pred[\"MeanAbsErrorExpanding\"] = df_pred[\"AbsError\"].expanding().mean()\n",
    "    samples_passed = df_pred.index[df_pred[\"MeanAbsErrorExpanding\"] < part_check_thld_mean].values\n",
    "    df_samples_test.loc[:, m] = 0\n",
    "    df_samples_test.loc[samples_passed, m] = 1\n",
    "    n_samples_passed = len(samples_passed)\n",
    "    print(f\"{m}: {n_samples_passed}\")\n",
    "\n",
    "df_samples_test.to_excel(f\"{path_models}/samples_test_full.xlsx\", index_label=\"model\")\n",
    "\n",
    "conditions = [df_samples_test[m] == 1 for m in models_main]\n",
    "df_samples_test = df_samples_test[conjunction(conditions)]\n",
    "samples_test_final = df_samples_test.index.values\n",
    "print(len(samples_test_final))\n",
    "\n",
    "for m in models_all:\n",
    "    df_summary = pd.read_excel(f\"{path_models}/{m}_trn_val_tst/multiruns/summary.xlsx\", index_col=0)\n",
    "    files_slctd = df_summary.index[df_summary[\"selected\"] == True].values\n",
    "    if len(files_slctd) != 1:\n",
    "        raise ValueError(f\"{m} model selection error\")\n",
    "    file_slctd = files_slctd[0]\n",
    "    path_head, _ = os.path.split(file_slctd)\n",
    "    path_head = path_head.replace('models/46/', 'models/46_trn_val_tst/', 1)\n",
    "\n",
    "    df_pred = pd.read_excel(f\"{path_head}/predictions.xlsx\", index_col=0)\n",
    "    df_pred = df_pred.loc[samples_test_final, :]\n",
    "    y_real = df_pred[\"Age\"]\n",
    "    y_pred = df_pred[\"Prediction\"]\n",
    "    mae_tst = mean_absolute_error(y_real, y_pred)\n",
    "    rho_tst = stats.pearsonr(y_real, y_pred).statistic\n",
    "    df_res.at[m, 'tst_mae'] = mae_tst\n",
    "    df_res.at[m, 'tst_rho'] = rho_tst\n",
    "\n",
    "df_res.to_excel(f\"{path_models}/baseline_results.xlsx\", index_label=\"model\")\n",
    "df_samples_test.to_excel(f\"{path_models}/samples_test_slctd.xlsx\", index_label=\"model\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5. Updating data with trn/val splits from best models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_excel(f\"{path}/data_final.xlsx\", index_col=0)\n",
    "\n",
    "models_all = [\n",
    "    \"elastic_net\",\n",
    "    \"xgboost\",\n",
    "    \"lightgbm\",\n",
    "    \"catboost\",\n",
    "    \"widedeep_tab_mlp\",\n",
    "    \"nam\",\n",
    "    \"nbm_spam_nam\",\n",
    "    \"pytorch_tabular_node\",\n",
    "    \"danet\",\n",
    "    \"widedeep_tab_net\",\n",
    "    \"pytorch_tabular_autoint\",\n",
    "    \"widedeep_saint\",\n",
    "    \"widedeep_ft_transformer\"\n",
    "]\n",
    "\n",
    "path_models = f\"{path}/models/46_trn_val_tst\"\n",
    "for m in models_all:\n",
    "    df[f\"best_{m}\"] = df[\"Split\"]\n",
    "\n",
    "    df_summary = pd.read_excel(f\"{path_models}/{m}_trn_val_tst/multiruns/summary.xlsx\", index_col=0)\n",
    "    files_slctd = df_summary.index[df_summary[\"selected\"] == True].values\n",
    "    if len(files_slctd) != 1:\n",
    "        raise ValueError(f\"{m} model selection error\")\n",
    "    file_slctd = files_slctd[0]\n",
    "    path_head, _ = os.path.split(file_slctd)\n",
    "\n",
    "    path_head = path_head.replace('models/46/', 'models/46_trn_val_tst/', 1)\n",
    "\n",
    "    df_pred = pd.read_excel(f\"{path_head}/predictions.xlsx\", index_col=0)\n",
    "    part_col = df_pred.columns[0]\n",
    "    ids_trn = df_pred.index[df_pred[part_col] == \"trn\"].values\n",
    "    df.loc[ids_trn, f\"best_{m}\"] = \"trn\"\n",
    "    ids_val = df_pred.index[df_pred[part_col] == \"val\"].values\n",
    "    df.loc[ids_val, f\"best_{m}\"] = \"val\"\n",
    "\n",
    "df.to_excel(f\"{path}/data_final1.xlsx\", index_label=\"index\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 6. Inference ckecking and yakutia thresholding"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "part_check = \"tst_ctrl_yakutia\"\n",
    "part_check_thld_mean = 99999\n",
    "\n",
    "df = pd.read_excel(f\"{path}/data_final.xlsx\", index_col=0)\n",
    "samples_test = df.index[df[\"Split\"] == part_check].values\n",
    "\n",
    "models_all = [\n",
    "    \"elastic_net\",\n",
    "    \"xgboost\",\n",
    "    \"lightgbm\",\n",
    "    \"catboost\",\n",
    "    \"widedeep_tab_mlp\",\n",
    "    \"nam\",\n",
    "    \"nbm_spam_nam\",\n",
    "    \"pytorch_tabular_node\",\n",
    "    \"danet\",\n",
    "    \"widedeep_tab_net\",\n",
    "    \"pytorch_tabular_autoint\",\n",
    "    \"widedeep_saint\",\n",
    "    \"widedeep_ft_transformer\"\n",
    "]\n",
    "\n",
    "models_main = [\n",
    "    \"danet\",\n",
    "    \"widedeep_saint\",\n",
    "    \"widedeep_ft_transformer\"\n",
    "]\n",
    "\n",
    "path_models = f\"{path}/models/46_inference\"\n",
    "\n",
    "df_res = pd.DataFrame(index=models_all)\n",
    "df_samples_test = pd.DataFrame(index=samples_test, columns=models_all)\n",
    "\n",
    "for m in models_all:\n",
    "    file_val = glob(f\"{path_models}/{m}_inference/runs/*/metrics_val.xlsx\")[0]\n",
    "    df_res_val = pd.read_excel(file_val, index_col=0)\n",
    "    df_res.at[m, 'val_mae'] = df_res_val.at['mean_absolute_error', 'val']\n",
    "    df_res.at[m, 'val_rho'] = df_res_val.at['pearson_corr_coef', 'val']\n",
    "\n",
    "    file_tst_central = glob(f\"{path_models}/{m}_inference/runs/*/metrics_tst_ctrl_central.xlsx\")[0]\n",
    "    df_res_tst_central = pd.read_excel(file_tst_central, index_col=0)\n",
    "    df_res.at[m, 'tst_central_mae'] = df_res_tst_central.at['mean_absolute_error', 'tst_ctrl_central']\n",
    "    df_res.at[m, 'tst_central_rho'] = df_res_tst_central.at['pearson_corr_coef', 'tst_ctrl_central']\n",
    "\n",
    "    file_val = glob(f\"{path_models}/{m}_inference/runs/*/metrics_tst_esrd.xlsx\")[0]\n",
    "    df_res_val = pd.read_excel(file_val, index_col=0)\n",
    "    df_res.at[m, 'tst_esrd_mae'] = df_res_val.at['mean_absolute_error', 'tst_esrd']\n",
    "    df_res.at[m, 'tst_esrd_rho'] = df_res_val.at['pearson_corr_coef', 'tst_esrd']\n",
    "\n",
    "    file_pred = glob(f\"{path_models}/{m}_inference/runs/*/df.xlsx\")[0]\n",
    "    df_pred = pd.read_excel(file_pred, index_col=0)\n",
    "    df_pred = df_pred.loc[df_pred[f\"best_{m}\"] == part_check, :]\n",
    "    df_pred.sort_values([\"Prediction error abs\"], ascending=[True], inplace=True)\n",
    "    df_pred[\"MeanAbsErrorExpanding\"] = df_pred[\"Prediction error abs\"].expanding().mean()\n",
    "    samples_passed = df_pred.index[df_pred[\"MeanAbsErrorExpanding\"] < part_check_thld_mean].values\n",
    "    df_samples_test.loc[:, m] = 0\n",
    "    df_samples_test.loc[samples_passed, m] = 1\n",
    "    n_samples_passed = len(samples_passed)\n",
    "    print(f\"{m}: {n_samples_passed}\")\n",
    "\n",
    "df_samples_test.to_excel(f\"{path_models}/samples_test_full.xlsx\", index_label=\"model\")\n",
    "\n",
    "conditions = [df_samples_test[m] == 1 for m in models_main]\n",
    "df_samples_test = df_samples_test[conjunction(conditions)]\n",
    "samples_test_final = df_samples_test.index.values\n",
    "print(len(samples_test_final))\n",
    "\n",
    "for m in models_all:\n",
    "    file_pred = glob(f\"{path_models}/{m}_inference/runs/*/df.xlsx\")[0]\n",
    "    df_pred = pd.read_excel(file_pred, index_col=0)\n",
    "    df_pred = df_pred.loc[samples_test_final, :]\n",
    "    y_real = df_pred[\"Age\"]\n",
    "    y_pred = df_pred[\"Prediction\"]\n",
    "    mae_tst = mean_absolute_error(y_real, y_pred)\n",
    "    rho_tst = stats.pearsonr(y_real, y_pred).statistic\n",
    "    df_res.at[m, 'tst_yakutia_mae'] = mae_tst\n",
    "    df_res.at[m, 'tst_yakutia_rho'] = rho_tst\n",
    "\n",
    "df_res.to_excel(f\"{path_models}/baseline_results_{part_check_thld_mean}.xlsx\", index_label=\"model\")\n",
    "df_samples_test.to_excel(f\"{path_models}/samples_test_slctd_{part_check_thld_mean}.xlsx\", index_label=\"model\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 7. Feature selection and dimensionality reduction via SHAP"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_excel(f\"{path}/data_final.xlsx\", index_col=0)\n",
    "df_trn_val = df.loc[df[\"Split\"] == \"trn_val\", :]\n",
    "feats = pd.read_excel(f\"{path}/feats_con.xlsx\", index_col=0).index.values\n",
    "path_models = f\"{path}/models/46_shap\"\n",
    "\n",
    "models = {\n",
    "    \"danet\": \"DANet\",\n",
    "    \"widedeep_tab_net\": \"TabNet\",\n",
    "    \"widedeep_saint\": \"SAINT\",\n",
    "    \"widedeep_ft_transformer\": \"FT-Transformer\"\n",
    "}\n",
    "\n",
    "df_fi = pd.DataFrame(index=feats)\n",
    "\n",
    "for m in models:\n",
    "    file_shap = glob(f\"{path_models}/{m}_inference/runs/*/shap/trn_val/shap.xlsx\")[0]\n",
    "    df_shap = pd.read_excel(file_shap, index_col=0)\n",
    "\n",
    "    for f in feats:\n",
    "        df_fi.at[f, models[m]] = df_shap[f].abs().mean()\n",
    "\n",
    "df_fi['Summary'] = df_fi.sum(axis=1)\n",
    "df_fi.sort_values(['Summary'], ascending=[False], inplace=True)\n",
    "df_fi.to_excel(f\"{path_models}/A.xlsx\", index_label=\"features\")\n",
    "\n",
    "feats_top10 = df_fi.index.values[0:10]\n",
    "df_fig = df_fi.loc[:, list(models.values())]\n",
    "\n",
    "sns.set_theme(style='ticks', font_scale=3)\n",
    "df_fig.plot(kind='bar', stacked=True, color=px.colors.qualitative.D3, figsize=(34, 10), edgecolor='black')\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Mean(|SHAP values|)')\n",
    "sns.despine(left=False, right=True, bottom=False, top=True)\n",
    "plt.savefig(f\"{path_models}/fi.png\", bbox_inches='tight', dpi=400)\n",
    "plt.savefig(f\"{path_models}/fi.pdf\", bbox_inches='tight')\n",
    "\n",
    "pw.overwrite_axisgrid()\n",
    "sns.set_theme(style='ticks', font_scale=3)\n",
    "ax1 = pw.Brick(figsize=(30, 10))\n",
    "tmp = df_fig.plot(kind='bar', stacked=True, color=px.colors.qualitative.D3, ax=ax1, edgecolor='black')\n",
    "sns.despine(left=False, right=True, bottom=False, top=True, ax=ax1)\n",
    "ax1.set_xlabel('')\n",
    "ax1.set_ylabel('Mean(|SHAP values|)')\n",
    "ax1.text(-4, 45,'A', fontsize=72)\n",
    "ax1.text(-4, -15,'B', fontsize=72)\n",
    "feats_plot = [\"Age\"] + list(feats_top10)\n",
    "sns.set_theme(style=\"ticks\", font_scale=2.0)\n",
    "g1 = sns.PairGrid(df_trn_val, vars=feats_plot)\n",
    "g1.map_diag(plt.hist, bins=15, color='darkred', edgecolor='k')\n",
    "g1.map_upper(sns.scatterplot, color='darkred', s=10, alpha=0.5, edgecolor='k', linewidth=0.2)\n",
    "g1.map_lower(sns.kdeplot, fill=True, cbar=False, cmap='rocket_r', thresh=-0.1)\n",
    "g1.add_legend()\n",
    "for ax in g1.axes.flatten():\n",
    "    ax.get_yaxis().set_label_coords(-0.5, 0.5)\n",
    "ax2 = pw.load_seaborngrid(g1, figsize=(30, 30))\n",
    "(ax1/ax2).savefig(f\"{path_models}/together.pdf\", bbox_inches='tight')\n",
    "(ax1/ax2).savefig(f\"{path_models}/together.png\", bbox_inches='tight', dpi=400)\n",
    "df_save = df_trn_val.loc[:, feats_plot]\n",
    "df_save.to_excel(f\"{path_models}/B.xlsx\", index_label='index')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 8. trn/val split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 8.1 Check trn/val identity"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pathlib.Path(f\"{path}/figure_splits\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df = pd.read_excel(f\"{path}/data_final.xlsx\", index_col=0)\n",
    "samples_trn_val = df.index[df[\"Split\"] == \"trn_val\"].values\n",
    "\n",
    "models_all = [\n",
    "    \"elastic_net\",\n",
    "    \"xgboost\",\n",
    "    \"lightgbm\",\n",
    "    \"catboost\",\n",
    "    \"widedeep_tab_mlp\",\n",
    "    \"nam\",\n",
    "    \"nbm_spam_nam\",\n",
    "    \"pytorch_tabular_node\",\n",
    "    \"danet\",\n",
    "    \"widedeep_tab_net\",\n",
    "    \"pytorch_tabular_autoint\",\n",
    "    \"widedeep_saint\",\n",
    "    \"widedeep_ft_transformer\"\n",
    "]\n",
    "\n",
    "path_models = f\"{path}/models/46_trn_val_tst\"\n",
    "\n",
    "df_folds = {f\"fold_{fold_idx:04d}\": pd.DataFrame(index=samples_trn_val) for fold_idx in range(5)}\n",
    "\n",
    "for m in models_all:\n",
    "    df[f\"best_{m}\"] = df[\"Split\"]\n",
    "\n",
    "    df_summary = pd.read_excel(f\"{path_models}/{m}_trn_val_tst/multiruns/summary.xlsx\", index_col=0)\n",
    "    files_slctd = df_summary.index[df_summary[\"selected\"] == True].values\n",
    "    if len(files_slctd) != 1:\n",
    "        raise ValueError(f\"{m} model selection error\")\n",
    "    file_slctd = files_slctd[0]\n",
    "    path_head, _ = os.path.split(file_slctd)\n",
    "\n",
    "    path_head = path_head.replace('models/46/', 'models/46_trn_val_tst/', 1)\n",
    "\n",
    "    df_cv_ids = pd.read_excel(f\"{path_head}/cv_ids.xlsx\", index_col=0)\n",
    "    for fold_idx in range(5):\n",
    "        df_folds[f\"fold_{fold_idx:04d}\"].loc[samples_trn_val, m] = df_cv_ids.loc[samples_trn_val, f\"fold_{fold_idx:04d}\"]\n",
    "\n",
    "for fold_idx in range(5):\n",
    "    df_folds[f\"fold_{fold_idx:04d}\"]['matching'] = df_folds[f\"fold_{fold_idx:04d}\"].eq(df_folds[f\"fold_{fold_idx:04d}\"].iloc[:, 0], axis=0).all(1)\n",
    "    df_folds[f\"fold_{fold_idx:04d}\"].to_excel(f\"{path}/figure_splits/fold_{fold_idx:04d}.xlsx\", index_label=\"index\")\n",
    "    n_matches = df_folds[f\"fold_{fold_idx:04d}\"].index[df_folds[f\"fold_{fold_idx:04d}\"]['matching'] == True].values.shape[0]\n",
    "    print(n_matches)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 8.2 Plot split histograms"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pathlib.Path(f\"{path}/figure_splits\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df = pd.read_excel(f\"{path}/data_final.xlsx\", index_col=0)\n",
    "samples_trn_val = df.index[df[\"Split\"] == \"trn_val\"].values\n",
    "df[\"split_id\"] = 0\n",
    "\n",
    "model = \"danet\"\n",
    "\n",
    "path_models = f\"{path}/models/46_trn_val_tst\"\n",
    "\n",
    "df_folds = {f\"fold_{fold_idx:04d}\": pd.DataFrame(index=samples_trn_val) for fold_idx in range(5)}\n",
    "\n",
    "for m in models_all:\n",
    "    df[f\"best_{m}\"] = df[\"Split\"]\n",
    "\n",
    "    df_summary = pd.read_excel(f\"{path_models}/{m}_trn_val_tst/multiruns/summary.xlsx\", index_col=0)\n",
    "    files_slctd = df_summary.index[df_summary[\"selected\"] == True].values\n",
    "    if len(files_slctd) != 1:\n",
    "        raise ValueError(f\"{m} model selection error\")\n",
    "    file_slctd = files_slctd[0]\n",
    "    path_head, _ = os.path.split(file_slctd)\n",
    "\n",
    "    path_head = path_head.replace('models/46/', 'models/46_trn_val_tst/', 1)\n",
    "\n",
    "    df_cv_ids = pd.read_excel(f\"{path_head}/cv_ids.xlsx\", index_col=0)\n",
    "    for fold_idx in range(5):\n",
    "        val_ids = df_cv_ids.index[df_cv_ids[f\"fold_{fold_idx:04d}\"] == \"val\"].values\n",
    "        df.loc[val_ids, \"split_id\"] = fold_idx + 1\n",
    "\n",
    "df_fig = df.loc[samples_trn_val, [\"Age\", \"split_id\"]].copy()\n",
    "df_fig.rename(columns={'split_id': 'Split'}, inplace=True)\n",
    "df_fig.to_excel(f\"{path}/figure_splits/df_fig.xlsx\", index_label=\"index\")\n",
    "\n",
    "hist_bins = np.linspace(0, 110, 12)\n",
    "\n",
    "palette = {x: px.colors.qualitative.Plotly[x+4] for x in range(1, 6)}\n",
    "\n",
    "fig = plt.figure()\n",
    "sns.set_theme(style='ticks', font_scale=1.3)\n",
    "hist = sns.histplot(\n",
    "    data=df_fig,\n",
    "    hue_order=list(range(1, 6))[::-1],\n",
    "    bins=hist_bins,\n",
    "    x=\"Age\",\n",
    "    hue=\"Split\",\n",
    "    edgecolor='black',\n",
    "    palette=palette,\n",
    "    multiple=\"stack\",\n",
    ")\n",
    "hist.set(xlim=(0, 110))\n",
    "sns.despine(left=False, right=True, bottom=False, top=True)\n",
    "plt.savefig(f\"{path}/figure_splits/hist.png\", bbox_inches='tight', dpi=400)\n",
    "plt.savefig(f\"{path}/figure_splits/hist.pdf\", bbox_inches='tight')\n",
    "plt.close(fig)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 9. SimAge plots"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pathlib.Path(f\"{path}/figure_simage\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "palette = {\n",
    "    \"Train\": 'chartreuse',\n",
    "    \"Validation\": 'cornflowerblue',\n",
    "    \"Test Controls\": \"orange\",\n",
    "    \"Test ESRD\": \"crimson\"\n",
    "}\n",
    "\n",
    "part_names = {\n",
    "    \"trn\": 'Train',\n",
    "    \"val\": 'Validation',\n",
    "    \"tst_ctrl_central\": \"Test Controls\",\n",
    "    \"tst_esrd\": \"Test ESRD\"\n",
    "}\n",
    "\n",
    "df = pd.read_excel(f\"{path}/data_final.xlsx\", index_col=0)\n",
    "df_dead_alive = pd.read_excel(f\"{path}/origin/df_samples_dead_or_alive.xlsx\", index_col=0)\n",
    "df.loc[:, \"Dead_Alive\"] = \"Alive\"\n",
    "ids_dead = df_dead_alive.index[(df_dead_alive[\"Status\"] == \"ESRD\") & (df_dead_alive[\"Dead_Alive\"] == \"Dead\")].values\n",
    "df.loc[ids_dead, \"Dead_Alive\"] = \"Dead\"\n",
    "\n",
    "feats = pd.read_excel(f\"{path}/feats_con.xlsx\", index_col=0).index.values\n",
    "df = df.loc[:, list(feats) + [\"Age\", \"Sex\", \"Status\", \"Dead_Alive\"]]\n",
    "\n",
    "df_pred = pd.read_excel(f\"{path}/models/10_trn_val_tst/widedeep_ft_transformer_trn_val_tst/multiruns/2023-05-07_19-40-40_1337/64/predictions.xlsx\", index_col=0)\n",
    "df_pred[\"Age acceleration\"] = df_pred[\"Prediction\"] - df_pred[\"Age\"]\n",
    "part_col = df_pred.columns[0]\n",
    "\n",
    "df.loc[df.index.values, \"Part\"] = df_pred.loc[df.index.values, part_col]\n",
    "df.loc[df.index.values, \"Prediction\"] = df_pred.loc[df.index.values, \"Prediction\"]\n",
    "df.loc[df.index.values, \"Age acceleration\"] = df_pred.loc[df.index.values, \"Age acceleration\"]\n",
    "#indexes_filtered = df.index[(df[\"Part\"].isin([\"trn\", \"val\", \"tst_ctrl_central\"])) | ((df[\"Part\"] == \"tst_esrd\") & (df[\"Dead_Alive\"] == \"Dead\") & (df[\"Age acceleration\"] > -30))].values\n",
    "indexes_filtered = df.index[(df[\"Part\"].isin([\"trn\", \"val\", \"tst_ctrl_central\"])) | ((df[\"Part\"] == \"tst_esrd\") & (df[\"Dead_Alive\"] == \"Dead\") & (df[\"Age acceleration\"] > -30)  & (df[\"Age acceleration\"] < 100))].values\n",
    "\n",
    "df_dead_alive = df.loc[df[\"Part\"] == \"tst_esrd\", :].copy()\n",
    "df_dead_alive = df_dead_alive.loc[(df_dead_alive[\"Age acceleration\"] < 100) & (df_dead_alive[\"Age acceleration\"] > -30), :]\n",
    "df_dead_alive.to_excel(f\"{path}/figure_simage/dead_alive/df.xlsx\", index_label=\"index\")\n",
    "\n",
    "df = df.loc[indexes_filtered, :]\n",
    "df[\"Part\"].replace(part_names, inplace=True)\n",
    "df.rename(columns={\"Part\": \"Dataset\"}, inplace=True)\n",
    "\n",
    "plt.figure()\n",
    "sns.set_theme(style='ticks')\n",
    "xy_min = df[[\"Age\", 'Prediction']].min().min() - 7\n",
    "xy_max = df[[\"Age\", 'Prediction']].max().max()\n",
    "xy_ptp = xy_max - xy_min\n",
    "plt.gca().plot(\n",
    "    [xy_min - 0.1 * xy_ptp, xy_max + 0.1 * xy_ptp],\n",
    "    [xy_min - 0.1 * xy_ptp, xy_max + 0.1 * xy_ptp],\n",
    "    color='k',\n",
    "    linestyle='dotted',\n",
    "    linewidth=1\n",
    ")\n",
    "scatter = sns.scatterplot(\n",
    "    data=df,\n",
    "    x=\"Age\",\n",
    "    y=\"Prediction\",\n",
    "    hue=\"Dataset\",\n",
    "    palette=palette,\n",
    "    linewidth=0.2,\n",
    "    alpha=0.75,\n",
    "    edgecolor=\"k\",\n",
    "    s=16,\n",
    "    hue_order=list(palette.keys())\n",
    ")\n",
    "scatter.set_xlabel(\"Age\")\n",
    "scatter.set_ylabel(\"SImAge\")\n",
    "sns.despine(left=False, right=True, bottom=False, top=True)\n",
    "scatter.set_xlim(xy_min - 0.1 * xy_ptp, xy_max + 0.1 * xy_ptp)\n",
    "scatter.set_ylim(xy_min - 0.1 * xy_ptp, xy_max + 0.1 * xy_ptp)\n",
    "plt.gca().set_aspect('equal', adjustable='box')\n",
    "plt.savefig(f\"{path}/figure_simage/scatter.png\", bbox_inches='tight', dpi=400)\n",
    "plt.savefig(f\"{path}/figure_simage/scatter.pdf\", bbox_inches='tight')\n",
    "plt.close()\n",
    "df.to_excel(f\"{path}/figure_simage/df.xlsx\", index_label=\"index\")\n",
    "\n",
    "plt.figure()\n",
    "sns.set_theme(style='ticks')\n",
    "violin = sns.violinplot(\n",
    "    data=df,\n",
    "    x=\"Dataset\",\n",
    "    y='Age acceleration',\n",
    "    palette=palette,\n",
    "    scale='width',\n",
    "    order=list(palette.keys()),\n",
    "    saturation=0.75,\n",
    ")\n",
    "violin.set_xlabel(\"\")\n",
    "violin.set_ylabel(\"SImAge acceleration\")\n",
    "violin.axhline(0.00, color='k', linestyle=':', linewidth=0.5)\n",
    "sns.despine(left=False, right=True, bottom=False, top=True)\n",
    "pval = mannwhitneyu(\n",
    "    df.loc[df['Dataset'] == \"Test Controls\", 'Age acceleration'].values,\n",
    "    df.loc[df['Dataset'] == \"Test ESRD\", 'Age acceleration'].values,\n",
    "    alternative=\"two-sided\"\n",
    ").pvalue\n",
    "pval_formatted = [f'p-value: {pval:.2e}']\n",
    "annotator = Annotator(\n",
    "    violin,\n",
    "    pairs=[(\"Test Controls\", \"Test ESRD\")],\n",
    "    data=df,\n",
    "    x='Dataset',\n",
    "    y='Age acceleration',\n",
    "    order=list(palette.keys())\n",
    ")\n",
    "annotator.set_custom_annotations(pval_formatted)\n",
    "annotator.configure(loc='outside')\n",
    "annotator.annotate()\n",
    "plt.savefig(f\"{path}/figure_simage/violin.png\", bbox_inches='tight', dpi=400)\n",
    "plt.savefig(f\"{path}/figure_simage/violin.pdf\", bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "palette_dead_alive = {\"Alive\": \"olive\", \"Dead\": \"crimson\"}\n",
    "plt.figure()\n",
    "sns.set_theme(style='ticks')\n",
    "violin = sns.violinplot(\n",
    "    data=df_dead_alive,\n",
    "    x=\"Dead_Alive\",\n",
    "    y='Age acceleration',\n",
    "    scale='width',\n",
    "    saturation=0.75,\n",
    "    palette=palette_dead_alive,\n",
    "    order=(\"Alive\", \"Dead\"),\n",
    ")\n",
    "violin.axhline(0.00, color='k', linestyle=':', linewidth=1)\n",
    "violin.set_xlabel(\"\")\n",
    "violin.set_ylabel(\"SImAge acceleration\")\n",
    "sns.despine(left=False, right=True, bottom=False, top=True)\n",
    "pval = mannwhitneyu(\n",
    "    df_dead_alive.loc[df_dead_alive['Dead_Alive'] == \"Alive\", 'Age acceleration'].values,\n",
    "    df_dead_alive.loc[df_dead_alive['Dead_Alive'] == \"Dead\", 'Age acceleration'].values,\n",
    "    alternative=\"two-sided\"\n",
    ").pvalue\n",
    "pval_formatted = [f'p-value: {pval:.2e}']\n",
    "annotator = Annotator(\n",
    "    violin,\n",
    "    pairs=[(\"Alive\", \"Dead\")],\n",
    "    data=df_dead_alive,\n",
    "    x='Dead_Alive',\n",
    "    y='Age acceleration',\n",
    "    order=(\"Alive\", \"Dead\")\n",
    ")\n",
    "annotator.set_custom_annotations(pval_formatted)\n",
    "annotator.configure(loc='outside')\n",
    "annotator.annotate()\n",
    "plt.savefig(f\"{path}/figure_simage/dead_alive/violin_global.png\", bbox_inches='tight', dpi=400)\n",
    "plt.savefig(f\"{path}/figure_simage/dead_alive/violin_global.pdf\", bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "hist_bins = np.linspace(0, 110, 12)\n",
    "plt.figure()\n",
    "sns.set_theme(style='ticks')\n",
    "hist = sns.histplot(\n",
    "    data=df_dead_alive,\n",
    "    x=f\"Age\",\n",
    "    bins=hist_bins,\n",
    "    edgecolor='k',\n",
    "    linewidth=1,\n",
    "    hue_order=list(palette_dead_alive.keys()),\n",
    "    hue=\"Dead_Alive\",\n",
    "    palette=palette_dead_alive,\n",
    "    multiple=\"stack\",\n",
    ")\n",
    "sns.despine(left=False, right=True, bottom=False, top=True)\n",
    "plt.savefig(f\"{path}/figure_simage/dead_alive/hist.png\", bbox_inches='tight', dpi=400)\n",
    "plt.savefig(f\"{path}/figure_simage/dead_alive/hist.pdf\", bbox_inches='tight')\n",
    "plt.clf()\n",
    "\n",
    "plt.figure()\n",
    "df_dead_alive_old = df_dead_alive.loc[df_dead_alive[\"Age\"] > 60, :]\n",
    "df_dead_alive_old.to_excel(f\"{path}/figure_simage/dead_alive/df_old.xlsx\", index_label=\"index\")\n",
    "sns.set_theme(style='ticks')\n",
    "violin = sns.violinplot(\n",
    "    data=df_dead_alive_old,\n",
    "    x=\"Dead_Alive\",\n",
    "    y='Age acceleration',\n",
    "    scale='width',\n",
    "    saturation=0.75,\n",
    "    palette=palette_dead_alive,\n",
    "    order=(\"Alive\", \"Dead\"),\n",
    ")\n",
    "violin.set_xlabel(\"\")\n",
    "violin.axhline(0.00, color='k', linestyle=':', linewidth=1)\n",
    "violin.set_ylabel(\"SImAge acceleration\")\n",
    "sns.despine(left=False, right=True, bottom=False, top=True)\n",
    "pval = mannwhitneyu(\n",
    "    df_dead_alive_old.loc[df_dead_alive_old['Dead_Alive'] == \"Alive\", 'Age acceleration'].values,\n",
    "    df_dead_alive_old.loc[df_dead_alive_old['Dead_Alive'] == \"Dead\", 'Age acceleration'].values,\n",
    "    alternative=\"two-sided\"\n",
    ").pvalue\n",
    "pval_formatted = [f'p-value: {pval:.2e}']\n",
    "annotator = Annotator(\n",
    "    violin,\n",
    "    pairs=[(\"Alive\", \"Dead\")],\n",
    "    data=df_dead_alive_old,\n",
    "    x='Dead_Alive',\n",
    "    y='Age acceleration',\n",
    "    order=(\"Alive\", \"Dead\")\n",
    ")\n",
    "annotator.set_custom_annotations(pval_formatted)\n",
    "annotator.configure(loc='outside')\n",
    "annotator.annotate()\n",
    "plt.savefig(f\"{path}/figure_simage/dead_alive/violin_old.png\", bbox_inches='tight', dpi=400)\n",
    "plt.savefig(f\"{path}/figure_simage/dead_alive/violin_old.pdf\", bbox_inches='tight')\n",
    "plt.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 10. SImAge SHAP plots"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pathlib.Path(f\"{path}/figure_shap\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "ids_local = {\n",
    "    \"A3\": \"A\",\n",
    "    \"L40\": \"B\",\n",
    "    \"166\": \"C\",\n",
    "    \"F2b-F1b-L1/L2\": \"D\",\n",
    "    \"H24\": \"E\",\n",
    "    \"H69\": \"F\",\n",
    "}\n",
    "\n",
    "df = pd.read_excel(f\"{path}/figure_simage/df.xlsx\", index_col=0)\n",
    "df[\"AbsError\"] = df[\"Age acceleration\"].abs()\n",
    "mae = 6.94\n",
    "ids_esrd = df.index[df[\"Status\"] == \"ESRD\"].values\n",
    "print(len(ids_esrd))\n",
    "ids_lft = df.index[(df[\"Status\"] == \"Control\") & (df[\"Age acceleration\"] < -mae)].values\n",
    "print(len(ids_lft))\n",
    "ids_ctr = df.index[(df[\"Status\"] == \"Control\") & (df[\"Age acceleration\"] < mae) & (df[\"Age acceleration\"] > -mae)].values\n",
    "print(len(ids_ctr))\n",
    "ids_rgt = df.index[(df[\"Status\"] == \"Control\") & (df[\"Age acceleration\"] > mae)].values\n",
    "print(len(ids_rgt))\n",
    "\n",
    "df[\"Part\"] = \"\"\n",
    "df.loc[ids_lft, \"Part\"] = \"Controls:  Acc < -MAE\"\n",
    "df.loc[ids_ctr, \"Part\"] = \"Controls: |Acc| < MAE\"\n",
    "df.loc[ids_rgt, \"Part\"] = \"Controls:  Acc > MAE\"\n",
    "df.loc[ids_esrd, \"Part\"] = \"ESRD\"\n",
    "\n",
    "parts = {\n",
    "    \"ESRD\": ids_esrd,\n",
    "    \"Controls:  Acc < -MAE\": ids_lft,\n",
    "    \"Controls: |Acc| < MAE\": ids_ctr,\n",
    "    \"Controls:  Acc > MAE\": ids_rgt,\n",
    "}\n",
    "\n",
    "palette = {\n",
    "    \"ESRD\": \"crimson\",\n",
    "    \"Controls:  Acc < -MAE\": 'cyan',\n",
    "    \"Controls: |Acc| < MAE\": 'lime',\n",
    "    \"Controls:  Acc > MAE\": \"gold\",\n",
    "}\n",
    "hue_order = list(palette.keys())[::-1],\n",
    "\n",
    "n_bins_ctr = 5\n",
    "binwidth = 2 * mae / (n_bins_ctr - 1)\n",
    "bins_to_lft = abs(df[\"Age acceleration\"].min()) // binwidth + 1\n",
    "hist_min = -binwidth * bins_to_lft\n",
    "bins_to_rgt = abs(df[\"Age acceleration\"].max()) // binwidth + 1\n",
    "hist_max = binwidth * bins_to_rgt\n",
    "hist_n_bins = bins_to_lft + bins_to_rgt\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "sns.set_theme(style='ticks')\n",
    "hist = sns.histplot(\n",
    "    data=df,\n",
    "    x=f\"Age acceleration\",\n",
    "    bins=hist_n_bins,\n",
    "    binrange=(hist_min, hist_max),\n",
    "    binwidth=binwidth,\n",
    "    edgecolor='k',\n",
    "    linewidth=1,\n",
    "    hue_order=list(palette.keys()),\n",
    "    hue=\"Part\",\n",
    "    palette=palette,\n",
    "    multiple=\"stack\",\n",
    ")\n",
    "sns.despine(left=False, right=True, bottom=False, top=True)\n",
    "plt.savefig(f\"{path}/figure_shap/hist.png\", bbox_inches='tight', dpi=400)\n",
    "plt.savefig(f\"{path}/figure_shap/hist.pdf\", bbox_inches='tight')\n",
    "plt.clf()\n",
    "df_fig = df.loc[:, [\"Age\", \"Prediction\", \"Age acceleration\"]].copy()\n",
    "df_fig.to_excel(f\"{path}/figure_shap/hist.xlsx\", index_label=\"index\")\n",
    "\n",
    "path_shap = f\"{path}/models/10_shap/widedeep_ft_transformer_inference/runs/2023-05-08_15-51-52/shap/all\"\n",
    "df_shap = pd.read_excel(f\"{path_shap}/shap.xlsx\", index_col=0)\n",
    "expval = pd.read_excel(f\"{path_shap}/expected_value.xlsx\", index_col=0).iloc[0,0]\n",
    "feats = df_shap.columns.values\n",
    "\n",
    "for f in feats:\n",
    "    plt.figure()\n",
    "    sns.set_theme(style='ticks')\n",
    "    scatter = sns.scatterplot(\n",
    "        data=df,\n",
    "        x=\"Age\",\n",
    "        y=f,\n",
    "        hue=\"Part\",\n",
    "        palette=palette,\n",
    "        linewidth=0.2,\n",
    "        alpha=0.75,\n",
    "        edgecolor=\"k\",\n",
    "        s=16,\n",
    "        hue_order=list(palette.keys())\n",
    "    )\n",
    "    sns.despine(left=False, right=True, bottom=False, top=True)\n",
    "    plt.savefig(f\"{path}/figure_shap/feats/{f}.png\", bbox_inches='tight', dpi=400)\n",
    "    plt.savefig(f\"{path}/figure_shap/feats/{f}.pdf\", bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "df_fi = pd.DataFrame(index=feats, columns=list(parts.keys()))\n",
    "for p in parts:\n",
    "    shap.summary_plot(\n",
    "        shap_values=df_shap.loc[parts[p], feats].values,\n",
    "        features=df.loc[parts[p], feats].values,\n",
    "        feature_names=feats,\n",
    "        max_display=len(feats),\n",
    "        plot_type=\"violin\",\n",
    "        show=False,\n",
    "    )\n",
    "    plt.savefig(f\"{path}/figure_shap/violin_{palette[p]}.png\", bbox_inches='tight', dpi=400)\n",
    "    plt.savefig(f\"{path}/figure_shap/violin_{palette[p]}.pdf\", bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    for f in feats:\n",
    "        df_fi.at[f, p] = np.mean(np.abs(df_shap.loc[parts[p], f].values))\n",
    "    df_fi.sort_values([p], ascending=[False], inplace=True)\n",
    "    df_fig = df_fi.loc[:, [p]].copy()\n",
    "    df_fig.rename(columns={p: \"Mean(|SHAP values|)\"}, inplace=True)\n",
    "\n",
    "    plt.figure(figsize=(2, 4))\n",
    "    sns.set_theme(style='ticks', font_scale=1)\n",
    "    bar = sns.barplot(\n",
    "        data=df_fig,\n",
    "        y=df_fig.index,\n",
    "        x=\"Mean(|SHAP values|)\",\n",
    "        edgecolor='black',\n",
    "        orient=\"h\",\n",
    "        dodge=False,\n",
    "        color=palette[p],\n",
    "    )\n",
    "    bar.set_xlabel(\"Mean(|SHAP values|)\")\n",
    "    bar.set_ylabel(\"\")\n",
    "    sns.despine(left=False, right=True, bottom=False, top=True)\n",
    "    plt.savefig(f\"{path}/figure_shap/bar_{palette[p]}.png\", bbox_inches='tight', dpi=400)\n",
    "    plt.savefig(f\"{path}/figure_shap/bar_{palette[p]}.pdf\", bbox_inches='tight')\n",
    "    plt.close()\n",
    "df_fi.to_excel(f\"{path}/figure_shap/fi.xlsx\", index_label=\"features\")\n",
    "\n",
    "for idl in ids_local:\n",
    "    real = df.at[idl, \"Age\"]\n",
    "    pred = df.at[idl, \"Prediction\"]\n",
    "    diff = df.at[idl, \"Age acceleration\"]\n",
    "\n",
    "    id_save = idl\n",
    "    if isinstance(idl, str):\n",
    "        id_save = slugify(idl)\n",
    "\n",
    "    shap.plots.waterfall(\n",
    "        shap.Explanation(\n",
    "            values=df_shap.loc[idl, feats].values,\n",
    "            base_values=expval,\n",
    "            data=df.loc[idl, feats].values,\n",
    "            feature_names=feats\n",
    "        ),\n",
    "        max_display=10,\n",
    "        show=False,\n",
    "    )\n",
    "    fig = plt.gcf()\n",
    "    fig.text(0.01, 0.99, f\"Age = {real:0.2f}\", fontsize=20)\n",
    "    fig.text(0.01, 0.94, f\"SImAge = {pred:0.2f}\", fontsize=20)\n",
    "    fig.text(-0.1, 0.96, ids_local[idl], fontsize=40)\n",
    "    fig.savefig(f\"{path}/figure_shap/local/{id_save}.pdf\", bbox_inches='tight')\n",
    "    fig.savefig(f\"{path}/figure_shap/local/{id_save}.png\", bbox_inches='tight')\n",
    "    plt.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 11. Data description"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hist"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pathlib.Path(f\"{path}/figure_data_desc\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "palette = {\n",
    "    \"Train/Validation\": 'cyan',\n",
    "    \"Test Controls\": \"orange\",\n",
    "    \"Test ESRD\": \"crimson\"\n",
    "}\n",
    "\n",
    "df = pd.read_excel(f\"{path}/figure_simage/df.xlsx\", index_col=0)\n",
    "df.loc[df[\"Dataset\"].isin([\"Train\", \"Validation\"]), \"Dataset\"] = \"Train/Validation\"\n",
    "\n",
    "hist_bins = np.linspace(10, 110, 11)\n",
    "fig = plt.figure()\n",
    "sns.set_theme(style='ticks', font_scale=1.0)\n",
    "hist = sns.histplot(\n",
    "    data=df,\n",
    "    bins=hist_bins,\n",
    "    x=\"Age\",\n",
    "    hue=\"Dataset\",\n",
    "    edgecolor='black',\n",
    "    palette=palette,\n",
    "    multiple=\"stack\",\n",
    "    linewidth=1,\n",
    "    hue_order=list(palette.keys())[::-1],\n",
    ")\n",
    "hist.set(xlim=(5, 115))\n",
    "sns.despine(left=False, right=True, bottom=False, top=True)\n",
    "plt.savefig(f\"{path}/figure_data_desc/hist.png\", bbox_inches='tight', dpi=400)\n",
    "plt.savefig(f\"{path}/figure_data_desc/hist.pdf\", bbox_inches='tight')\n",
    "plt.close(fig)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Matrix"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pathlib.Path(f\"{path}/figure_data_desc\").mkdir(parents=True, exist_ok=True)\n",
    "df = pd.read_excel(f\"{path}/figure_simage/df.xlsx\", index_col=0)\n",
    "df = df.loc[df['Status'] == 'Control', :]\n",
    "feats = pd.read_excel(f\"{path}/feats_con.xlsx\", index_col=0).index.values\n",
    "feats = [\"Age\"] + list(feats)\n",
    "\n",
    "df_corr = pd.DataFrame(data=np.zeros(shape=(len(feats), len(feats))), index=feats, columns=feats)\n",
    "for f_id_1 in range(len(feats)):\n",
    "    for f_id_2 in range(f_id_1, len(feats)):\n",
    "        f_1 = feats[f_id_1]\n",
    "        f_2 = feats[f_id_2]\n",
    "        if f_id_1 != f_id_2:\n",
    "            vals_1 = df.loc[:, f_1].values\n",
    "            vals_2 = df.loc[:, f_2].values\n",
    "            corr, pval = stats.pearsonr(vals_1, vals_2)\n",
    "            df_corr.at[f_2, f_1] = pval\n",
    "            df_corr.at[f_1, f_2] = corr\n",
    "        else:\n",
    "            df_corr.at[f_2, f_1] = np.nan\n",
    "selection = np.tri(df_corr.shape[0], df_corr.shape[1], -1, dtype=np.bool)\n",
    "df_fdr = df_corr.where(selection).stack().reset_index()\n",
    "df_fdr.columns = ['row', 'col', 'pval']\n",
    "_, df_fdr['pval_fdr_bh'], _, _ = multipletests(df_fdr.loc[:, 'pval'].values, 0.05, method='fdr_bh')\n",
    "df_corr_fdr = df_corr.copy()\n",
    "for line_id in range(df_fdr.shape[0]):\n",
    "    df_corr_fdr.loc[df_fdr.at[line_id, 'row'], df_fdr.at[line_id, 'col']] = -np.log10(df_fdr.at[line_id, 'pval_fdr_bh'])\n",
    "\n",
    "sns.set_theme(style='whitegrid')\n",
    "df_to_plot = df_corr_fdr.copy()\n",
    "mtx_to_plot = df_to_plot.to_numpy()\n",
    "\n",
    "mtx_triu = np.triu(mtx_to_plot, +1)\n",
    "max_corr = np.max(mtx_triu)\n",
    "min_corr = np.min(mtx_triu)\n",
    "mtx_triu_mask = np.ma.masked_array(mtx_triu, mtx_triu==0)\n",
    "cmap_triu = plt.get_cmap(\"bwr\").copy()\n",
    "\n",
    "mtx_tril = np.tril(mtx_to_plot, -1)\n",
    "mtx_tril_mask = np.ma.masked_array(mtx_tril, mtx_tril==0)\n",
    "cmap_tril = plt.get_cmap(\"viridis\").copy()\n",
    "cmap_tril.set_under('black')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "im_triu = ax.imshow(mtx_triu_mask, cmap=cmap_triu, vmin=-1, vmax=1)\n",
    "cbar_triu = ax.figure.colorbar(im_triu, ax=ax, location='right', shrink=0.80)\n",
    "cbar_triu.ax.tick_params(labelsize=8)\n",
    "cbar_triu.set_label(r\"$\\mathrm{Correlation\\:coefficient}$\", horizontalalignment='center', fontsize=8)\n",
    "\n",
    "im_tril = ax.imshow(mtx_tril_mask, cmap=cmap_tril, vmin=-np.log10(0.05))\n",
    "cbar_tril = ax.figure.colorbar(im_tril, ax=ax, location='right', shrink=0.80)\n",
    "cbar_tril.ax.tick_params(labelsize=8)\n",
    "cbar_tril.set_label(r\"$-\\log_{10}(\\mathrm{p-value})$\", horizontalalignment='center', fontsize=8)\n",
    "\n",
    "ax.grid(None)\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.set_xticks(np.arange(df_to_plot.shape[1]))\n",
    "ax.set_yticks(np.arange(df_to_plot.shape[0]))\n",
    "ax.set_xticklabels(df_to_plot.columns.values)\n",
    "ax.set_yticklabels(df_to_plot.index.values)\n",
    "plt.setp(ax.get_xticklabels(), rotation=90)\n",
    "threshold = np.ptp(mtx_tril.flatten()) * 0.5\n",
    "ax.tick_params(axis='both', which='major', labelsize=5)\n",
    "ax.tick_params(axis='both', which='minor', labelsize=5)\n",
    "textcolors = (\"black\", \"white\")\n",
    "for i in range(df_to_plot.shape[0]):\n",
    "    for j in range(df_to_plot.shape[1]):\n",
    "        color = \"black\"\n",
    "        if i > j:\n",
    "            color = textcolors[int(mtx_tril[i, j] < threshold)]\n",
    "        if np.isinf(mtx_to_plot[i, j]) or np.isnan(mtx_to_plot[i, j]):\n",
    "            text = ax.text(j, i, f\"\", ha=\"center\", va=\"center\", color=color, fontsize=1.4)\n",
    "        else:\n",
    "            text = ax.text(j, i, f\"{mtx_to_plot[i, j]:0.2f}\", ha=\"center\", va=\"center\", color=color, fontsize=1.4)\n",
    "fig.tight_layout()\n",
    "plt.savefig(f\"{path}/figure_data_desc/corr_mtx_fdr.png\", bbox_inches='tight', dpi=400)\n",
    "plt.savefig(f\"{path}/figure_data_desc/corr_mtx_fdr.pdf\", bbox_inches='tight', dpi=400)\n",
    "plt.clf()\n",
    "\n",
    "df_save = df_corr_fdr\n",
    "df_save.to_excel(f\"{path}/figure_data_desc/corr_mtx_fdr.xlsx\", index=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 12. Supplementary table MAE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pathlib.Path(f\"{path}/supp_table_mae\").mkdir(parents=True, exist_ok=True)\n",
    "df = pd.read_excel(f\"{path}/figure_simage/df.xlsx\", index_col=0)\n",
    "\n",
    "cond_group = {\n",
    "    \"Age < 30\": (df[\"Age\"] < 30),\n",
    "    \"30 <= Age < 50\": (df[\"Age\"] < 50) & (df[\"Age\"] >= 30),\n",
    "    \"50 <= Age < 70\": (df[\"Age\"] < 70) & (df[\"Age\"] >= 50),\n",
    "    \"Age > 70\": (df[\"Age\"] > 70),\n",
    "    \"Females\": (df[\"Sex\"] == \"F\"),\n",
    "    \"Males\": (df[\"Sex\"] == \"M\"),\n",
    "    \"All\": (df[\"Sex\"].isin(['M', 'F']))\n",
    "}\n",
    "\n",
    "cond_dataset = {\n",
    "    \"Train\": (df[\"Dataset\"] == \"Train\"),\n",
    "    \"Validation\": (df[\"Dataset\"] == \"Validation\"),\n",
    "    \"Test Controls\": (df[\"Dataset\"] == \"Test Controls\"),\n",
    "    \"Overall Controls\": (df[\"Dataset\"].isin(['Train', 'Validation', 'Test Controls'])),\n",
    "    \"ESRD\": (df[\"Dataset\"] == \"Test ESRD\"),\n",
    "}\n",
    "\n",
    "df_mae = pd.DataFrame(index=list(cond_group.keys()), columns=list(cond_dataset.keys()))\n",
    "for g_name, g_cond in cond_group.items():\n",
    "    for d_name, d_cond in cond_dataset.items():\n",
    "        df_local = df[conjunction([g_cond, d_cond])]\n",
    "        real = df_local.loc[:, \"Age\"]\n",
    "        pred = df_local.loc[:, \"Prediction\"]\n",
    "        mae = mean_absolute_error(real, pred)\n",
    "        df_mae.at[g_name, d_name] = mae\n",
    "\n",
    "df_mae.to_excel(f\"{path}/supp_table_mae/df_mae.xlsx\", index_label=\"Group\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 13. Supplementary table data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pathlib.Path(f\"{path}/supp_table_data\").mkdir(parents=True, exist_ok=True)\n",
    "df = pd.read_excel(f\"{path}/figure_simage/df.xlsx\", index_col=0)\n",
    "df['Dataset'].replace({'Train': 'Train/Validation', 'Validation': 'Train/Validation'}, inplace=True)\n",
    "df['new_index'] = 0\n",
    "parts = {\n",
    "    'Train/Validation': 'trn_val',\n",
    "    'Test Controls': 'tst_ctrl',\n",
    "    'Test ESRD': 'tst_esrd'\n",
    "}\n",
    "for part, p_name in parts.items():\n",
    "    for id_new, id_old in enumerate(df.index[df['Dataset'] == part].values):\n",
    "        df.at[id_old, 'new_index'] = f\"{p_name}_{id_new:03d}\"\n",
    "\n",
    "df_mapping = df.loc[:, [\"new_index\"]].copy()\n",
    "df_mapping.to_excel(f\"{path}/supp_table_data/df_mapping.xlsx\", index_label='old_index')\n",
    "\n",
    "df.set_index(\"new_index\", inplace=True)\n",
    "df.drop(columns=['Dead_Alive'], inplace=True)\n",
    "df.rename(columns={'Prediction': 'SImAge', 'Age acceleration': 'SImAge acceleration'}, inplace=True)\n",
    "df.to_excel(f\"{path}/supp_table_data/df.xlsx\", index_label='index')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
