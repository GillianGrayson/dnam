{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Debugging autoreload"
  },
  {
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Load packages"
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src.utils.outliers.iqr import add_iqr_outs_to_df, plot_iqr_outs, plot_iqr_outs_regression_error\n",
    "from src.utils.outliers.pyod import add_pyod_outs_to_df, plot_pyod_outs, plot_pyod_outs_regression_error\n",
    "from scripts.python.dataset_specific.GSEUNN.tasks.routines_046 import plot_regression_error_distributions\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy import stats\n",
    "import plotly.express as px\n",
    "from scripts.python.routines.plot.scatter import add_scatter_trace\n",
    "import plotly.graph_objects as go\n",
    "from scripts.python.routines.plot.save import save_figure\n",
    "from scripts.python.routines.plot.layout import add_layout, get_axis\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import plotly.io as pio\n",
    "import importlib\n",
    "pio.kaleido.scope.mathjax = None\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "from scipy.interpolate import interp1d\n",
    "from src.utils.verbose import NoStdStreams\n",
    "init_notebook_mode(connected=False)\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from omegaconf import OmegaConf\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "import pathlib\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.decomposition import MiniBatchDictionaryLearning, FastICA\n",
    "from sklearn.random_projection import GaussianRandomProjection, SparseRandomProjection\n",
    "from sklearn.manifold import MDS, Isomap\n",
    "from openTSNE import TSNE\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from scipy import stats\n",
    "import patchworklib as pw\n",
    "import os\n",
    "import functools\n",
    "from scipy.stats import iqr\n",
    "from statannotations.Annotator import Annotator\n",
    "from scipy.stats import mannwhitneyu\n",
    "import shap\n",
    "from slugify import slugify\n",
    "from src.models.tabular.widedeep.ft_transformer import WDFTTransformerModel\n",
    "from src.models.tabular.widedeep.tab_net import WDTabNetModel\n",
    "from art.estimators.regression.pytorch import PyTorchRegressor\n",
    "from art.estimators.classification import PyTorchClassifier\n",
    "from art.estimators.regression.blackbox import BlackBoxRegressor\n",
    "from art.attacks.evasion import ProjectedGradientDescentNumpy, FastGradientMethod, BasicIterativeMethod, MomentumIterativeMethod\n",
    "from art.attacks.evasion import ZooAttack, CarliniL2Method, ElasticNet, NewtonFool\n",
    "import torch\n",
    "from src.tasks.metrics import get_cls_pred_metrics, get_cls_prob_metrics, get_reg_metrics\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "from sdv.metadata import SingleTableMetadata\n",
    "from sdv.lite import SingleTablePreset\n",
    "from sdv.single_table import GaussianCopulaSynthesizer, CTGANSynthesizer, TVAESynthesizer, CopulaGANSynthesizer\n",
    "from sdv.evaluation.single_table import evaluate_quality\n",
    "from sdv.evaluation.single_table import get_column_plot\n",
    "from sdv.evaluation.single_table import get_column_pair_plot\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scripts.python.routines.mvals import expit2\n",
    "\n",
    "import missingno as msno\n",
    "\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "from pyod.models.ecod import ECOD\n",
    "from pyod.models.abod import ABOD\n",
    "from pyod.models.copod import COPOD\n",
    "from pyod.models.sos import SOS\n",
    "from pyod.models.kde import KDE\n",
    "from pyod.models.sampling import Sampling\n",
    "from pyod.models.gmm import GMM\n",
    "\n",
    "from pyod.models.kpca import KPCA\n",
    "from pyod.models.mcd import MCD\n",
    "from pyod.models.ocsvm import OCSVM\n",
    "from pyod.models.lmdd import LMDD\n",
    "\n",
    "from pyod.models.lof import LOF\n",
    "from pyod.models.cof import COF\n",
    "from pyod.models.cblof import CBLOF\n",
    "from pyod.models.hbos import HBOS\n",
    "from pyod.models.knn import KNN\n",
    "from pyod.models.sod import SOD\n",
    "\n",
    "from pyod.models.iforest import IForest\n",
    "from pyod.models.inne import INNE\n",
    "from pyod.models.loda import LODA\n",
    "from pyod.models.suod import SUOD\n",
    "\n",
    "from pyod.models.auto_encoder_torch import AutoEncoder\n",
    "from pyod.models.vae import VAE\n",
    "from pyod.models.deep_svdd import DeepSVDD\n",
    "\n",
    "from pyod.models.lunar import LUNAR\n",
    "\n",
    "from torchmetrics import BootStrapper\n",
    "\n",
    "\n",
    "from pytorch_tabular.utils import make_mixed_dataset, print_metrics\n",
    "from pytorch_tabular import available_models\n",
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.models import CategoryEmbeddingModelConfig, GANDALFConfig, TabNetModelConfig, FTTransformerConfig, DANetConfig, GatedAdditiveTreeEnsembleConfig\n",
    "from pytorch_tabular.config import DataConfig, OptimizerConfig, TrainerConfig\n",
    "from pytorch_tabular.models.common.heads import LinearHeadConfig\n",
    "from pytorch_tabular.tabular_model_tuner import TabularModelTuner\n",
    "from torchmetrics.functional.classification import (\n",
    "    multiclass_accuracy,\n",
    "    multiclass_f1_score,\n",
    "    multiclass_precision,\n",
    "    multiclass_recall,\n",
    "    multiclass_specificity,\n",
    "    multiclass_cohen_kappa,\n",
    "    multiclass_auroc\n",
    ")\n",
    "from pytorch_tabular import MODEL_SWEEP_PRESETS\n",
    "from pytorch_tabular import model_sweep\n",
    "import warnings\n",
    "\n",
    "\n",
    "def conjunction(conditions):\n",
    "    return functools.reduce(np.logical_and, conditions)\n",
    "\n",
    "\n",
    "def disjunction(conditions):\n",
    "    return functools.reduce(np.logical_or, conditions)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "# Load data and model, define PyTorchRegressor, setup colors, dimensionality reduction models",
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "path = \"D:/YandexDisk/Work/pydnameth/datasets/GPL21145/GSEUNN\"\n",
    "path_model = f\"{path}/data/immuno/models/SImAge\"\n",
    "path_save = f\"{path}/special/064_tai_report_4/immuno\"\n",
    "pathlib.Path(f\"{path_save}\").mkdir(parents=True, exist_ok=True)\n",
    "df = pd.read_excel(f\"{path}/data/immuno/models/SImAge/data.xlsx\", index_col='sample_id')\n",
    "feats = pd.read_excel(f\"{path}/data/immuno/models/SImAge/feats_con_top10.xlsx\", index_col=0).index.values\n",
    "ids_feat = list(range(len(feats)))\n",
    "col_trgt = 'Age'\n",
    "col_pred = 'SImAge'\n",
    "\n",
    "df_preds = pd.read_excel(f\"{path}/data/immuno/models/SImAge/results/predictions.xlsx\", index_col=0)\n",
    "ids_trn = df_preds.index[df_preds['fold_0002'] == 'trn'].values\n",
    "ids_val = df_preds.index[df_preds['fold_0002'] == 'val'].values\n",
    "ids_tst = df_preds.index[df_preds['fold_0002'] == 'tst_ctrl_central'].values\n",
    "ids_all = df_preds.index[df_preds['fold_0002'].isin(['trn', 'val', 'tst_ctrl_central'])].values\n",
    "ids_trn_val = df_preds.index[df_preds['fold_0002'].isin(['trn', 'val'])].values\n",
    "ids_dict = {\n",
    "    'all': ids_all,\n",
    "    'trn_val': ids_trn_val,\n",
    "    'tst': ids_tst\n",
    "}\n",
    "\n",
    "df = df.loc[ids_all, :]\n",
    "df[\"SImAge Error\"] = df[\"SImAge\"] - df[\"Age\"]\n",
    "df[\"|SImAge Error|\"] = df[\"SImAge Error\"].abs()\n",
    "df['Data'] = 'Real'\n",
    "df['Eps'] = 'Origin'\n",
    "\n",
    "model = WDFTTransformerModel.load_from_checkpoint(checkpoint_path=f\"{path}/data/immuno/models/SImAge/best_fold_0002.ckpt\")\n",
    "model.eval()\n",
    "model.freeze()\n",
    "\n",
    "def predict_func_regression(X):\n",
    "    model.produce_probabilities = True\n",
    "    batch = {\n",
    "        'all': torch.from_numpy(np.float32(X[:, ids_feat])),\n",
    "        'continuous': torch.from_numpy(np.float32(X[:, ids_feat])),\n",
    "        'categorical': torch.from_numpy(np.int32(X[:, []])),\n",
    "    }\n",
    "    tmp = model(batch)\n",
    "    return tmp.cpu().detach().numpy()\n",
    "\n",
    "art_regressor = PyTorchRegressor(\n",
    "    model=model,\n",
    "    loss=model.loss_fn,\n",
    "    input_shape=[len(feats)],\n",
    "    optimizer=torch.optim.Adam(\n",
    "        params=model.parameters(),\n",
    "        lr=model.hparams.optimizer_lr,\n",
    "        weight_decay=model.hparams.optimizer_weight_decay\n",
    "    ),\n",
    "    use_amp=False,\n",
    "    opt_level=\"O1\",\n",
    "    loss_scale=\"dynamic\",\n",
    "    channels_first=True,\n",
    "    clip_values=None,\n",
    "    preprocessing_defences=None,\n",
    "    postprocessing_defences=None,\n",
    "    preprocessing=(0.0, 1.0),\n",
    "    device_type=\"cpu\",\n",
    ")\n",
    "\n",
    "colors_atks = {\n",
    "    \"MomentumIterative\": px.colors.qualitative.D3[0],\n",
    "    \"BasicIterative\": px.colors.qualitative.D3[1],\n",
    "    \"FastGradient\": px.colors.qualitative.D3[3],\n",
    "}\n",
    "\n",
    "dim_red_labels = {\n",
    "    'PCA': ['PC 1', 'PC 2'],\n",
    "    'SVD': ['SVD 1', 'SVD 2'],\n",
    "    't-SNE': ['t-SNE 1', 't-SNE 2'],\n",
    "    'GRP': ['GRP 1', 'GRP 2'],\n",
    "    'SRP': ['SRP 1', 'SRP 2'],\n",
    "    'IsoMap': ['IsoMap 1', 'IsoMap 2'],\n",
    "    'MBDL': ['MBDL 1', 'MBDL 2'],\n",
    "}\n",
    "X_dim_red = df.loc[ids_trn_val, feats].values\n",
    "dim_red_models = {\n",
    "    'PCA': PCA(n_components=2, whiten=False).fit(X_dim_red),\n",
    "    'SVD': TruncatedSVD(n_components=2, algorithm='randomized', n_iter=5).fit(X_dim_red),\n",
    "    't-SNE': TSNE(n_components=2).fit(X_dim_red),\n",
    "    'GRP': GaussianRandomProjection(n_components=2, eps=0.5).fit(X_dim_red),\n",
    "    'SRP': SparseRandomProjection(n_components=2, density='auto', eps=0.5, dense_output=False).fit(X_dim_red),\n",
    "    'IsoMap': Isomap(n_components=2, n_neighbors=5).fit(X_dim_red),\n",
    "    'MBDL': MiniBatchDictionaryLearning(n_components=2, batch_size=100, alpha=1, n_iter=25).fit(X_dim_red),\n",
    "}\n",
    "for m, drm in dim_red_models.items():\n",
    "    dim_red_res = drm.transform(df.loc[:, feats].values)\n",
    "    df.loc[:, dim_red_labels[m][0]] = dim_red_res[:, 0]\n",
    "    df.loc[:, dim_red_labels[m][1]] = dim_red_res[:, 1]\n",
    "df.to_excel(f\"{path_save}/df_origin.xlsx\", index_label='sample_id')"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create PyOD models, trained on trn_val samples"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "contamination = 0.1\n",
    "\n",
    "pyod_methods = {\n",
    "    'ECOD': ECOD(contamination=contamination),\n",
    "    'LUNAR': LUNAR(),\n",
    "    'DeepSVDD': DeepSVDD(contamination=contamination, verbose=0),\n",
    "    'VAE': VAE(encoder_neurons=[32, 16, 8], decoder_neurons=[8, 16, 32], contamination=contamination),\n",
    "    'LODA': LODA(contamination=contamination),\n",
    "    'INNE': INNE(contamination=contamination),\n",
    "    'IForest': IForest(contamination=contamination),\n",
    "    'SOD': SOD(contamination=contamination),\n",
    "    'KNN': KNN(contamination=contamination),\n",
    "    'CBLOF': CBLOF(contamination=contamination),\n",
    "    'COF': COF(contamination=contamination),\n",
    "    'LOF': LOF(contamination=contamination),\n",
    "    'LMDD': LMDD(contamination=contamination),\n",
    "    'MCD': MCD(contamination=contamination),\n",
    "    'GMM': GMM(contamination=contamination),\n",
    "    'Sampling': Sampling(contamination=contamination),\n",
    "    'SOS': SOS(contamination=contamination),\n",
    "    'COPOD': COPOD(contamination=contamination),\n",
    "}\n",
    "\n",
    "for method_name, method in (pbar := tqdm(pyod_methods.items())):\n",
    "    pbar.set_description(f\"Processing {method_name}\")\n",
    "    \n",
    "    method.fit(df.loc[ids_trn_val, feats].values)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Apply and save or load processed data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Load data with dim_red columns ==============================================\n",
    "df = pd.read_excel(f\"{path_save}/df_origin.xlsx\", index_col=0)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Add to df_origin.xlsx PyOD outliers columns =================================\n",
    "add_pyod_outs_to_df(df, pyod_methods, feats)\n",
    "df.to_excel(f\"{path_save}/df_origin.xlsx\", index_label='sample_id')"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Outliers analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# IQR plots\n",
    "pathlib.Path(f\"{path_save}/Origin/outliers_iqr\").mkdir(parents=True, exist_ok=True)\n",
    "plot_iqr_outs(df, feats, 'grey', 'Origin', f\"{path_save}/Origin/outliers_iqr\")\n",
    "plot_iqr_outs_regression_error(df, feats, 'Origin', f\"{path_save}/Origin/outliers_iqr\", thld_outs_iqr, 'Age', 'SImAge', 'SImAge Error')\n",
    "\n",
    "# PyOD plots\n",
    "pathlib.Path(f\"{path_save}/Origin/outliers_pyod\").mkdir(parents=True, exist_ok=True)\n",
    "plot_pyod_outs(df, pyod_methods, 'grey', 'Origin', f\"{path_save}/Origin/outliers_pyod\")\n",
    "plot_pyod_outs_regression_error(df, pyod_methods, 'Origin', f\"{path_save}/Origin/outliers_pyod\", thld_outs_pyod, 'Age', 'SImAge', 'SImAge Error')"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "# Adversarial attacks",
   "metadata": {
    "collapsed": false
   }
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Generate"
  },
  {
   "cell_type": "code",
   "source": [
    "epsilons = sorted(list(set.union(\n",
    "    set(np.linspace(0.1, 1.0, 10)), \n",
    "    set(np.linspace(0.01, 0.1, 10)),\n",
    ")))\n",
    "df_eps = pd.DataFrame(index=epsilons)\n",
    "\n",
    "for eps_raw in epsilons:\n",
    "\n",
    "    eps = np.array([eps_raw * iqr(df.loc[:, feat].values) for feat in feats])\n",
    "    eps_step = np.array([0.2 * eps_raw * iqr(df.loc[:, feat].values) for feat in feats])\n",
    "\n",
    "    attacks = {\n",
    "        'MomentumIterative': MomentumIterativeMethod(\n",
    "            estimator=art_regressor,\n",
    "            norm=np.inf,\n",
    "            eps=eps,\n",
    "            eps_step=eps_step,\n",
    "            decay=0.1,\n",
    "            max_iter=100,\n",
    "            targeted=False,\n",
    "            batch_size=512,\n",
    "            verbose=True\n",
    "        ),\n",
    "        'BasicIterative': BasicIterativeMethod(\n",
    "            estimator=art_regressor,\n",
    "            eps=eps,\n",
    "            eps_step=eps_step,\n",
    "            max_iter=100,\n",
    "            targeted=False,\n",
    "            batch_size=512,\n",
    "            verbose=True\n",
    "        ),\n",
    "        'FastGradient': FastGradientMethod(\n",
    "            estimator=art_regressor,\n",
    "            norm=np.inf,\n",
    "            eps=eps,\n",
    "            eps_step=eps_step,\n",
    "            targeted=False,\n",
    "            num_random_init=0,\n",
    "            batch_size=512,\n",
    "            minimal=False,\n",
    "            summary_writer=False,\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    for attack_name, attack in attacks.items():\n",
    "        path_curr = f\"{path_save}/Evasion/{attack_name}/eps_{eps_raw:0.4f}\"\n",
    "        pathlib.Path(f\"{path_curr}\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        X_adv = attack.generate(np.float32(df.loc[:, feats].values))\n",
    "        \n",
    "        df_adv = df.loc[:, ['Age']].copy()\n",
    "        df_adv.loc[:, feats] = X_adv\n",
    "        df_adv[\"SImAge\"] = model(torch.from_numpy(np.float32(df_adv.loc[:, feats].values))).cpu().detach().numpy().ravel()\n",
    "        df_adv[\"SImAge Error\"] = df_adv[\"SImAge\"] - df_adv[\"Age\"]\n",
    "        df_adv[\"|SImAge Error|\"] = df_adv[\"SImAge Error\"].abs()\n",
    "        df_adv.loc[:, \"Error Origin\"] = df.loc[:, \"SImAge\"] - df.loc[:, \"Age\"]\n",
    "        df_adv.loc[:, \"Error Attack\"] = df_adv.loc[:, \"SImAge\"] - df_adv.loc[:, \"Age\"]\n",
    "        df_adv['Error Diff'] = df_adv['Error Attack'] - df_adv['Error Origin']\n",
    "        df_adv['|Error Diff|'] = df_adv['Error Diff'].abs()\n",
    "        for m, drm in dim_red_models.items():\n",
    "            dim_red_res = drm.transform(df_adv.loc[:, feats].values)\n",
    "            df_adv.loc[:, dim_red_labels[m][0]] = dim_red_res[:, 0]\n",
    "            df_adv.loc[:, dim_red_labels[m][1]] = dim_red_res[:, 1]\n",
    "            \n",
    "        df_adv.to_excel(f\"{path_curr}/df.xlsx\", index_label='sample_id')\n",
    "\n",
    "        metrics = get_reg_metrics()\n",
    "        metrics_cols = [f\"{m}_{p}\" for m in metrics for p in ids_dict]\n",
    "        df_metrics = pd.DataFrame(index=metrics_cols)\n",
    "        for p, ids_part in ids_dict.items():\n",
    "            for m in metrics:\n",
    "                m_val = float(metrics[m][0](torch.from_numpy(np.float32(df.loc[ids_part, \"SImAge\"].values)), torch.from_numpy(np.float32(df.loc[ids_part, \"Age\"].values))).numpy())\n",
    "                df_metrics.at[f\"{m}_{p}\", 'Origin'] = m_val\n",
    "                metrics[m][0].reset()\n",
    "                m_val = float(metrics[m][0](torch.from_numpy(np.float32(df_adv.loc[ids_part, \"SImAge\"].values)), torch.from_numpy(np.float32(df.loc[ids_part, \"Age\"].values))).numpy())\n",
    "                df_metrics.at[f\"{m}_{p}\", 'Attack'] = m_val\n",
    "                metrics[m][0].reset()\n",
    "        df_metrics.to_excel(f\"{path_curr}/metrics.xlsx\", index_label='Metrics')\n",
    "        \n",
    "        for p in ids_dict:\n",
    "            if attack_name == 'MomentumIterative':\n",
    "                df_eps.loc[eps_raw, f\"Origin_MAE_{p}\"] = df_metrics.at[f'mean_absolute_error_{p}', 'Origin']\n",
    "            df_eps.loc[eps_raw, f\"{attack_name}_MAE_{p}\"] = df_metrics.at[f'mean_absolute_error_{p}', 'Attack']\n",
    "            \n",
    "df_eps.to_excel(f\"{path_save}/Evasion/df_eps.xlsx\", index_label='eps')"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Plot Error from Eps"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for p in ids_dict:\n",
    "    df_fig = df_eps.loc[:, [f\"{x}_MAE_{p}\" for x in colors_atks]].copy()\n",
    "    df_fig.rename(columns={f\"{x}_MAE_{p}\": x for x in colors_atks}, inplace=True)\n",
    "    df_fig['Eps'] = df_fig.index.values\n",
    "    df_fig = df_fig.melt(id_vars=\"Eps\", var_name='Method', value_name=\"MAE\")\n",
    "    sns.set_theme(style='ticks', font_scale=1)\n",
    "    fig = plt.figure()\n",
    "    lines = sns.lineplot(\n",
    "        data=df_fig,\n",
    "        x='Eps',\n",
    "        y=\"MAE\",\n",
    "        hue=f\"Method\",\n",
    "        style=f\"Method\",\n",
    "        palette=colors_atks,\n",
    "        hue_order=list(colors_atks.keys()),\n",
    "        markers=True,\n",
    "        dashes=False,\n",
    "    )\n",
    "    plt.xscale('log')\n",
    "    lines.set_xlabel(r'$\\epsilon$')\n",
    "    x_min = 0.009\n",
    "    x_max = 1.05\n",
    "    mae_basic = df_eps.at[0.01, f\"Origin_MAE_{p}\"]\n",
    "    lines.set_xlim(x_min, x_max)\n",
    "    plt.gca().plot(\n",
    "        [x_min, x_max],\n",
    "        [mae_basic, mae_basic],\n",
    "        color='k',\n",
    "        linestyle='dashed',\n",
    "        linewidth=1\n",
    "    )\n",
    "    plt.savefig(f\"{path_save}/Evasion/line_mae_vs_eps_{p}.png\", bbox_inches='tight', dpi=200)\n",
    "    plt.savefig(f\"{path_save}/Evasion/line_mae_vs_eps_{p}.pdf\", bbox_inches='tight')\n",
    "    plt.close(fig)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## Plot in reduced dimension",
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "epsilons_hglt = [0.01, 0.02, 0.05, 0.1, 0.2, 0.5]\n",
    "colors_epsilons = {x: px.colors.qualitative.G10[x_id] for x_id, x in enumerate(['Origin'] + epsilons_hglt)}\n",
    "\n",
    "for atk in colors_atks:\n",
    "    for m in ['t-SNE']:\n",
    "        df_fig_ori = df.loc[:, ['SImAge Error', dim_red_labels[m][0], dim_red_labels[m][1]]].copy()\n",
    "        df_fig_ori['Symbol'] = 'o'\n",
    "        df_fig_ori['index_origin'] = df_fig_ori.index\n",
    "        df_fig_ori['Eps'] = 'Origin'\n",
    "        \n",
    "        dfs_fig_adv = [df_fig_ori]\n",
    "        for eps in epsilons_hglt:\n",
    "            path_curr = f\"{path_save}/Evasion/{atk}/eps_{eps:0.4f}\"\n",
    "            pathlib.Path(f\"{path_curr}/SImAgeError\").mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            df_adv = pd.read_excel(f\"{path_curr}/df.xlsx\", index_col='sample_id')\n",
    "            df_fig_adv = df_adv.loc[:, ['SImAge Error', '|Error Diff|', dim_red_labels[m][0], dim_red_labels[m][1]]].copy()\n",
    "            df_fig_adv['Eps'] = eps\n",
    "            df_fig_adv['index_origin'] = df_fig_adv.index\n",
    "            df_fig_adv.set_index(df_fig_adv.index.values + f'_adv_eps_{eps:0.4f}', inplace=True)\n",
    "            df_fig_adv['Symbol'] = 'X'\n",
    "            dfs_fig_adv.append(df_fig_adv)\n",
    "            df_fig_all = pd.concat([df_fig_ori, df_fig_adv])\n",
    "            \n",
    "            norm = plt.Normalize(df_fig_all['SImAge Error'].min(), df_fig_all['SImAge Error'].max())\n",
    "            sm = plt.cm.ScalarMappable(cmap=\"spring\", norm=norm)\n",
    "            sm.set_array([])\n",
    "            \n",
    "            sns.set_theme(style='ticks')\n",
    "            fig, ax = plt.subplots(figsize=(5, 4))\n",
    "            scatter = sns.scatterplot(\n",
    "                data=df_fig_all,\n",
    "                x=dim_red_labels[m][0],\n",
    "                y=dim_red_labels[m][1],\n",
    "                palette='spring',\n",
    "                hue='SImAge Error',\n",
    "                linewidth=1,\n",
    "                alpha=0.75,\n",
    "                edgecolor=\"k\",\n",
    "                style=df_fig_all.loc[:, 'Symbol'].values,\n",
    "                s=40,\n",
    "                ax=ax\n",
    "            )\n",
    "            scatter.get_legend().remove()\n",
    "            scatter.figure.colorbar(sm, label='SImAge Error')\n",
    "            scatter.set_title(fr'$\\epsilon={eps:0.2f}$', loc='left', fontdict={'fontsize': 20})\n",
    "\n",
    "            legend_handles = [\n",
    "                mlines.Line2D([], [], marker='o', linestyle='None', markeredgecolor='k', markerfacecolor='lightgrey', markersize=10, label='Real'),\n",
    "                mlines.Line2D([], [], marker='X', linestyle='None', markeredgecolor='k', markerfacecolor='lightgrey', markersize=10, label='Attack')\n",
    "            ]\n",
    "            plt.legend(handles=legend_handles, title=\"Samples\", bbox_to_anchor=(0.4, 1.02, 1, 0.2), loc=\"lower left\", borderaxespad=0, ncol=2, frameon=False)\n",
    "            \n",
    "            plt.savefig(f\"{path_curr}/SImAgeError/{m}.png\", bbox_inches='tight', dpi=200)\n",
    "            plt.savefig(f\"{path_curr}/SImAgeError/{m}.pdf\", bbox_inches='tight')\n",
    "            plt.close(fig)  \n",
    "        \n",
    "        df_fig_adv_eps = pd.concat(dfs_fig_adv)\n",
    "        sns.set_theme(style='ticks')\n",
    "        fig, ax = plt.subplots(figsize=(6, 4))\n",
    "        kdeplot = sns.kdeplot(\n",
    "            data=df_fig_adv_eps,\n",
    "            x='SImAge Error',\n",
    "            palette=colors_epsilons,\n",
    "            hue='Eps',\n",
    "            linewidth=2,\n",
    "            fill=False,\n",
    "            ax=ax\n",
    "        )\n",
    "        plt.savefig(f\"{path_save}/Evasion/{atk}/SImAgeError_{m}.png\", bbox_inches='tight', dpi=200)\n",
    "        plt.savefig(f\"{path_save}/Evasion/{atk}/SImAgeError_{m}.pdf\", bbox_inches='tight')\n",
    "        plt.close(fig)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## Plot distributions",
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "epsilons_hglt = [0.01, 0.02, 0.05, 0.1, 0.2, 0.5]\n",
    "colors_epsilons = {x: px.colors.qualitative.G10[x_id] for x_id, x in enumerate(['Origin'] + epsilons_hglt)}\n",
    "\n",
    "df['Eps'] = 'Origin'\n",
    "df['MarkerSize'] = 40\n",
    "\n",
    "for atk in colors_atks:\n",
    "\n",
    "    for eps in epsilons_hglt:\n",
    "        path_curr = f\"{path_save}/Evasion/{atk}/eps_{eps:0.4f}\"\n",
    "        pathlib.Path(f\"{path_curr}/SImAgeError\").mkdir(parents=True, exist_ok=True)\n",
    "        df_adv = pd.read_excel(f\"{path_curr}/df.xlsx\", index_col='sample_id')\n",
    "        df_adv.index += f'_eps_{eps:0.4f}'\n",
    "        df_adv['Eps'] = eps\n",
    "        df_adv['MarkerSize'] = 30\n",
    "        df_ori_adv = pd.concat([df, df_adv])\n",
    "        \n",
    "        pw_brick_kdes = {}\n",
    "        pw_brick_scatters = {}\n",
    "        for f in feats:\n",
    "            \n",
    "            pw_brick_kdes[f] = pw.Brick(figsize=(3, 2))\n",
    "            sns.set_theme(style='whitegrid')\n",
    "            kdeplot = sns.kdeplot(\n",
    "                data=df_ori_adv,\n",
    "                x=f,\n",
    "                hue='Eps',\n",
    "                palette={'Origin': 'grey', eps: colors_epsilons[eps]},\n",
    "                hue_order=['Origin', eps],\n",
    "                fill=True,\n",
    "                common_norm=False,\n",
    "                ax=pw_brick_kdes[f]\n",
    "            )\n",
    "            \n",
    "            pw_brick_scatters[f] = pw.Brick(figsize=(3, 2))\n",
    "            sns.set_theme(style='whitegrid')\n",
    "            scatterplot = sns.scatterplot(\n",
    "                data=df_ori_adv,\n",
    "                x=f,\n",
    "                y='Age',\n",
    "                hue='Eps',\n",
    "                palette={'Origin': 'grey', eps: colors_epsilons[eps]},\n",
    "                hue_order=['Origin', eps],\n",
    "                linewidth=0.85,\n",
    "                alpha=0.75,\n",
    "                edgecolor=\"k\",\n",
    "                marker='o',\n",
    "                s=30,\n",
    "                ax=pw_brick_scatters[f]\n",
    "            )\n",
    "        \n",
    "        n_cols = 5\n",
    "        n_rows = int(np.ceil(len(feats)/ n_cols))\n",
    "        pw_rows_kdes = []\n",
    "        pw_rows_scatters = []\n",
    "        for r_id in range(n_rows):\n",
    "            pw_cols_kdes = []\n",
    "            pw_cols_scatters = []\n",
    "            for c_id in range(n_cols):\n",
    "                rc_id = r_id * n_cols + c_id\n",
    "                if rc_id < len(feats):\n",
    "                    f = feats[rc_id]\n",
    "                    pw_cols_kdes.append(pw_brick_kdes[f])\n",
    "                    pw_cols_scatters.append(pw_brick_scatters[f])\n",
    "                else:\n",
    "                    empty_fig = pw.Brick(figsize=(4.67, 3))\n",
    "                    empty_fig.axis('off')\n",
    "                    pw_cols_kdes.append(empty_fig)\n",
    "                    pw_cols_scatters.append(empty_fig)\n",
    "            pw_rows_kdes.append(pw.stack(pw_cols_kdes, operator=\"|\"))\n",
    "            pw_rows_scatters.append(pw.stack(pw_cols_scatters, operator=\"|\"))\n",
    "        pw_fig_kde = pw.stack(pw_rows_kdes, operator=\"/\")\n",
    "        pw_fig_kde.savefig(f\"{path_curr}/feats_kde.png\", bbox_inches='tight', dpi=200)\n",
    "        pw_fig_kde.savefig(f\"{path_curr}/feats_kde.pdf\", bbox_inches='tight')\n",
    "        pw_fig_scatter = pw.stack(pw_rows_scatters, operator=\"/\")\n",
    "        pw_fig_scatter.savefig(f\"{path_curr}/feats_scatter.png\", bbox_inches='tight', dpi=200)\n",
    "        pw_fig_scatter.savefig(f\"{path_curr}/feats_scatter.pdf\", bbox_inches='tight')\n",
    "        pw.clear()"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Adversarial defences from attacks"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Generate detectors"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_ori = df[feats].copy()\n",
    "df_ori['Class'] = 'Original'\n",
    "\n",
    "for atk in colors_atks:\n",
    "    \n",
    "    df_def_acc = pd.DataFrame(index=epsilons, columns=['Model'] + list(epsilons))\n",
    "    \n",
    "    for eps in tqdm(epsilons):\n",
    "        \n",
    "        path_curr = f\"{path_save}/Evasion/{atk}/eps_{eps:0.4f}\"\n",
    "        df_adv = pd.read_excel(f\"{path_curr}/df.xlsx\", index_col='sample_id')\n",
    "        df_adv = df_adv[feats]\n",
    "        df_adv['Class'] = 'Attack'\n",
    "        df_def_trn_val = pd.concat([df_ori.loc[ids_trn_val, :], df_adv.loc[ids_trn_val, :]])\n",
    "        df_def_tst = pd.concat([df_ori.loc[ids_tst, :], df_adv.loc[ids_tst, :]])\n",
    "        \n",
    "        data_config = DataConfig(\n",
    "            target=['Class'],\n",
    "            continuous_cols=list(feats),\n",
    "            continuous_feature_transform='yeo-johnson',\n",
    "            normalize_continuous_features=True,\n",
    "        )\n",
    "        \n",
    "        trainer_config = TrainerConfig(\n",
    "            batch_size=1024,\n",
    "            max_epochs=100,\n",
    "            min_epochs=1,\n",
    "            auto_lr_find=True,\n",
    "            early_stopping='valid_loss',\n",
    "            early_stopping_min_delta=0.0001,\n",
    "            early_stopping_mode='min',\n",
    "            early_stopping_patience=100,\n",
    "            checkpoints='valid_loss',\n",
    "            checkpoints_path=f\"{path_curr}/detector\",\n",
    "            load_best=True,\n",
    "            progress_bar='none',\n",
    "            seed=42\n",
    "        )\n",
    "        \n",
    "        optimizer_config = OptimizerConfig(\n",
    "            optimizer='Adam',\n",
    "            lr_scheduler='CosineAnnealingWarmRestarts',\n",
    "            lr_scheduler_params={\n",
    "                'T_0': 10,\n",
    "                'T_mult': 1,\n",
    "                'eta_min': 0.00001,\n",
    "            },\n",
    "            lr_scheduler_monitor_metric='valid_loss'\n",
    "        )\n",
    "\n",
    "        head_config = LinearHeadConfig(\n",
    "            layers='',\n",
    "            activation='ReLU',\n",
    "            dropout=0.1,\n",
    "            use_batch_norm=False,\n",
    "            initialization='xavier',\n",
    "        ).__dict__\n",
    "\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            sweep_df, best_model = model_sweep(\n",
    "                task=\"classification\",\n",
    "                train=df_def_trn_val,\n",
    "                test=df_def_tst,\n",
    "                data_config=data_config,\n",
    "                optimizer_config=optimizer_config,\n",
    "                trainer_config=trainer_config,\n",
    "                model_list=\"standard\",\n",
    "                common_model_args=dict(head=\"LinearHead\", head_config=head_config),\n",
    "                metrics=[\n",
    "                    'accuracy',\n",
    "                    'f1_score',\n",
    "                    'precision',\n",
    "                    'recall',\n",
    "                    'specificity',\n",
    "                    'cohen_kappa',\n",
    "                    'auroc'\n",
    "                ],\n",
    "                metrics_prob_input=[True, True, True, True, True, True, True],\n",
    "                metrics_params=[\n",
    "                    {'task': 'multiclass', 'num_classes': 2, 'average': 'weighted'},\n",
    "                    {'task': 'multiclass', 'num_classes': 2, 'average': 'weighted'},\n",
    "                    {'task': 'multiclass', 'num_classes': 2, 'average': 'weighted'},\n",
    "                    {'task': 'multiclass', 'num_classes': 2, 'average': 'weighted'},\n",
    "                    {'task': 'multiclass', 'num_classes': 2, 'average': 'weighted'},\n",
    "                    {'task': 'multiclass', 'num_classes': 2},\n",
    "                    {'task': 'multiclass', 'num_classes': 2, 'average': 'weighted'},\n",
    "                ],\n",
    "                rank_metric=(\"accuracy\", \"higher_is_better\"),\n",
    "                progress_bar=False,\n",
    "                verbose=False,\n",
    "                suppress_lightning_logger=True,\n",
    "            )\n",
    "        ckpts = glob(f\"{path_curr}/detector/*\")\n",
    "        for ckpt in ckpts:\n",
    "            os.remove(ckpt)\n",
    "        # best_model.save_model(f\"{path_curr}/detector\")\n",
    "        df_def_acc.at[eps, 'Model'] = best_model.config['_model_name']\n",
    "        \n",
    "        for tst_eps in epsilons:\n",
    "            if tst_eps != eps:\n",
    "                path_tst = f\"{path_save}/Evasion/{atk}/eps_{tst_eps:0.4f}\"\n",
    "                df_adv_tst = pd.read_excel(f\"{path_tst}/df.xlsx\", index_col='sample_id')\n",
    "                df_adv_tst = df_adv_tst[feats]\n",
    "                df_adv_tst['Class'] = 'Attack'\n",
    "                df_def_tst_eps = pd.concat([df_ori, df_adv_tst])\n",
    "                metrics = best_model.evaluate(test=df_def_tst_eps, verbose=False)[0]\n",
    "                df_def_acc.at[eps, tst_eps] = metrics['test_accuracy']\n",
    "    df_def_acc.to_excel(f\"{path_save}/Evasion/{atk}/detectors_accuracy.xlsx\")            \n",
    "    "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Plot detectors accuracy"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for atk in colors_atks:\n",
    "    df_def_acc = pd.read_excel(f\"{path_save}/Evasion/{atk}/detectors_accuracy.xlsx\", index_col=0)\n",
    "    df_def_acc['Eps'] = [f\"{x:.2f}\" for x in df_def_acc.index.values]\n",
    "    df_def_acc['index'] = df_def_acc['Model'] + '\\n' + df_def_acc['Eps']\n",
    "    df_def_acc.set_index('index', inplace=True)\n",
    "    df_def_acc.drop(['Model', 'Eps'], axis=1, inplace=True)\n",
    "    df_def_acc.rename(columns={x: f\"{x:.2f}\" for x in df_def_acc.columns}, inplace=True)\n",
    "    \n",
    "    df_fig = df_def_acc.astype(float)\n",
    "    sns.set_theme(style='ticks', font_scale=1.0)\n",
    "    fig, ax = plt.subplots(figsize=(13, 12))\n",
    "    heatmap = sns.heatmap(\n",
    "        df_fig,\n",
    "        annot=True,\n",
    "        fmt=\".2f\",\n",
    "        cmap='hot',\n",
    "        linewidth=0.1,\n",
    "        linecolor='black',\n",
    "        cbar_kws={\n",
    "            'orientation': 'horizontal',\n",
    "            'location': 'top',\n",
    "            'pad': 0.025,\n",
    "            'aspect': 30\n",
    "        },\n",
    "        annot_kws={\"size\": 12},\n",
    "        ax=ax\n",
    "    )\n",
    "    ax.set_xlabel('Test Attack Strength')\n",
    "    ax.set_ylabel('Training Model and Data')\n",
    "    heatmap_pos = heatmap.get_position()\n",
    "    ax.figure.axes[-1].set_title(\"Accuracy\")\n",
    "    ax.figure.axes[-1].tick_params()\n",
    "    for spine in ax.figure.axes[-1].spines.values():\n",
    "        spine.set_linewidth(1)\n",
    "    plt.savefig(f\"{path_save}/Evasion/{atk}/detectors_accuracy.png\", bbox_inches='tight', dpi=200)\n",
    "    plt.savefig(f\"{path_save}/Evasion/{atk}/detectors_accuracy.pdf\", bbox_inches='tight')\n",
    "    plt.close(fig)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "# Outliers analysis for attacks",
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "epsilons_hglt = [0.01, 0.02, 0.05, 0.1, 0.2, 0.5]\n",
    "colors_epsilons = {x: px.colors.qualitative.G10[x_id] for x_id, x in enumerate(['Origin'] + epsilons_hglt)}\n",
    "\n",
    "for atk in colors_atks:\n",
    "\n",
    "    for eps in epsilons_hglt:\n",
    "        path_curr = f\"{path_save}/Evasion/{atk}/eps_{eps:0.4f}\"\n",
    "        pathlib.Path(f\"{path_curr}/SImAgeError\").mkdir(parents=True, exist_ok=True)\n",
    "        df_adv = pd.read_excel(f\"{path_curr}/df.xlsx\", index_col='sample_id')\n",
    "        \n",
    "        # IQR outliers\n",
    "        pathlib.Path(f\"{path_curr}/outliers_iqr\").mkdir(parents=True, exist_ok=True)\n",
    "        plot_iqr_outs(df_adv, feats, colors_epsilons[eps], f\"{atk} Eps({eps})\", f\"{path_curr}/outliers_iqr\")\n",
    "        \n",
    "        # PyOD plots\n",
    "        pathlib.Path(f\"{path_curr}/outliers_pyod\").mkdir(parents=True, exist_ok=True)\n",
    "        plot_pyod_outs(df_adv, pyod_methods, colors_epsilons[eps], f\"{atk} Eps({eps})\", f\"{path_curr}/outliers_pyod\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
